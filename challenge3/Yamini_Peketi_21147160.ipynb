{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "#Prediction Challenge 3- Deep Reinforcement Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "!pip install keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNGTghHEhyW4",
        "outputId": "1ad00080-39b2-49ff-b645-f6c4ae270df7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (15.0.6.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (67.6.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.31.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.51.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.16.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.2.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GYM-It provides a collection of environments to test and develop reinforcement learning algorithms, including classic control problems, Atari games, and robotics tasks. Gym also provides a standardized interface for these environments, making it easy to train and test reinforcement learning algorithms across different environments. Gym is developed by OpenAI and is open source, meaning that anyone can use and contribute to its development."
      ],
      "metadata": {
        "id": "HMbV5sY9zsdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym\n",
        "#Gym is an tool kit and developing reinforcement  Learnig algorithms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ_dXOCKh0jV",
        "outputId": "0f457670-00c4-4159-ae86-a8391223ef59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U4FsOc5szqk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the gym module tool kit\n",
        "import gym\n",
        "#to visualize\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "#simple forward network \n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "#name of the environment we are using\n",
        "env = gym.make(ENV_NAME)\n",
        "#creating the instance of the environment"
      ],
      "metadata": {
        "id": "75Phf54nh2y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a24bf5-9203-4165-b5bc-6fc74244fc86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy  # import the policy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent"
      ],
      "metadata": {
        "id": "KsGYDOrDh58e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation_space.shape\n",
        "#pre defined input in the environmnet"
      ],
      "metadata": {
        "id": "MhsbKs7F8Ny3",
        "outputId": "cedaa921-78ab-4d8d-925d-295b4ade3755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.n"
      ],
      "metadata": {
        "id": "adTkKLlE8ZlQ",
        "outputId": "81471ec5-751f-44c5-e63a-877ef23d35d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1\n"
      ],
      "metadata": {
        "id": "2W6qC7yl0cyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Network\n",
        "model1 = Sequential()\n",
        "model1.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model1.add(Flatten())\n",
        "# add extra layers here\n",
        "model1.add(Dense(16, activation='relu'))\n",
        "model1.add(Dense(32, activation='relu'))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "\n",
        "model1.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Kmv2uS0cHc",
        "outputId": "3b9fe9c6-0885-4a64-ae6b-58676ae4f728"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,314\n",
            "Trainable params: 11,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network takes as input a single observation vector of size env.observation_space.shape[0], which corresponds to the number of observations in the observation space of the environment. The input layer is followed by a Flatten layer that flattens the input tensor into a 1-dimensional vector.\n",
        "\n",
        "The network then has four fully connected (Dense) hidden layers with 16, 32, 64, and 128 units, respectively, each using ReLU activation. These layers allow the network to learn complex representations of the state space.\n",
        "\n",
        "Finally, the network has an output layer with env.action_space.n units, which corresponds to the number of actions in the action space of the environment. The output layer uses a linear activation function to produce the Q-values for each action."
      ],
      "metadata": {
        "id": "lkg3Lgs-03ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=2500, window_length=1)\n",
        "\"\"\"This creates a memory buffer that stores the agent's experiences during training. \n",
        "In this case, the buffer has a limit of 2500 experiences, and each experience consists of a single observation.\"\"\"\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\"\"\" This defines the exploration policy for the agent. In this case, \n",
        "it uses an Epsilon Greedy policy with an initial exploration rate of 1.0, which means the agent takes random actions at first. \n",
        "The exploration rate is linearly annealed over 10,000 steps down to a minimum value of 0.1,\n",
        " which means the agent starts to rely more on its learned policy as training progresses.\"\"\"\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model1, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\"\"\" This creates the DQN agent using the previously defined neural network model,\n",
        " with the number of actions in the environment's action space env.action_space.n. \n",
        " The memory argument specifies the memory buffer to be used for experience replay, \n",
        "and nb_steps_warmup specifies the number of random steps to take before learning starts. \"\"\"\n",
        "\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "\n",
        "\n",
        "history_1 = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\"\"\"his fits the DQN agent to the environment for 10,000 steps. \n",
        "The visualize argument specifies whether to display the environment during training, \n",
        "and verbose controls the verbosity of the training output.\n",
        " The function returns a history object that contains information about the training process, \n",
        " such as the rewards obtained at each step. \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17U1kpYV1FVI",
        "outputId": "cad82551-07ff-42d7-d86f-989907201102"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n",
            "   45/10000: episode: 1, duration: 0.194s, episode steps:  45, steps per second: 232, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   83/10000: episode: 2, duration: 0.038s, episode steps:  38, steps per second: 1004, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.395 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   97/10000: episode: 3, duration: 0.013s, episode steps:  14, steps per second: 1108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  113/10000: episode: 4, duration: 1.316s, episode steps:  16, steps per second:  12, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.382911, mae: 0.506274, mean_q: 0.186772, mean_eps: 0.990415\n",
            "  139/10000: episode: 5, duration: 0.296s, episode steps:  26, steps per second:  88, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 0.118301, mae: 0.632972, mean_q: 0.918382, mean_eps: 0.988705\n",
            "  171/10000: episode: 6, duration: 0.377s, episode steps:  32, steps per second:  85, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.022593, mae: 0.673793, mean_q: 1.229166, mean_eps: 0.986095\n",
            "  184/10000: episode: 7, duration: 0.150s, episode steps:  13, steps per second:  87, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 0.010111, mae: 0.721274, mean_q: 1.406162, mean_eps: 0.984070\n",
            "  200/10000: episode: 8, duration: 0.192s, episode steps:  16, steps per second:  84, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.006197, mae: 0.762562, mean_q: 1.513491, mean_eps: 0.982765\n",
            "  248/10000: episode: 9, duration: 0.566s, episode steps:  48, steps per second:  85, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 0.015204, mae: 0.871695, mean_q: 1.730714, mean_eps: 0.979885\n",
            "  292/10000: episode: 10, duration: 0.359s, episode steps:  44, steps per second: 123, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 0.023032, mae: 1.039027, mean_q: 2.027389, mean_eps: 0.975745\n",
            "  315/10000: episode: 11, duration: 0.230s, episode steps:  23, steps per second: 100, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 0.030339, mae: 1.172641, mean_q: 2.266129, mean_eps: 0.972730\n",
            "  325/10000: episode: 12, duration: 0.088s, episode steps:  10, steps per second: 114, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 0.027825, mae: 1.240830, mean_q: 2.395118, mean_eps: 0.971245\n",
            "  343/10000: episode: 13, duration: 0.150s, episode steps:  18, steps per second: 120, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.041156, mae: 1.292520, mean_q: 2.503458, mean_eps: 0.969985\n",
            "  386/10000: episode: 14, duration: 0.328s, episode steps:  43, steps per second: 131, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 0.044603, mae: 1.404316, mean_q: 2.732871, mean_eps: 0.967240\n",
            "  408/10000: episode: 15, duration: 0.188s, episode steps:  22, steps per second: 117, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.062808, mae: 1.542306, mean_q: 2.992861, mean_eps: 0.964315\n",
            "  429/10000: episode: 16, duration: 0.177s, episode steps:  21, steps per second: 119, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 0.051653, mae: 1.623043, mean_q: 3.162612, mean_eps: 0.962380\n",
            "  451/10000: episode: 17, duration: 0.178s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.070767, mae: 1.746021, mean_q: 3.398480, mean_eps: 0.960445\n",
            "  475/10000: episode: 18, duration: 0.190s, episode steps:  24, steps per second: 127, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.067947, mae: 1.832591, mean_q: 3.603136, mean_eps: 0.958375\n",
            "  517/10000: episode: 19, duration: 0.338s, episode steps:  42, steps per second: 124, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.084320, mae: 1.968615, mean_q: 3.857066, mean_eps: 0.955405\n",
            "  530/10000: episode: 20, duration: 0.107s, episode steps:  13, steps per second: 122, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 0.117755, mae: 2.121364, mean_q: 4.116848, mean_eps: 0.952930\n",
            "  554/10000: episode: 21, duration: 0.191s, episode steps:  24, steps per second: 126, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 0.121588, mae: 2.201869, mean_q: 4.249282, mean_eps: 0.951265\n",
            "  591/10000: episode: 22, duration: 0.319s, episode steps:  37, steps per second: 116, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 0.160077, mae: 2.325796, mean_q: 4.451943, mean_eps: 0.948520\n",
            "  620/10000: episode: 23, duration: 0.238s, episode steps:  29, steps per second: 122, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 0.099351, mae: 2.445688, mean_q: 4.786633, mean_eps: 0.945550\n",
            "  634/10000: episode: 24, duration: 0.119s, episode steps:  14, steps per second: 118, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 0.093350, mae: 2.563337, mean_q: 5.029804, mean_eps: 0.943615\n",
            "  644/10000: episode: 25, duration: 0.093s, episode steps:  10, steps per second: 108, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.093049, mae: 2.562684, mean_q: 5.101569, mean_eps: 0.942535\n",
            "  658/10000: episode: 26, duration: 0.113s, episode steps:  14, steps per second: 124, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.126358, mae: 2.656955, mean_q: 5.177121, mean_eps: 0.941455\n",
            "  676/10000: episode: 27, duration: 0.144s, episode steps:  18, steps per second: 125, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.133643, mae: 2.670340, mean_q: 5.242062, mean_eps: 0.940015\n",
            "  690/10000: episode: 28, duration: 0.114s, episode steps:  14, steps per second: 122, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.120068, mae: 2.746639, mean_q: 5.372405, mean_eps: 0.938575\n",
            "  703/10000: episode: 29, duration: 0.121s, episode steps:  13, steps per second: 108, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.155583, mae: 2.801891, mean_q: 5.484182, mean_eps: 0.937360\n",
            "  722/10000: episode: 30, duration: 0.164s, episode steps:  19, steps per second: 116, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 0.158730, mae: 2.907029, mean_q: 5.684883, mean_eps: 0.935920\n",
            "  746/10000: episode: 31, duration: 0.215s, episode steps:  24, steps per second: 112, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.173964, mae: 2.988386, mean_q: 5.809802, mean_eps: 0.933985\n",
            "  760/10000: episode: 32, duration: 0.111s, episode steps:  14, steps per second: 126, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.177844, mae: 3.047741, mean_q: 5.918268, mean_eps: 0.932275\n",
            "  796/10000: episode: 33, duration: 0.278s, episode steps:  36, steps per second: 129, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.139689, mae: 3.151744, mean_q: 6.168498, mean_eps: 0.930025\n",
            "  814/10000: episode: 34, duration: 0.146s, episode steps:  18, steps per second: 124, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.138980, mae: 3.258367, mean_q: 6.363530, mean_eps: 0.927595\n",
            "  838/10000: episode: 35, duration: 0.186s, episode steps:  24, steps per second: 129, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.131932, mae: 3.323471, mean_q: 6.551261, mean_eps: 0.925705\n",
            "  861/10000: episode: 36, duration: 0.179s, episode steps:  23, steps per second: 129, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 0.124087, mae: 3.428639, mean_q: 6.796402, mean_eps: 0.923590\n",
            "  919/10000: episode: 37, duration: 0.464s, episode steps:  58, steps per second: 125, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 0.123812, mae: 3.592996, mean_q: 7.130091, mean_eps: 0.919945\n",
            "  935/10000: episode: 38, duration: 0.134s, episode steps:  16, steps per second: 120, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.142471, mae: 3.781923, mean_q: 7.550394, mean_eps: 0.916615\n",
            "  992/10000: episode: 39, duration: 0.435s, episode steps:  57, steps per second: 131, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.164724, mae: 3.902181, mean_q: 7.798975, mean_eps: 0.913330\n",
            " 1020/10000: episode: 40, duration: 0.223s, episode steps:  28, steps per second: 126, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.122913, mae: 4.083033, mean_q: 8.253996, mean_eps: 0.909505\n",
            " 1036/10000: episode: 41, duration: 0.125s, episode steps:  16, steps per second: 128, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.235807, mae: 4.226018, mean_q: 8.421881, mean_eps: 0.907525\n",
            " 1052/10000: episode: 42, duration: 0.129s, episode steps:  16, steps per second: 124, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.211308, mae: 4.277075, mean_q: 8.506748, mean_eps: 0.906085\n",
            " 1084/10000: episode: 43, duration: 0.276s, episode steps:  32, steps per second: 116, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 0.139896, mae: 4.390496, mean_q: 8.813627, mean_eps: 0.903925\n",
            " 1119/10000: episode: 44, duration: 0.412s, episode steps:  35, steps per second:  85, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.629 [0.000, 1.000],  loss: 0.233059, mae: 4.563051, mean_q: 9.214045, mean_eps: 0.900910\n",
            " 1183/10000: episode: 45, duration: 0.721s, episode steps:  64, steps per second:  89, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.422 [0.000, 1.000],  loss: 0.176751, mae: 4.853301, mean_q: 9.834538, mean_eps: 0.896455\n",
            " 1197/10000: episode: 46, duration: 0.170s, episode steps:  14, steps per second:  82, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.328386, mae: 4.932676, mean_q: 9.939733, mean_eps: 0.892945\n",
            " 1211/10000: episode: 47, duration: 0.194s, episode steps:  14, steps per second:  72, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.252756, mae: 5.003420, mean_q: 9.966669, mean_eps: 0.891685\n",
            " 1265/10000: episode: 48, duration: 0.614s, episode steps:  54, steps per second:  88, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 0.227862, mae: 5.177708, mean_q: 10.488543, mean_eps: 0.888625\n",
            " 1334/10000: episode: 49, duration: 0.687s, episode steps:  69, steps per second: 101, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 0.260115, mae: 5.488119, mean_q: 11.126805, mean_eps: 0.883090\n",
            " 1356/10000: episode: 50, duration: 0.178s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.254162, mae: 5.765914, mean_q: 11.698898, mean_eps: 0.878995\n",
            " 1372/10000: episode: 51, duration: 0.130s, episode steps:  16, steps per second: 123, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.350849, mae: 5.776062, mean_q: 11.686826, mean_eps: 0.877285\n",
            " 1408/10000: episode: 52, duration: 0.288s, episode steps:  36, steps per second: 125, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 0.236425, mae: 5.869448, mean_q: 11.949994, mean_eps: 0.874945\n",
            " 1427/10000: episode: 53, duration: 0.169s, episode steps:  19, steps per second: 112, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 0.211704, mae: 6.031296, mean_q: 12.193032, mean_eps: 0.872470\n",
            " 1465/10000: episode: 54, duration: 0.315s, episode steps:  38, steps per second: 121, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.189492, mae: 6.197641, mean_q: 12.625332, mean_eps: 0.869905\n",
            " 1479/10000: episode: 55, duration: 0.112s, episode steps:  14, steps per second: 125, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.211556, mae: 6.278922, mean_q: 12.808585, mean_eps: 0.867565\n",
            " 1494/10000: episode: 56, duration: 0.134s, episode steps:  15, steps per second: 112, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.285305, mae: 6.387328, mean_q: 12.982003, mean_eps: 0.866260\n",
            " 1546/10000: episode: 57, duration: 0.457s, episode steps:  52, steps per second: 114, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 0.274114, mae: 6.571617, mean_q: 13.419245, mean_eps: 0.863245\n",
            " 1591/10000: episode: 58, duration: 0.357s, episode steps:  45, steps per second: 126, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 0.186907, mae: 6.763435, mean_q: 13.865104, mean_eps: 0.858880\n",
            " 1609/10000: episode: 59, duration: 0.135s, episode steps:  18, steps per second: 133, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.271459, mae: 6.909058, mean_q: 14.096928, mean_eps: 0.856045\n",
            " 1618/10000: episode: 60, duration: 0.076s, episode steps:   9, steps per second: 118, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.447774, mae: 6.985092, mean_q: 14.239987, mean_eps: 0.854830\n",
            " 1629/10000: episode: 61, duration: 0.085s, episode steps:  11, steps per second: 129, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 0.176649, mae: 7.060486, mean_q: 14.420882, mean_eps: 0.853930\n",
            " 1684/10000: episode: 62, duration: 0.445s, episode steps:  55, steps per second: 124, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 0.279805, mae: 7.181312, mean_q: 14.700714, mean_eps: 0.850960\n",
            " 1729/10000: episode: 63, duration: 0.344s, episode steps:  45, steps per second: 131, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.422 [0.000, 1.000],  loss: 0.289154, mae: 7.629178, mean_q: 15.551666, mean_eps: 0.846460\n",
            " 1760/10000: episode: 64, duration: 0.243s, episode steps:  31, steps per second: 127, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.581 [0.000, 1.000],  loss: 0.292947, mae: 7.714257, mean_q: 15.792860, mean_eps: 0.843040\n",
            " 1799/10000: episode: 65, duration: 0.326s, episode steps:  39, steps per second: 120, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 0.289464, mae: 7.950433, mean_q: 16.369293, mean_eps: 0.839890\n",
            " 1852/10000: episode: 66, duration: 0.426s, episode steps:  53, steps per second: 124, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 0.413250, mae: 8.204136, mean_q: 16.813768, mean_eps: 0.835750\n",
            " 1896/10000: episode: 67, duration: 0.339s, episode steps:  44, steps per second: 130, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.614 [0.000, 1.000],  loss: 0.405316, mae: 8.401446, mean_q: 17.154930, mean_eps: 0.831385\n",
            " 1922/10000: episode: 68, duration: 0.199s, episode steps:  26, steps per second: 131, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.325843, mae: 8.566282, mean_q: 17.526349, mean_eps: 0.828235\n",
            " 1934/10000: episode: 69, duration: 0.107s, episode steps:  12, steps per second: 112, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.377434, mae: 8.926586, mean_q: 18.141369, mean_eps: 0.826525\n",
            " 1946/10000: episode: 70, duration: 0.096s, episode steps:  12, steps per second: 125, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.379358, mae: 8.689135, mean_q: 17.758221, mean_eps: 0.825445\n",
            " 1985/10000: episode: 71, duration: 0.309s, episode steps:  39, steps per second: 126, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.410 [0.000, 1.000],  loss: 0.271103, mae: 8.861940, mean_q: 18.143876, mean_eps: 0.823150\n",
            " 2002/10000: episode: 72, duration: 0.134s, episode steps:  17, steps per second: 126, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 0.400598, mae: 8.969873, mean_q: 18.398211, mean_eps: 0.820630\n",
            " 2021/10000: episode: 73, duration: 0.162s, episode steps:  19, steps per second: 117, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 0.227025, mae: 9.077992, mean_q: 18.495650, mean_eps: 0.819010\n",
            " 2042/10000: episode: 74, duration: 0.177s, episode steps:  21, steps per second: 119, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 0.336058, mae: 9.161840, mean_q: 18.827051, mean_eps: 0.817210\n",
            " 2072/10000: episode: 75, duration: 0.251s, episode steps:  30, steps per second: 119, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.473553, mae: 9.340963, mean_q: 19.141079, mean_eps: 0.814915\n",
            " 2094/10000: episode: 76, duration: 0.174s, episode steps:  22, steps per second: 126, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 0.682173, mae: 9.368763, mean_q: 19.237793, mean_eps: 0.812575\n",
            " 2119/10000: episode: 77, duration: 0.199s, episode steps:  25, steps per second: 126, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.640 [0.000, 1.000],  loss: 0.665119, mae: 9.712391, mean_q: 19.668311, mean_eps: 0.810460\n",
            " 2141/10000: episode: 78, duration: 0.177s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 0.456463, mae: 9.666242, mean_q: 19.708898, mean_eps: 0.808345\n",
            " 2173/10000: episode: 79, duration: 0.254s, episode steps:  32, steps per second: 126, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.594 [0.000, 1.000],  loss: 0.441003, mae: 9.814750, mean_q: 20.146317, mean_eps: 0.805915\n",
            " 2201/10000: episode: 80, duration: 0.235s, episode steps:  28, steps per second: 119, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 0.433628, mae: 9.928634, mean_q: 20.361992, mean_eps: 0.803215\n",
            " 2223/10000: episode: 81, duration: 0.165s, episode steps:  22, steps per second: 134, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.356227, mae: 10.138237, mean_q: 20.680801, mean_eps: 0.800965\n",
            " 2283/10000: episode: 82, duration: 0.454s, episode steps:  60, steps per second: 132, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.327080, mae: 10.320696, mean_q: 21.137112, mean_eps: 0.797275\n",
            " 2310/10000: episode: 83, duration: 0.214s, episode steps:  27, steps per second: 126, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.630 [0.000, 1.000],  loss: 0.326963, mae: 10.600123, mean_q: 21.578060, mean_eps: 0.793360\n",
            " 2324/10000: episode: 84, duration: 0.123s, episode steps:  14, steps per second: 114, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 0.266907, mae: 10.651694, mean_q: 21.851110, mean_eps: 0.791515\n",
            " 2342/10000: episode: 85, duration: 0.142s, episode steps:  18, steps per second: 127, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.477680, mae: 10.744546, mean_q: 22.263036, mean_eps: 0.790075\n",
            " 2355/10000: episode: 86, duration: 0.102s, episode steps:  13, steps per second: 128, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.957354, mae: 10.807678, mean_q: 22.006265, mean_eps: 0.788680\n",
            " 2374/10000: episode: 87, duration: 0.155s, episode steps:  19, steps per second: 123, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 0.505996, mae: 11.027420, mean_q: 22.320838, mean_eps: 0.787240\n",
            " 2386/10000: episode: 88, duration: 0.094s, episode steps:  12, steps per second: 127, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.257123, mae: 11.095017, mean_q: 22.627983, mean_eps: 0.785845\n",
            " 2409/10000: episode: 89, duration: 0.186s, episode steps:  23, steps per second: 123, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.304 [0.000, 1.000],  loss: 0.440479, mae: 11.009299, mean_q: 22.577975, mean_eps: 0.784270\n",
            " 2423/10000: episode: 90, duration: 0.110s, episode steps:  14, steps per second: 127, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.359844, mae: 11.104924, mean_q: 22.763678, mean_eps: 0.782605\n",
            " 2464/10000: episode: 91, duration: 0.340s, episode steps:  41, steps per second: 121, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 0.523289, mae: 11.144360, mean_q: 22.884197, mean_eps: 0.780130\n",
            " 2499/10000: episode: 92, duration: 0.279s, episode steps:  35, steps per second: 125, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.915691, mae: 11.390223, mean_q: 23.283647, mean_eps: 0.776710\n",
            " 2519/10000: episode: 93, duration: 0.179s, episode steps:  20, steps per second: 112, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 0.503463, mae: 11.424890, mean_q: 23.307275, mean_eps: 0.774235\n",
            " 2588/10000: episode: 94, duration: 0.813s, episode steps:  69, steps per second:  85, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 0.685436, mae: 11.561502, mean_q: 23.740893, mean_eps: 0.770230\n",
            " 2641/10000: episode: 95, duration: 0.639s, episode steps:  53, steps per second:  83, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 0.486717, mae: 11.858673, mean_q: 24.357411, mean_eps: 0.764740\n",
            " 2676/10000: episode: 96, duration: 0.387s, episode steps:  35, steps per second:  90, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.530534, mae: 12.166486, mean_q: 24.990682, mean_eps: 0.760780\n",
            " 2696/10000: episode: 97, duration: 0.237s, episode steps:  20, steps per second:  84, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 0.914754, mae: 12.162212, mean_q: 25.164040, mean_eps: 0.758305\n",
            " 2742/10000: episode: 98, duration: 0.539s, episode steps:  46, steps per second:  85, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.715936, mae: 12.418825, mean_q: 25.481665, mean_eps: 0.755335\n",
            " 2757/10000: episode: 99, duration: 0.177s, episode steps:  15, steps per second:  85, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 1.986961, mae: 12.702117, mean_q: 25.875738, mean_eps: 0.752590\n",
            " 2811/10000: episode: 100, duration: 0.419s, episode steps:  54, steps per second: 129, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 1.172221, mae: 12.908200, mean_q: 26.239010, mean_eps: 0.749485\n",
            " 2854/10000: episode: 101, duration: 0.342s, episode steps:  43, steps per second: 126, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.605 [0.000, 1.000],  loss: 0.846065, mae: 12.881961, mean_q: 26.393372, mean_eps: 0.745120\n",
            " 2874/10000: episode: 102, duration: 0.160s, episode steps:  20, steps per second: 125, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.450157, mae: 13.295217, mean_q: 27.265557, mean_eps: 0.742285\n",
            " 2908/10000: episode: 103, duration: 0.284s, episode steps:  34, steps per second: 120, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.618 [0.000, 1.000],  loss: 0.560924, mae: 13.259211, mean_q: 27.275321, mean_eps: 0.739855\n",
            " 2951/10000: episode: 104, duration: 0.345s, episode steps:  43, steps per second: 125, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 0.877962, mae: 13.486680, mean_q: 27.632010, mean_eps: 0.736390\n",
            " 2967/10000: episode: 105, duration: 0.123s, episode steps:  16, steps per second: 130, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.477255, mae: 13.783424, mean_q: 28.333952, mean_eps: 0.733735\n",
            " 2985/10000: episode: 106, duration: 0.157s, episode steps:  18, steps per second: 114, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.475373, mae: 13.594515, mean_q: 28.065136, mean_eps: 0.732205\n",
            " 2998/10000: episode: 107, duration: 0.104s, episode steps:  13, steps per second: 125, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 1.462911, mae: 13.544531, mean_q: 27.769134, mean_eps: 0.730810\n",
            " 3035/10000: episode: 108, duration: 0.280s, episode steps:  37, steps per second: 132, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.395907, mae: 13.823613, mean_q: 28.299784, mean_eps: 0.728560\n",
            " 3048/10000: episode: 109, duration: 0.099s, episode steps:  13, steps per second: 131, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 1.237408, mae: 13.755407, mean_q: 28.095078, mean_eps: 0.726310\n",
            " 3072/10000: episode: 110, duration: 0.182s, episode steps:  24, steps per second: 132, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.830148, mae: 14.029838, mean_q: 28.929352, mean_eps: 0.724645\n",
            " 3104/10000: episode: 111, duration: 0.267s, episode steps:  32, steps per second: 120, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.769451, mae: 14.017029, mean_q: 28.629131, mean_eps: 0.722125\n",
            " 3119/10000: episode: 112, duration: 0.113s, episode steps:  15, steps per second: 133, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.941198, mae: 13.847066, mean_q: 28.594538, mean_eps: 0.720010\n",
            " 3151/10000: episode: 113, duration: 0.259s, episode steps:  32, steps per second: 124, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 0.667904, mae: 13.885199, mean_q: 28.808659, mean_eps: 0.717895\n",
            " 3178/10000: episode: 114, duration: 0.213s, episode steps:  27, steps per second: 127, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.022644, mae: 14.593618, mean_q: 29.959267, mean_eps: 0.715240\n",
            " 3196/10000: episode: 115, duration: 0.146s, episode steps:  18, steps per second: 124, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.038623, mae: 14.474030, mean_q: 29.440828, mean_eps: 0.713215\n",
            " 3214/10000: episode: 116, duration: 0.143s, episode steps:  18, steps per second: 126, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 1.105399, mae: 14.569398, mean_q: 29.850564, mean_eps: 0.711595\n",
            " 3242/10000: episode: 117, duration: 0.231s, episode steps:  28, steps per second: 121, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 0.526730, mae: 14.640282, mean_q: 30.075257, mean_eps: 0.709525\n",
            " 3271/10000: episode: 118, duration: 0.223s, episode steps:  29, steps per second: 130, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.789505, mae: 14.736607, mean_q: 30.413278, mean_eps: 0.706960\n",
            " 3347/10000: episode: 119, duration: 0.602s, episode steps:  76, steps per second: 126, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 0.851788, mae: 14.889810, mean_q: 30.773483, mean_eps: 0.702235\n",
            " 3363/10000: episode: 120, duration: 0.144s, episode steps:  16, steps per second: 111, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 1.254305, mae: 15.645407, mean_q: 31.972978, mean_eps: 0.698095\n",
            " 3401/10000: episode: 121, duration: 0.290s, episode steps:  38, steps per second: 131, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.806831, mae: 14.999750, mean_q: 31.215906, mean_eps: 0.695665\n",
            " 3431/10000: episode: 122, duration: 0.265s, episode steps:  30, steps per second: 113, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 2.006827, mae: 15.332981, mean_q: 31.582818, mean_eps: 0.692605\n",
            " 3445/10000: episode: 123, duration: 0.116s, episode steps:  14, steps per second: 121, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.596020, mae: 15.227423, mean_q: 31.207116, mean_eps: 0.690625\n",
            " 3455/10000: episode: 124, duration: 0.088s, episode steps:  10, steps per second: 114, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 2.231408, mae: 15.201558, mean_q: 31.011025, mean_eps: 0.689545\n",
            " 3472/10000: episode: 125, duration: 0.137s, episode steps:  17, steps per second: 124, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 4.189657, mae: 15.309158, mean_q: 31.124503, mean_eps: 0.688330\n",
            " 3486/10000: episode: 126, duration: 0.136s, episode steps:  14, steps per second: 103, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.037239, mae: 15.665562, mean_q: 31.774511, mean_eps: 0.686935\n",
            " 3498/10000: episode: 127, duration: 0.095s, episode steps:  12, steps per second: 126, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 2.910836, mae: 15.527745, mean_q: 31.754998, mean_eps: 0.685765\n",
            " 3524/10000: episode: 128, duration: 0.225s, episode steps:  26, steps per second: 116, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 2.372701, mae: 15.746558, mean_q: 32.089694, mean_eps: 0.684055\n",
            " 3539/10000: episode: 129, duration: 0.125s, episode steps:  15, steps per second: 120, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 0.711319, mae: 15.451166, mean_q: 31.716314, mean_eps: 0.682210\n",
            " 3557/10000: episode: 130, duration: 0.150s, episode steps:  18, steps per second: 120, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 1.038881, mae: 15.884148, mean_q: 32.361517, mean_eps: 0.680725\n",
            " 3656/10000: episode: 131, duration: 0.754s, episode steps:  99, steps per second: 131, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 1.524508, mae: 15.824202, mean_q: 32.462587, mean_eps: 0.675460\n",
            " 3688/10000: episode: 132, duration: 0.257s, episode steps:  32, steps per second: 124, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 1.257749, mae: 15.766830, mean_q: 32.626403, mean_eps: 0.669565\n",
            " 3710/10000: episode: 133, duration: 0.168s, episode steps:  22, steps per second: 131, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.003236, mae: 15.781362, mean_q: 32.581320, mean_eps: 0.667135\n",
            " 3797/10000: episode: 134, duration: 0.697s, episode steps:  87, steps per second: 125, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 1.656780, mae: 16.067587, mean_q: 33.149332, mean_eps: 0.662230\n",
            " 3820/10000: episode: 135, duration: 0.186s, episode steps:  23, steps per second: 124, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 2.339203, mae: 16.061718, mean_q: 33.173741, mean_eps: 0.657280\n",
            " 3837/10000: episode: 136, duration: 0.154s, episode steps:  17, steps per second: 111, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 1.671549, mae: 15.898947, mean_q: 33.259172, mean_eps: 0.655480\n",
            " 3873/10000: episode: 137, duration: 0.288s, episode steps:  36, steps per second: 125, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 1.414222, mae: 16.370687, mean_q: 33.665087, mean_eps: 0.653095\n",
            " 3893/10000: episode: 138, duration: 0.164s, episode steps:  20, steps per second: 122, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 1.671745, mae: 16.240959, mean_q: 33.839116, mean_eps: 0.650575\n",
            " 3934/10000: episode: 139, duration: 0.336s, episode steps:  41, steps per second: 122, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.585 [0.000, 1.000],  loss: 1.562129, mae: 16.458315, mean_q: 34.213169, mean_eps: 0.647830\n",
            " 3960/10000: episode: 140, duration: 0.222s, episode steps:  26, steps per second: 117, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.851842, mae: 16.507575, mean_q: 34.235338, mean_eps: 0.644815\n",
            " 3981/10000: episode: 141, duration: 0.172s, episode steps:  21, steps per second: 122, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 1.129345, mae: 16.831318, mean_q: 34.861579, mean_eps: 0.642700\n",
            " 4039/10000: episode: 142, duration: 0.675s, episode steps:  58, steps per second:  86, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.287007, mae: 16.821285, mean_q: 34.994498, mean_eps: 0.639145\n",
            " 4052/10000: episode: 143, duration: 0.161s, episode steps:  13, steps per second:  81, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.452046, mae: 17.046412, mean_q: 35.192104, mean_eps: 0.635950\n",
            " 4101/10000: episode: 144, duration: 0.583s, episode steps:  49, steps per second:  84, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 1.410350, mae: 16.978872, mean_q: 35.037996, mean_eps: 0.633160\n",
            " 4180/10000: episode: 145, duration: 0.899s, episode steps:  79, steps per second:  88, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.888547, mae: 17.321209, mean_q: 36.092321, mean_eps: 0.627400\n",
            " 4201/10000: episode: 146, duration: 0.262s, episode steps:  21, steps per second:  80, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.623572, mae: 17.314864, mean_q: 36.441867, mean_eps: 0.622900\n",
            " 4237/10000: episode: 147, duration: 0.333s, episode steps:  36, steps per second: 108, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 2.521723, mae: 17.606820, mean_q: 36.851242, mean_eps: 0.620335\n",
            " 4249/10000: episode: 148, duration: 0.097s, episode steps:  12, steps per second: 124, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 2.545662, mae: 17.538844, mean_q: 35.702240, mean_eps: 0.618175\n",
            " 4286/10000: episode: 149, duration: 0.298s, episode steps:  37, steps per second: 124, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 1.627802, mae: 17.608006, mean_q: 36.459095, mean_eps: 0.615970\n",
            " 4310/10000: episode: 150, duration: 0.192s, episode steps:  24, steps per second: 125, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.668560, mae: 18.047322, mean_q: 37.601151, mean_eps: 0.613225\n",
            " 4337/10000: episode: 151, duration: 0.223s, episode steps:  27, steps per second: 121, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 3.278750, mae: 18.006544, mean_q: 37.330096, mean_eps: 0.610930\n",
            " 4358/10000: episode: 152, duration: 0.159s, episode steps:  21, steps per second: 132, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 2.010718, mae: 17.970475, mean_q: 37.026134, mean_eps: 0.608770\n",
            " 4417/10000: episode: 153, duration: 0.458s, episode steps:  59, steps per second: 129, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 2.388532, mae: 18.398367, mean_q: 37.924026, mean_eps: 0.605170\n",
            " 4432/10000: episode: 154, duration: 0.114s, episode steps:  15, steps per second: 132, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 5.223213, mae: 18.564965, mean_q: 38.403883, mean_eps: 0.601840\n",
            " 4465/10000: episode: 155, duration: 0.269s, episode steps:  33, steps per second: 123, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 1.953069, mae: 18.428721, mean_q: 38.207796, mean_eps: 0.599680\n",
            " 4532/10000: episode: 156, duration: 0.533s, episode steps:  67, steps per second: 126, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 1.559588, mae: 18.940127, mean_q: 39.327575, mean_eps: 0.595180\n",
            " 4547/10000: episode: 157, duration: 0.122s, episode steps:  15, steps per second: 123, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.017485, mae: 18.505658, mean_q: 38.791398, mean_eps: 0.591490\n",
            " 4558/10000: episode: 158, duration: 0.103s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.113148, mae: 19.447859, mean_q: 40.349353, mean_eps: 0.590320\n",
            " 4572/10000: episode: 159, duration: 0.121s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 1.963625, mae: 19.021388, mean_q: 39.481458, mean_eps: 0.589195\n",
            " 4593/10000: episode: 160, duration: 0.181s, episode steps:  21, steps per second: 116, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.338321, mae: 18.849214, mean_q: 39.323051, mean_eps: 0.587620\n",
            " 4610/10000: episode: 161, duration: 0.139s, episode steps:  17, steps per second: 122, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 2.874544, mae: 19.277329, mean_q: 39.855972, mean_eps: 0.585910\n",
            " 4627/10000: episode: 162, duration: 0.173s, episode steps:  17, steps per second:  98, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: 1.027331, mae: 19.159786, mean_q: 40.102738, mean_eps: 0.584380\n",
            " 4638/10000: episode: 163, duration: 0.105s, episode steps:  11, steps per second: 105, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 0.828705, mae: 18.818180, mean_q: 40.085588, mean_eps: 0.583120\n",
            " 4650/10000: episode: 164, duration: 0.096s, episode steps:  12, steps per second: 126, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 1.026903, mae: 18.936488, mean_q: 39.639628, mean_eps: 0.582085\n",
            " 4685/10000: episode: 165, duration: 0.276s, episode steps:  35, steps per second: 127, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 2.281552, mae: 19.042429, mean_q: 39.874575, mean_eps: 0.579970\n",
            " 4714/10000: episode: 166, duration: 0.231s, episode steps:  29, steps per second: 126, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.941669, mae: 19.543318, mean_q: 40.947266, mean_eps: 0.577090\n",
            " 4752/10000: episode: 167, duration: 0.292s, episode steps:  38, steps per second: 130, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 2.481371, mae: 19.802718, mean_q: 41.332949, mean_eps: 0.574075\n",
            " 4796/10000: episode: 168, duration: 0.349s, episode steps:  44, steps per second: 126, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 2.877283, mae: 19.579317, mean_q: 41.236388, mean_eps: 0.570385\n",
            " 4854/10000: episode: 169, duration: 0.444s, episode steps:  58, steps per second: 131, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 3.014792, mae: 20.002445, mean_q: 41.715952, mean_eps: 0.565795\n",
            " 4866/10000: episode: 170, duration: 0.108s, episode steps:  12, steps per second: 111, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 3.509961, mae: 20.120989, mean_q: 42.339885, mean_eps: 0.562645\n",
            " 4908/10000: episode: 171, duration: 0.343s, episode steps:  42, steps per second: 123, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 3.799675, mae: 20.628573, mean_q: 42.462820, mean_eps: 0.560215\n",
            " 4984/10000: episode: 172, duration: 0.583s, episode steps:  76, steps per second: 130, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 3.641551, mae: 20.653380, mean_q: 43.321837, mean_eps: 0.554905\n",
            " 5026/10000: episode: 173, duration: 0.361s, episode steps:  42, steps per second: 116, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 1.961521, mae: 20.966360, mean_q: 44.347841, mean_eps: 0.549595\n",
            " 5049/10000: episode: 174, duration: 0.183s, episode steps:  23, steps per second: 126, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 2.316994, mae: 21.231176, mean_q: 44.713817, mean_eps: 0.546670\n",
            " 5062/10000: episode: 175, duration: 0.125s, episode steps:  13, steps per second: 104, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 3.813284, mae: 21.380187, mean_q: 44.580031, mean_eps: 0.545050\n",
            " 5116/10000: episode: 176, duration: 0.416s, episode steps:  54, steps per second: 130, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.947655, mae: 21.528122, mean_q: 44.910774, mean_eps: 0.542035\n",
            " 5174/10000: episode: 177, duration: 0.468s, episode steps:  58, steps per second: 124, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 3.311871, mae: 21.357101, mean_q: 45.069652, mean_eps: 0.536995\n",
            " 5209/10000: episode: 178, duration: 0.294s, episode steps:  35, steps per second: 119, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 1.576866, mae: 21.550581, mean_q: 45.573956, mean_eps: 0.532810\n",
            " 5227/10000: episode: 179, duration: 0.146s, episode steps:  18, steps per second: 123, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 3.041407, mae: 21.891866, mean_q: 45.983510, mean_eps: 0.530425\n",
            " 5247/10000: episode: 180, duration: 0.176s, episode steps:  20, steps per second: 114, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 2.134639, mae: 21.453880, mean_q: 45.658933, mean_eps: 0.528715\n",
            " 5270/10000: episode: 181, duration: 0.186s, episode steps:  23, steps per second: 124, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 2.247201, mae: 22.309522, mean_q: 46.581059, mean_eps: 0.526780\n",
            " 5304/10000: episode: 182, duration: 0.291s, episode steps:  34, steps per second: 117, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.913521, mae: 22.019073, mean_q: 45.815860, mean_eps: 0.524215\n",
            " 5326/10000: episode: 183, duration: 0.181s, episode steps:  22, steps per second: 122, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.650033, mae: 22.547511, mean_q: 46.709063, mean_eps: 0.521695\n",
            " 5348/10000: episode: 184, duration: 0.177s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.177451, mae: 23.093877, mean_q: 48.147831, mean_eps: 0.519715\n",
            " 5403/10000: episode: 185, duration: 0.451s, episode steps:  55, steps per second: 122, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 3.344966, mae: 22.807871, mean_q: 47.690364, mean_eps: 0.516250\n",
            " 5486/10000: episode: 186, duration: 0.840s, episode steps:  83, steps per second:  99, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 2.857011, mae: 22.747816, mean_q: 47.879645, mean_eps: 0.510040\n",
            " 5518/10000: episode: 187, duration: 0.386s, episode steps:  32, steps per second:  83, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.829115, mae: 23.337865, mean_q: 49.116405, mean_eps: 0.504865\n",
            " 5528/10000: episode: 188, duration: 0.117s, episode steps:  10, steps per second:  85, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 6.790232, mae: 22.975326, mean_q: 48.576047, mean_eps: 0.502975\n",
            " 5563/10000: episode: 189, duration: 0.391s, episode steps:  35, steps per second:  90, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 3.634613, mae: 23.820999, mean_q: 49.775613, mean_eps: 0.500950\n",
            " 5626/10000: episode: 190, duration: 1.170s, episode steps:  63, steps per second:  54, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 1.277826, mae: 23.804695, mean_q: 49.962147, mean_eps: 0.496540\n",
            " 5757/10000: episode: 191, duration: 1.399s, episode steps: 131, steps per second:  94, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 3.547871, mae: 24.190589, mean_q: 50.433832, mean_eps: 0.487810\n",
            " 5780/10000: episode: 192, duration: 0.199s, episode steps:  23, steps per second: 115, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 2.994480, mae: 24.632680, mean_q: 51.363124, mean_eps: 0.480880\n",
            " 5805/10000: episode: 193, duration: 0.211s, episode steps:  25, steps per second: 119, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 3.133477, mae: 24.464210, mean_q: 50.947630, mean_eps: 0.478720\n",
            " 5820/10000: episode: 194, duration: 0.127s, episode steps:  15, steps per second: 118, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 7.313745, mae: 24.329923, mean_q: 49.677199, mean_eps: 0.476920\n",
            " 5838/10000: episode: 195, duration: 0.152s, episode steps:  18, steps per second: 119, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 2.999659, mae: 24.144532, mean_q: 50.642394, mean_eps: 0.475435\n",
            " 5925/10000: episode: 196, duration: 0.699s, episode steps:  87, steps per second: 125, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 2.323481, mae: 24.223832, mean_q: 51.103525, mean_eps: 0.470710\n",
            " 5946/10000: episode: 197, duration: 0.168s, episode steps:  21, steps per second: 125, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 1.628114, mae: 24.748384, mean_q: 52.302839, mean_eps: 0.465850\n",
            " 6071/10000: episode: 198, duration: 0.976s, episode steps: 125, steps per second: 128, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 3.384841, mae: 25.203735, mean_q: 53.122378, mean_eps: 0.459280\n",
            " 6254/10000: episode: 199, duration: 1.613s, episode steps: 183, steps per second: 113, episode reward: 183.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 2.620121, mae: 25.031454, mean_q: 52.898709, mean_eps: 0.445420\n",
            " 6284/10000: episode: 200, duration: 0.371s, episode steps:  30, steps per second:  81, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.811519, mae: 25.681290, mean_q: 54.726580, mean_eps: 0.435835\n",
            " 6301/10000: episode: 201, duration: 0.153s, episode steps:  17, steps per second: 111, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 4.961923, mae: 26.258425, mean_q: 55.505524, mean_eps: 0.433720\n",
            " 6358/10000: episode: 202, duration: 0.724s, episode steps:  57, steps per second:  79, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 2.589351, mae: 26.130570, mean_q: 54.894506, mean_eps: 0.430390\n",
            " 6381/10000: episode: 203, duration: 0.294s, episode steps:  23, steps per second:  78, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 2.014124, mae: 26.036670, mean_q: 55.214446, mean_eps: 0.426790\n",
            " 6414/10000: episode: 204, duration: 0.318s, episode steps:  33, steps per second: 104, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 3.081478, mae: 26.275281, mean_q: 55.601742, mean_eps: 0.424270\n",
            " 6519/10000: episode: 205, duration: 0.932s, episode steps: 105, steps per second: 113, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 2.006675, mae: 26.465302, mean_q: 56.152333, mean_eps: 0.418060\n",
            " 6627/10000: episode: 206, duration: 0.843s, episode steps: 108, steps per second: 128, episode reward: 108.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 2.583599, mae: 26.880952, mean_q: 56.506235, mean_eps: 0.408475\n",
            " 6795/10000: episode: 207, duration: 2.149s, episode steps: 168, steps per second:  78, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 2.803300, mae: 27.538200, mean_q: 57.944381, mean_eps: 0.396055\n",
            " 6811/10000: episode: 208, duration: 0.440s, episode steps:  16, steps per second:  36, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.478099, mae: 26.825230, mean_q: 56.635403, mean_eps: 0.387775\n",
            " 6827/10000: episode: 209, duration: 0.355s, episode steps:  16, steps per second:  45, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 4.113309, mae: 26.802680, mean_q: 57.019927, mean_eps: 0.386335\n",
            " 7019/10000: episode: 210, duration: 2.871s, episode steps: 192, steps per second:  67, episode reward: 192.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.843980, mae: 27.823840, mean_q: 58.787482, mean_eps: 0.376975\n",
            " 7034/10000: episode: 211, duration: 0.127s, episode steps:  15, steps per second: 118, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 3.348034, mae: 27.992650, mean_q: 59.447720, mean_eps: 0.367660\n",
            " 7049/10000: episode: 212, duration: 0.155s, episode steps:  15, steps per second:  97, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 2.230383, mae: 27.532534, mean_q: 57.889305, mean_eps: 0.366310\n",
            " 7063/10000: episode: 213, duration: 0.171s, episode steps:  14, steps per second:  82, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 2.056693, mae: 28.119398, mean_q: 59.438974, mean_eps: 0.365005\n",
            " 7076/10000: episode: 214, duration: 0.212s, episode steps:  13, steps per second:  61, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 2.665129, mae: 27.829635, mean_q: 59.016145, mean_eps: 0.363790\n",
            " 7099/10000: episode: 215, duration: 0.222s, episode steps:  23, steps per second: 103, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 1.443649, mae: 27.933925, mean_q: 58.925422, mean_eps: 0.362170\n",
            " 7143/10000: episode: 216, duration: 0.373s, episode steps:  44, steps per second: 118, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 1.143302, mae: 28.360152, mean_q: 59.820694, mean_eps: 0.359155\n",
            " 7186/10000: episode: 217, duration: 0.352s, episode steps:  43, steps per second: 122, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 1.786519, mae: 28.328316, mean_q: 59.388190, mean_eps: 0.355240\n",
            " 7343/10000: episode: 218, duration: 1.274s, episode steps: 157, steps per second: 123, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 4.085157, mae: 28.666716, mean_q: 60.058525, mean_eps: 0.346240\n",
            " 7362/10000: episode: 219, duration: 0.304s, episode steps:  19, steps per second:  63, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 1.851891, mae: 28.489091, mean_q: 59.777644, mean_eps: 0.338320\n",
            " 7385/10000: episode: 220, duration: 0.332s, episode steps:  23, steps per second:  69, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 2.608315, mae: 28.709675, mean_q: 60.655943, mean_eps: 0.336430\n",
            " 7523/10000: episode: 221, duration: 1.241s, episode steps: 138, steps per second: 111, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 3.619406, mae: 29.018423, mean_q: 60.128995, mean_eps: 0.329185\n",
            " 7650/10000: episode: 222, duration: 1.150s, episode steps: 127, steps per second: 110, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 2.669165, mae: 28.809142, mean_q: 60.020334, mean_eps: 0.317260\n",
            " 7664/10000: episode: 223, duration: 0.112s, episode steps:  14, steps per second: 125, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 4.966676, mae: 28.539553, mean_q: 59.626531, mean_eps: 0.310915\n",
            " 7806/10000: episode: 224, duration: 1.117s, episode steps: 142, steps per second: 127, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 2.367113, mae: 28.699584, mean_q: 59.964753, mean_eps: 0.303895\n",
            " 7831/10000: episode: 225, duration: 0.227s, episode steps:  25, steps per second: 110, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 0.779210, mae: 29.336551, mean_q: 61.306514, mean_eps: 0.296380\n",
            " 7961/10000: episode: 226, duration: 1.350s, episode steps: 130, steps per second:  96, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.119980, mae: 28.757610, mean_q: 60.245523, mean_eps: 0.289405\n",
            " 8148/10000: episode: 227, duration: 2.039s, episode steps: 187, steps per second:  92, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 1.112886, mae: 28.890046, mean_q: 60.237335, mean_eps: 0.275140\n",
            " 8277/10000: episode: 228, duration: 1.022s, episode steps: 129, steps per second: 126, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.948040, mae: 28.601612, mean_q: 59.553705, mean_eps: 0.260920\n",
            " 8289/10000: episode: 229, duration: 0.095s, episode steps:  12, steps per second: 126, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.453685, mae: 28.127509, mean_q: 58.106517, mean_eps: 0.254575\n",
            " 8382/10000: episode: 230, duration: 0.734s, episode steps:  93, steps per second: 127, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.567189, mae: 28.817297, mean_q: 60.276042, mean_eps: 0.249850\n",
            " 8491/10000: episode: 231, duration: 0.884s, episode steps: 109, steps per second: 123, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 2.011537, mae: 29.065790, mean_q: 60.285813, mean_eps: 0.240760\n",
            " 8513/10000: episode: 232, duration: 0.177s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.050873, mae: 28.876287, mean_q: 60.041512, mean_eps: 0.234865\n",
            " 8530/10000: episode: 233, duration: 0.141s, episode steps:  17, steps per second: 120, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.366488, mae: 28.333224, mean_q: 59.691370, mean_eps: 0.233110\n",
            " 8552/10000: episode: 234, duration: 0.173s, episode steps:  22, steps per second: 127, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 2.145667, mae: 29.170102, mean_q: 60.963604, mean_eps: 0.231355\n",
            " 8564/10000: episode: 235, duration: 0.105s, episode steps:  12, steps per second: 114, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.900702, mae: 29.190884, mean_q: 61.644750, mean_eps: 0.229825\n",
            " 8686/10000: episode: 236, duration: 0.934s, episode steps: 122, steps per second: 131, episode reward: 122.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 2.012464, mae: 29.399498, mean_q: 60.979637, mean_eps: 0.223795\n",
            " 8810/10000: episode: 237, duration: 0.980s, episode steps: 124, steps per second: 126, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 2.697153, mae: 29.153206, mean_q: 60.831510, mean_eps: 0.212725\n",
            " 8833/10000: episode: 238, duration: 0.197s, episode steps:  23, steps per second: 117, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 3.332736, mae: 29.716127, mean_q: 61.569906, mean_eps: 0.206110\n",
            " 8985/10000: episode: 239, duration: 1.198s, episode steps: 152, steps per second: 127, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.521433, mae: 29.195563, mean_q: 60.512053, mean_eps: 0.198235\n",
            " 9002/10000: episode: 240, duration: 0.134s, episode steps:  17, steps per second: 127, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 1.695036, mae: 29.414767, mean_q: 60.228364, mean_eps: 0.190630\n",
            " 9202/10000: episode: 241, duration: 1.518s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.385788, mae: 28.886076, mean_q: 60.069190, mean_eps: 0.180865\n",
            " 9311/10000: episode: 242, duration: 0.815s, episode steps: 109, steps per second: 134, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.431 [0.000, 1.000],  loss: 3.379400, mae: 29.332011, mean_q: 60.705075, mean_eps: 0.166960\n",
            " 9323/10000: episode: 243, duration: 0.094s, episode steps:  12, steps per second: 127, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 1.426808, mae: 29.113828, mean_q: 60.785002, mean_eps: 0.161515\n",
            " 9344/10000: episode: 244, duration: 0.165s, episode steps:  21, steps per second: 127, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 4.078363, mae: 29.192088, mean_q: 60.684964, mean_eps: 0.160030\n",
            " 9454/10000: episode: 245, duration: 1.160s, episode steps: 110, steps per second:  95, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 2.172207, mae: 29.184487, mean_q: 61.027146, mean_eps: 0.154135\n",
            " 9560/10000: episode: 246, duration: 1.165s, episode steps: 106, steps per second:  91, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 3.209411, mae: 29.399042, mean_q: 61.200256, mean_eps: 0.144415\n",
            " 9688/10000: episode: 247, duration: 1.207s, episode steps: 128, steps per second: 106, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.674476, mae: 29.832435, mean_q: 61.636967, mean_eps: 0.133885\n",
            " 9755/10000: episode: 248, duration: 0.523s, episode steps:  67, steps per second: 128, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.418 [0.000, 1.000],  loss: 2.541991, mae: 29.383810, mean_q: 60.731575, mean_eps: 0.125110\n",
            " 9861/10000: episode: 249, duration: 0.835s, episode steps: 106, steps per second: 127, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 2.795525, mae: 29.905345, mean_q: 62.282687, mean_eps: 0.117325\n",
            " 9965/10000: episode: 250, duration: 0.845s, episode steps: 104, steps per second: 123, episode reward: 104.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 2.075741, mae: 29.864177, mean_q: 62.336316, mean_eps: 0.107875\n",
            "done, took 91.743 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history_1.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "0geZJ9__2CpY",
        "outputId": "4fcda003-2fb8-4b1c-bc12-7456d45efe91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "    dqn.test(env, nb_episodes=20, visualize=False)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gl03c8m2StJ",
        "outputId": "ed6f82e1-0275-4c5d-e2bd-7901621840d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 104.000, steps: 104\n",
            "Episode 2: reward: 104.000, steps: 104\n",
            "Episode 3: reward: 101.000, steps: 101\n",
            "Episode 4: reward: 97.000, steps: 97\n",
            "Episode 5: reward: 100.000, steps: 100\n",
            "Episode 6: reward: 102.000, steps: 102\n",
            "Episode 7: reward: 100.000, steps: 100\n",
            "Episode 8: reward: 103.000, steps: 103\n",
            "Episode 9: reward: 102.000, steps: 102\n",
            "Episode 10: reward: 103.000, steps: 103\n",
            "Episode 11: reward: 103.000, steps: 103\n",
            "Episode 12: reward: 100.000, steps: 100\n",
            "Episode 13: reward: 105.000, steps: 105\n",
            "Episode 14: reward: 98.000, steps: 98\n",
            "Episode 15: reward: 100.000, steps: 100\n",
            "Episode 16: reward: 103.000, steps: 103\n",
            "Episode 17: reward: 99.000, steps: 99\n",
            "Episode 18: reward: 106.000, steps: 106\n",
            "Episode 19: reward: 102.000, steps: 102\n",
            "Episode 20: reward: 100.000, steps: 100\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 100.000, steps: 100\n",
            "Episode 2: reward: 106.000, steps: 106\n",
            "Episode 3: reward: 101.000, steps: 101\n",
            "Episode 4: reward: 102.000, steps: 102\n",
            "Episode 5: reward: 99.000, steps: 99\n",
            "Episode 6: reward: 104.000, steps: 104\n",
            "Episode 7: reward: 104.000, steps: 104\n",
            "Episode 8: reward: 97.000, steps: 97\n",
            "Episode 9: reward: 98.000, steps: 98\n",
            "Episode 10: reward: 100.000, steps: 100\n",
            "Episode 11: reward: 103.000, steps: 103\n",
            "Episode 12: reward: 101.000, steps: 101\n",
            "Episode 13: reward: 106.000, steps: 106\n",
            "Episode 14: reward: 100.000, steps: 100\n",
            "Episode 15: reward: 99.000, steps: 99\n",
            "Episode 16: reward: 104.000, steps: 104\n",
            "Episode 17: reward: 109.000, steps: 109\n",
            "Episode 18: reward: 98.000, steps: 98\n",
            "Episode 19: reward: 99.000, steps: 99\n",
            "Episode 20: reward: 103.000, steps: 103\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 100.000, steps: 100\n",
            "Episode 2: reward: 100.000, steps: 100\n",
            "Episode 3: reward: 100.000, steps: 100\n",
            "Episode 4: reward: 99.000, steps: 99\n",
            "Episode 5: reward: 99.000, steps: 99\n",
            "Episode 6: reward: 102.000, steps: 102\n",
            "Episode 7: reward: 101.000, steps: 101\n",
            "Episode 8: reward: 102.000, steps: 102\n",
            "Episode 9: reward: 104.000, steps: 104\n",
            "Episode 10: reward: 97.000, steps: 97\n",
            "Episode 11: reward: 99.000, steps: 99\n",
            "Episode 12: reward: 94.000, steps: 94\n",
            "Episode 13: reward: 98.000, steps: 98\n",
            "Episode 14: reward: 100.000, steps: 100\n",
            "Episode 15: reward: 98.000, steps: 98\n",
            "Episode 16: reward: 109.000, steps: 109\n",
            "Episode 17: reward: 103.000, steps: 103\n",
            "Episode 18: reward: 105.000, steps: 105\n",
            "Episode 19: reward: 102.000, steps: 102\n",
            "Episode 20: reward: 100.000, steps: 100\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 98.000, steps: 98\n",
            "Episode 2: reward: 100.000, steps: 100\n",
            "Episode 3: reward: 102.000, steps: 102\n",
            "Episode 4: reward: 99.000, steps: 99\n",
            "Episode 5: reward: 96.000, steps: 96\n",
            "Episode 6: reward: 101.000, steps: 101\n",
            "Episode 7: reward: 95.000, steps: 95\n",
            "Episode 8: reward: 101.000, steps: 101\n",
            "Episode 9: reward: 101.000, steps: 101\n",
            "Episode 10: reward: 102.000, steps: 102\n",
            "Episode 11: reward: 101.000, steps: 101\n",
            "Episode 12: reward: 101.000, steps: 101\n",
            "Episode 13: reward: 96.000, steps: 96\n",
            "Episode 14: reward: 99.000, steps: 99\n",
            "Episode 15: reward: 97.000, steps: 97\n",
            "Episode 16: reward: 106.000, steps: 106\n",
            "Episode 17: reward: 100.000, steps: 100\n",
            "Episode 18: reward: 102.000, steps: 102\n",
            "Episode 19: reward: 100.000, steps: 100\n",
            "Episode 20: reward: 98.000, steps: 98\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 99.000, steps: 99\n",
            "Episode 2: reward: 103.000, steps: 103\n",
            "Episode 3: reward: 102.000, steps: 102\n",
            "Episode 4: reward: 97.000, steps: 97\n",
            "Episode 5: reward: 100.000, steps: 100\n",
            "Episode 6: reward: 102.000, steps: 102\n",
            "Episode 7: reward: 101.000, steps: 101\n",
            "Episode 8: reward: 106.000, steps: 106\n",
            "Episode 9: reward: 102.000, steps: 102\n",
            "Episode 10: reward: 98.000, steps: 98\n",
            "Episode 11: reward: 95.000, steps: 95\n",
            "Episode 12: reward: 104.000, steps: 104\n",
            "Episode 13: reward: 101.000, steps: 101\n",
            "Episode 14: reward: 104.000, steps: 104\n",
            "Episode 15: reward: 109.000, steps: 109\n",
            "Episode 16: reward: 99.000, steps: 99\n",
            "Episode 17: reward: 100.000, steps: 100\n",
            "Episode 18: reward: 100.000, steps: 100\n",
            "Episode 19: reward: 98.000, steps: 98\n",
            "Episode 20: reward: 98.000, steps: 98\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 101.000, steps: 101\n",
            "Episode 2: reward: 100.000, steps: 100\n",
            "Episode 3: reward: 102.000, steps: 102\n",
            "Episode 4: reward: 105.000, steps: 105\n",
            "Episode 5: reward: 95.000, steps: 95\n",
            "Episode 6: reward: 104.000, steps: 104\n",
            "Episode 7: reward: 100.000, steps: 100\n",
            "Episode 8: reward: 100.000, steps: 100\n",
            "Episode 9: reward: 98.000, steps: 98\n",
            "Episode 10: reward: 96.000, steps: 96\n",
            "Episode 11: reward: 96.000, steps: 96\n",
            "Episode 12: reward: 101.000, steps: 101\n",
            "Episode 13: reward: 101.000, steps: 101\n",
            "Episode 14: reward: 98.000, steps: 98\n",
            "Episode 15: reward: 100.000, steps: 100\n",
            "Episode 16: reward: 111.000, steps: 111\n",
            "Episode 17: reward: 99.000, steps: 99\n",
            "Episode 18: reward: 100.000, steps: 100\n",
            "Episode 19: reward: 100.000, steps: 100\n",
            "Episode 20: reward: 97.000, steps: 97\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 100.000, steps: 100\n",
            "Episode 2: reward: 100.000, steps: 100\n",
            "Episode 3: reward: 101.000, steps: 101\n",
            "Episode 4: reward: 95.000, steps: 95\n",
            "Episode 5: reward: 101.000, steps: 101\n",
            "Episode 6: reward: 102.000, steps: 102\n",
            "Episode 7: reward: 100.000, steps: 100\n",
            "Episode 8: reward: 98.000, steps: 98\n",
            "Episode 9: reward: 100.000, steps: 100\n",
            "Episode 10: reward: 101.000, steps: 101\n",
            "Episode 11: reward: 103.000, steps: 103\n",
            "Episode 12: reward: 102.000, steps: 102\n",
            "Episode 13: reward: 101.000, steps: 101\n",
            "Episode 14: reward: 98.000, steps: 98\n",
            "Episode 15: reward: 99.000, steps: 99\n",
            "Episode 16: reward: 110.000, steps: 110\n",
            "Episode 17: reward: 98.000, steps: 98\n",
            "Episode 18: reward: 99.000, steps: 99\n",
            "Episode 19: reward: 101.000, steps: 101\n",
            "Episode 20: reward: 96.000, steps: 96\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 98.000, steps: 98\n",
            "Episode 2: reward: 106.000, steps: 106\n",
            "Episode 3: reward: 100.000, steps: 100\n",
            "Episode 4: reward: 98.000, steps: 98\n",
            "Episode 5: reward: 97.000, steps: 97\n",
            "Episode 6: reward: 101.000, steps: 101\n",
            "Episode 7: reward: 99.000, steps: 99\n",
            "Episode 8: reward: 103.000, steps: 103\n",
            "Episode 9: reward: 98.000, steps: 98\n",
            "Episode 10: reward: 99.000, steps: 99\n",
            "Episode 11: reward: 98.000, steps: 98\n",
            "Episode 12: reward: 100.000, steps: 100\n",
            "Episode 13: reward: 106.000, steps: 106\n",
            "Episode 14: reward: 100.000, steps: 100\n",
            "Episode 15: reward: 104.000, steps: 104\n",
            "Episode 16: reward: 105.000, steps: 105\n",
            "Episode 17: reward: 104.000, steps: 104\n",
            "Episode 18: reward: 98.000, steps: 98\n",
            "Episode 19: reward: 103.000, steps: 103\n",
            "Episode 20: reward: 110.000, steps: 110\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 101.000, steps: 101\n",
            "Episode 2: reward: 106.000, steps: 106\n",
            "Episode 3: reward: 97.000, steps: 97\n",
            "Episode 4: reward: 105.000, steps: 105\n",
            "Episode 5: reward: 99.000, steps: 99\n",
            "Episode 6: reward: 103.000, steps: 103\n",
            "Episode 7: reward: 99.000, steps: 99\n",
            "Episode 8: reward: 99.000, steps: 99\n",
            "Episode 9: reward: 103.000, steps: 103\n",
            "Episode 10: reward: 104.000, steps: 104\n",
            "Episode 11: reward: 98.000, steps: 98\n",
            "Episode 12: reward: 107.000, steps: 107\n",
            "Episode 13: reward: 98.000, steps: 98\n",
            "Episode 14: reward: 100.000, steps: 100\n",
            "Episode 15: reward: 100.000, steps: 100\n",
            "Episode 16: reward: 103.000, steps: 103\n",
            "Episode 17: reward: 99.000, steps: 99\n",
            "Episode 18: reward: 100.000, steps: 100\n",
            "Episode 19: reward: 100.000, steps: 100\n",
            "Episode 20: reward: 104.000, steps: 104\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 102.000, steps: 102\n",
            "Episode 2: reward: 100.000, steps: 100\n",
            "Episode 3: reward: 98.000, steps: 98\n",
            "Episode 4: reward: 103.000, steps: 103\n",
            "Episode 5: reward: 101.000, steps: 101\n",
            "Episode 6: reward: 104.000, steps: 104\n",
            "Episode 7: reward: 100.000, steps: 100\n",
            "Episode 8: reward: 101.000, steps: 101\n",
            "Episode 9: reward: 103.000, steps: 103\n",
            "Episode 10: reward: 103.000, steps: 103\n",
            "Episode 11: reward: 103.000, steps: 103\n",
            "Episode 12: reward: 109.000, steps: 109\n",
            "Episode 13: reward: 101.000, steps: 101\n",
            "Episode 14: reward: 97.000, steps: 97\n",
            "Episode 15: reward: 101.000, steps: 101\n",
            "Episode 16: reward: 105.000, steps: 105\n",
            "Episode 17: reward: 102.000, steps: 102\n",
            "Episode 18: reward: 100.000, steps: 100\n",
            "Episode 19: reward: 103.000, steps: 103\n",
            "Episode 20: reward: 101.000, steps: 101\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the above model 1 we can see that those are not near to 200 trying other model with different paramenters"
      ],
      "metadata": {
        "id": "k7AtE3zm2wj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model2"
      ],
      "metadata": {
        "id": "qqkTmIsP3BqL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciRfMJSC2vkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Network\n",
        "model_2 = Sequential()\n",
        "model_2.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(16, activation='relu'))\n",
        "\n",
        "# adds a fully connected layer to the model with 16 units and a ReLU activation function.\n",
        "model_2.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model_2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5dvD8xTio0U",
        "outputId": "07a73d6c-2c9b-465c-c1bc-bf7b1895b71c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ZiiRbxlH2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce21e999-9044-4477-fd6a-8663c7f41cc8"
      },
      "source": [
        "memory = SequentialMemory(limit=2500, window_length=1)\n",
        "\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "\n",
        "# define the agent\n",
        "dqn_1 = DQNAgent(model=model_2, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn_1.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history_2 = dqn_1.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n",
            "   25/10000: episode: 1, duration: 0.188s, episode steps:  25, steps per second: 133, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   43/10000: episode: 2, duration: 0.024s, episode steps:  18, steps per second: 743, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   60/10000: episode: 3, duration: 0.013s, episode steps:  17, steps per second: 1267, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   75/10000: episode: 4, duration: 0.012s, episode steps:  15, steps per second: 1248, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  106/10000: episode: 5, duration: 0.875s, episode steps:  31, steps per second:  35, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.581 [0.000, 1.000],  loss: 31.903622, mae: 23.997589, mean_q: 46.100916, mean_eps: 0.990730\n",
            "  118/10000: episode: 6, duration: 0.089s, episode steps:  12, steps per second: 134, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 26.609778, mae: 23.718660, mean_q: 45.605296, mean_eps: 0.989965\n",
            "  133/10000: episode: 7, duration: 0.119s, episode steps:  15, steps per second: 126, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 37.144606, mae: 23.807058, mean_q: 45.162691, mean_eps: 0.988750\n",
            "  144/10000: episode: 8, duration: 0.099s, episode steps:  11, steps per second: 111, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 37.289199, mae: 23.756157, mean_q: 44.820741, mean_eps: 0.987580\n",
            "  175/10000: episode: 9, duration: 0.271s, episode steps:  31, steps per second: 114, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 30.396630, mae: 23.518427, mean_q: 44.518064, mean_eps: 0.985690\n",
            "  184/10000: episode: 10, duration: 0.074s, episode steps:   9, steps per second: 122, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 45.005457, mae: 23.591642, mean_q: 44.042615, mean_eps: 0.983890\n",
            "  196/10000: episode: 11, duration: 0.101s, episode steps:  12, steps per second: 119, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 39.701457, mae: 23.528409, mean_q: 43.956097, mean_eps: 0.982945\n",
            "  216/10000: episode: 12, duration: 0.176s, episode steps:  20, steps per second: 114, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 45.440142, mae: 23.517942, mean_q: 43.402241, mean_eps: 0.981505\n",
            "  232/10000: episode: 13, duration: 0.140s, episode steps:  16, steps per second: 114, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 33.817547, mae: 23.185749, mean_q: 43.293802, mean_eps: 0.979885\n",
            "  273/10000: episode: 14, duration: 0.316s, episode steps:  41, steps per second: 130, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.390 [0.000, 1.000],  loss: 27.929945, mae: 22.935690, mean_q: 43.426105, mean_eps: 0.977320\n",
            "  284/10000: episode: 15, duration: 0.094s, episode steps:  11, steps per second: 117, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 31.999005, mae: 23.065641, mean_q: 43.456665, mean_eps: 0.974980\n",
            "  302/10000: episode: 16, duration: 0.140s, episode steps:  18, steps per second: 128, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 31.441772, mae: 22.903013, mean_q: 43.148300, mean_eps: 0.973675\n",
            "  329/10000: episode: 17, duration: 0.200s, episode steps:  27, steps per second: 135, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 32.925883, mae: 22.872149, mean_q: 43.027777, mean_eps: 0.971650\n",
            "  342/10000: episode: 18, duration: 0.097s, episode steps:  13, steps per second: 134, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 26.981770, mae: 22.714388, mean_q: 42.932745, mean_eps: 0.969850\n",
            "  365/10000: episode: 19, duration: 0.198s, episode steps:  23, steps per second: 116, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 25.583434, mae: 22.678988, mean_q: 43.133338, mean_eps: 0.968230\n",
            "  388/10000: episode: 20, duration: 0.175s, episode steps:  23, steps per second: 132, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 31.989178, mae: 22.798593, mean_q: 43.222662, mean_eps: 0.966160\n",
            "  402/10000: episode: 21, duration: 0.125s, episode steps:  14, steps per second: 112, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 15.725861, mae: 22.283496, mean_q: 42.941981, mean_eps: 0.964495\n",
            "  414/10000: episode: 22, duration: 0.105s, episode steps:  12, steps per second: 114, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 24.321306, mae: 22.418639, mean_q: 42.864373, mean_eps: 0.963325\n",
            "  442/10000: episode: 23, duration: 0.228s, episode steps:  28, steps per second: 123, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 31.951438, mae: 22.712042, mean_q: 43.082741, mean_eps: 0.961525\n",
            "  467/10000: episode: 24, duration: 0.213s, episode steps:  25, steps per second: 117, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 30.301745, mae: 22.543347, mean_q: 42.809077, mean_eps: 0.959140\n",
            "  479/10000: episode: 25, duration: 0.095s, episode steps:  12, steps per second: 126, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 27.751185, mae: 22.366368, mean_q: 42.580159, mean_eps: 0.957475\n",
            "  498/10000: episode: 26, duration: 0.151s, episode steps:  19, steps per second: 126, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 29.242473, mae: 22.477221, mean_q: 42.561247, mean_eps: 0.956080\n",
            "  517/10000: episode: 27, duration: 0.149s, episode steps:  19, steps per second: 127, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 29.271426, mae: 22.419986, mean_q: 42.553577, mean_eps: 0.954370\n",
            "  550/10000: episode: 28, duration: 0.262s, episode steps:  33, steps per second: 126, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 25.423025, mae: 22.323167, mean_q: 42.486309, mean_eps: 0.952030\n",
            "  583/10000: episode: 29, duration: 0.243s, episode steps:  33, steps per second: 136, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.606 [0.000, 1.000],  loss: 23.877587, mae: 22.278879, mean_q: 42.742556, mean_eps: 0.949060\n",
            "  616/10000: episode: 30, duration: 0.249s, episode steps:  33, steps per second: 133, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.394 [0.000, 1.000],  loss: 19.912926, mae: 22.222646, mean_q: 42.838476, mean_eps: 0.946090\n",
            "  635/10000: episode: 31, duration: 0.158s, episode steps:  19, steps per second: 120, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.263 [0.000, 1.000],  loss: 31.219897, mae: 22.458920, mean_q: 42.844528, mean_eps: 0.943750\n",
            "  654/10000: episode: 32, duration: 0.172s, episode steps:  19, steps per second: 111, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.316 [0.000, 1.000],  loss: 32.293208, mae: 22.344385, mean_q: 42.306294, mean_eps: 0.942040\n",
            "  667/10000: episode: 33, duration: 0.114s, episode steps:  13, steps per second: 114, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 25.136980, mae: 22.262128, mean_q: 42.331980, mean_eps: 0.940600\n",
            "  682/10000: episode: 34, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 16.014705, mae: 21.957782, mean_q: 42.449569, mean_eps: 0.939340\n",
            "  702/10000: episode: 35, duration: 0.165s, episode steps:  20, steps per second: 121, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 23.483450, mae: 22.113161, mean_q: 42.327053, mean_eps: 0.937765\n",
            "  716/10000: episode: 36, duration: 0.125s, episode steps:  14, steps per second: 112, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 39.684906, mae: 22.348002, mean_q: 41.812944, mean_eps: 0.936235\n",
            "  743/10000: episode: 37, duration: 0.252s, episode steps:  27, steps per second: 107, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 21.867848, mae: 22.070370, mean_q: 42.283369, mean_eps: 0.934390\n",
            "  783/10000: episode: 38, duration: 0.308s, episode steps:  40, steps per second: 130, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 26.089070, mae: 22.037273, mean_q: 42.098783, mean_eps: 0.931375\n",
            "  795/10000: episode: 39, duration: 0.115s, episode steps:  12, steps per second: 104, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 21.517736, mae: 21.933063, mean_q: 42.070586, mean_eps: 0.929035\n",
            "  812/10000: episode: 40, duration: 0.132s, episode steps:  17, steps per second: 128, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 25.699860, mae: 21.902393, mean_q: 41.742357, mean_eps: 0.927730\n",
            "  824/10000: episode: 41, duration: 0.089s, episode steps:  12, steps per second: 136, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 28.463860, mae: 21.869399, mean_q: 41.560236, mean_eps: 0.926425\n",
            "  844/10000: episode: 42, duration: 0.159s, episode steps:  20, steps per second: 126, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 20.801372, mae: 21.904986, mean_q: 42.133927, mean_eps: 0.924985\n",
            "  858/10000: episode: 43, duration: 0.112s, episode steps:  14, steps per second: 125, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.786 [0.000, 1.000],  loss: 21.978881, mae: 21.860448, mean_q: 41.934478, mean_eps: 0.923455\n",
            "  911/10000: episode: 44, duration: 0.389s, episode steps:  53, steps per second: 136, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 20.869084, mae: 21.849484, mean_q: 42.046280, mean_eps: 0.920440\n",
            "  922/10000: episode: 45, duration: 0.100s, episode steps:  11, steps per second: 110, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 25.020315, mae: 21.796224, mean_q: 41.905230, mean_eps: 0.917560\n",
            "  938/10000: episode: 46, duration: 0.130s, episode steps:  16, steps per second: 123, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 21.369727, mae: 21.771834, mean_q: 41.777246, mean_eps: 0.916345\n",
            "  983/10000: episode: 47, duration: 0.447s, episode steps:  45, steps per second: 101, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 23.510654, mae: 21.764533, mean_q: 41.689122, mean_eps: 0.913600\n",
            " 1051/10000: episode: 48, duration: 0.749s, episode steps:  68, steps per second:  91, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 20.046863, mae: 21.655374, mean_q: 41.807455, mean_eps: 0.908515\n",
            " 1069/10000: episode: 49, duration: 0.208s, episode steps:  18, steps per second:  86, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 13.230495, mae: 21.444875, mean_q: 41.816182, mean_eps: 0.904645\n",
            " 1102/10000: episode: 50, duration: 0.339s, episode steps:  33, steps per second:  97, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 23.657160, mae: 21.675466, mean_q: 41.621045, mean_eps: 0.902350\n",
            " 1156/10000: episode: 51, duration: 0.601s, episode steps:  54, steps per second:  90, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 22.347982, mae: 21.650706, mean_q: 41.558236, mean_eps: 0.898435\n",
            " 1172/10000: episode: 52, duration: 0.184s, episode steps:  16, steps per second:  87, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 18.738621, mae: 21.587517, mean_q: 41.859508, mean_eps: 0.895285\n",
            " 1193/10000: episode: 53, duration: 0.225s, episode steps:  21, steps per second:  93, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 15.717636, mae: 21.517127, mean_q: 41.832966, mean_eps: 0.893620\n",
            " 1229/10000: episode: 54, duration: 0.283s, episode steps:  36, steps per second: 127, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 21.715071, mae: 21.582631, mean_q: 41.685366, mean_eps: 0.891055\n",
            " 1262/10000: episode: 55, duration: 0.244s, episode steps:  33, steps per second: 135, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 20.048556, mae: 21.504159, mean_q: 41.424955, mean_eps: 0.887950\n",
            " 1282/10000: episode: 56, duration: 0.149s, episode steps:  20, steps per second: 134, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.951631, mae: 21.577780, mean_q: 41.772888, mean_eps: 0.885565\n",
            " 1336/10000: episode: 57, duration: 0.422s, episode steps:  54, steps per second: 128, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 22.169382, mae: 21.493662, mean_q: 41.427668, mean_eps: 0.882235\n",
            " 1354/10000: episode: 58, duration: 0.144s, episode steps:  18, steps per second: 125, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 21.414382, mae: 21.515701, mean_q: 41.448161, mean_eps: 0.878995\n",
            " 1406/10000: episode: 59, duration: 0.385s, episode steps:  52, steps per second: 135, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.442 [0.000, 1.000],  loss: 19.497289, mae: 21.432000, mean_q: 41.393323, mean_eps: 0.875845\n",
            " 1424/10000: episode: 60, duration: 0.130s, episode steps:  18, steps per second: 139, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 23.090819, mae: 21.281407, mean_q: 41.089572, mean_eps: 0.872695\n",
            " 1457/10000: episode: 61, duration: 0.253s, episode steps:  33, steps per second: 131, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 20.591271, mae: 21.388160, mean_q: 41.391610, mean_eps: 0.870400\n",
            " 1474/10000: episode: 62, duration: 0.137s, episode steps:  17, steps per second: 124, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 20.445362, mae: 21.262975, mean_q: 41.183607, mean_eps: 0.868150\n",
            " 1530/10000: episode: 63, duration: 0.433s, episode steps:  56, steps per second: 129, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 21.650264, mae: 21.343756, mean_q: 41.029726, mean_eps: 0.864865\n",
            " 1553/10000: episode: 64, duration: 0.190s, episode steps:  23, steps per second: 121, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 13.160217, mae: 21.041836, mean_q: 41.016169, mean_eps: 0.861310\n",
            " 1585/10000: episode: 65, duration: 0.256s, episode steps:  32, steps per second: 125, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 12.393769, mae: 21.242206, mean_q: 41.479728, mean_eps: 0.858835\n",
            " 1609/10000: episode: 66, duration: 0.189s, episode steps:  24, steps per second: 127, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.803458, mae: 21.233440, mean_q: 41.390291, mean_eps: 0.856315\n",
            " 1631/10000: episode: 67, duration: 0.182s, episode steps:  22, steps per second: 121, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 20.694859, mae: 21.300129, mean_q: 41.232963, mean_eps: 0.854245\n",
            " 1768/10000: episode: 68, duration: 1.016s, episode steps: 137, steps per second: 135, episode reward: 137.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 17.715927, mae: 21.278249, mean_q: 41.335557, mean_eps: 0.847090\n",
            " 1794/10000: episode: 69, duration: 0.214s, episode steps:  26, steps per second: 122, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 12.817691, mae: 21.240643, mean_q: 41.535165, mean_eps: 0.839755\n",
            " 1812/10000: episode: 70, duration: 0.144s, episode steps:  18, steps per second: 125, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 18.857012, mae: 21.498516, mean_q: 41.654012, mean_eps: 0.837775\n",
            " 1833/10000: episode: 71, duration: 0.193s, episode steps:  21, steps per second: 109, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 14.785244, mae: 21.222713, mean_q: 41.447148, mean_eps: 0.836020\n",
            " 1851/10000: episode: 72, duration: 0.176s, episode steps:  18, steps per second: 102, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 15.292558, mae: 21.255715, mean_q: 41.472125, mean_eps: 0.834265\n",
            " 1865/10000: episode: 73, duration: 0.131s, episode steps:  14, steps per second: 107, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 10.344329, mae: 21.354871, mean_q: 41.963987, mean_eps: 0.832825\n",
            " 2007/10000: episode: 74, duration: 1.203s, episode steps: 142, steps per second: 118, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 18.649407, mae: 21.344799, mean_q: 41.395452, mean_eps: 0.825805\n",
            " 2021/10000: episode: 75, duration: 0.109s, episode steps:  14, steps per second: 128, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 15.632333, mae: 21.184227, mean_q: 41.185008, mean_eps: 0.818785\n",
            " 2034/10000: episode: 76, duration: 0.108s, episode steps:  13, steps per second: 121, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 15.421269, mae: 21.175336, mean_q: 41.281190, mean_eps: 0.817570\n",
            " 2067/10000: episode: 77, duration: 0.275s, episode steps:  33, steps per second: 120, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 17.052307, mae: 21.380856, mean_q: 41.736844, mean_eps: 0.815500\n",
            " 2150/10000: episode: 78, duration: 0.634s, episode steps:  83, steps per second: 131, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 15.037055, mae: 21.337771, mean_q: 41.765339, mean_eps: 0.810280\n",
            " 2233/10000: episode: 79, duration: 0.618s, episode steps:  83, steps per second: 134, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 16.898558, mae: 21.407199, mean_q: 41.675312, mean_eps: 0.802810\n",
            " 2253/10000: episode: 80, duration: 0.155s, episode steps:  20, steps per second: 129, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 9.558285, mae: 21.159544, mean_q: 41.714517, mean_eps: 0.798175\n",
            " 2288/10000: episode: 81, duration: 0.280s, episode steps:  35, steps per second: 125, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 13.253277, mae: 21.409568, mean_q: 42.133935, mean_eps: 0.795700\n",
            " 2310/10000: episode: 82, duration: 0.168s, episode steps:  22, steps per second: 131, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 18.276396, mae: 21.566478, mean_q: 42.197379, mean_eps: 0.793135\n",
            " 2386/10000: episode: 83, duration: 0.569s, episode steps:  76, steps per second: 134, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 14.431150, mae: 21.557288, mean_q: 42.351604, mean_eps: 0.788725\n",
            " 2426/10000: episode: 84, duration: 0.301s, episode steps:  40, steps per second: 133, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 17.874182, mae: 21.701130, mean_q: 42.405007, mean_eps: 0.783505\n",
            " 2458/10000: episode: 85, duration: 0.247s, episode steps:  32, steps per second: 130, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.954475, mae: 21.611252, mean_q: 42.501844, mean_eps: 0.780265\n",
            " 2506/10000: episode: 86, duration: 0.544s, episode steps:  48, steps per second:  88, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 21.959741, mae: 21.920840, mean_q: 42.642815, mean_eps: 0.776665\n",
            " 2589/10000: episode: 87, duration: 1.028s, episode steps:  83, steps per second:  81, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 14.696379, mae: 21.720259, mean_q: 42.645744, mean_eps: 0.770770\n",
            " 2692/10000: episode: 88, duration: 1.242s, episode steps: 103, steps per second:  83, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 14.957975, mae: 21.953880, mean_q: 43.081343, mean_eps: 0.762400\n",
            " 2713/10000: episode: 89, duration: 0.225s, episode steps:  21, steps per second:  93, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 18.305796, mae: 21.888679, mean_q: 42.933983, mean_eps: 0.756820\n",
            " 2777/10000: episode: 90, duration: 0.613s, episode steps:  64, steps per second: 104, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.117098, mae: 22.073551, mean_q: 43.453292, mean_eps: 0.752995\n",
            " 2816/10000: episode: 91, duration: 0.313s, episode steps:  39, steps per second: 125, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 14.612638, mae: 22.236994, mean_q: 43.721567, mean_eps: 0.748360\n",
            " 2846/10000: episode: 92, duration: 0.249s, episode steps:  30, steps per second: 121, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.538821, mae: 22.119480, mean_q: 43.907594, mean_eps: 0.745255\n",
            " 2951/10000: episode: 93, duration: 0.917s, episode steps: 105, steps per second: 115, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 13.652209, mae: 22.288736, mean_q: 44.076653, mean_eps: 0.739180\n",
            " 2967/10000: episode: 94, duration: 0.137s, episode steps:  16, steps per second: 117, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 11.690503, mae: 22.293480, mean_q: 44.383401, mean_eps: 0.733735\n",
            " 2999/10000: episode: 95, duration: 0.257s, episode steps:  32, steps per second: 124, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 14.973747, mae: 22.483058, mean_q: 44.444656, mean_eps: 0.731575\n",
            " 3141/10000: episode: 96, duration: 1.053s, episode steps: 142, steps per second: 135, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 15.794576, mae: 22.578093, mean_q: 44.613726, mean_eps: 0.723745\n",
            " 3177/10000: episode: 97, duration: 0.279s, episode steps:  36, steps per second: 129, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 19.660020, mae: 22.788380, mean_q: 44.764221, mean_eps: 0.715735\n",
            " 3304/10000: episode: 98, duration: 0.970s, episode steps: 127, steps per second: 131, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 17.457945, mae: 22.691277, mean_q: 44.665279, mean_eps: 0.708400\n",
            " 3356/10000: episode: 99, duration: 0.445s, episode steps:  52, steps per second: 117, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 14.983650, mae: 22.764924, mean_q: 45.063020, mean_eps: 0.700345\n",
            " 3443/10000: episode: 100, duration: 0.664s, episode steps:  87, steps per second: 131, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 12.279406, mae: 22.813793, mean_q: 45.403733, mean_eps: 0.694090\n",
            " 3505/10000: episode: 101, duration: 0.482s, episode steps:  62, steps per second: 129, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 11.668952, mae: 22.966560, mean_q: 45.780480, mean_eps: 0.687385\n",
            " 3572/10000: episode: 102, duration: 0.584s, episode steps:  67, steps per second: 115, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 13.155394, mae: 23.216560, mean_q: 46.208547, mean_eps: 0.681580\n",
            " 3626/10000: episode: 103, duration: 0.477s, episode steps:  54, steps per second: 113, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.259234, mae: 23.226293, mean_q: 46.359624, mean_eps: 0.676135\n",
            " 3659/10000: episode: 104, duration: 0.299s, episode steps:  33, steps per second: 110, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 16.327598, mae: 23.204015, mean_q: 46.062593, mean_eps: 0.672220\n",
            " 3701/10000: episode: 105, duration: 0.341s, episode steps:  42, steps per second: 123, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 14.398494, mae: 23.267202, mean_q: 46.165726, mean_eps: 0.668845\n",
            " 3728/10000: episode: 106, duration: 0.222s, episode steps:  27, steps per second: 122, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 10.759590, mae: 23.385724, mean_q: 46.622805, mean_eps: 0.665740\n",
            " 3756/10000: episode: 107, duration: 0.234s, episode steps:  28, steps per second: 120, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 9.821789, mae: 23.360188, mean_q: 46.777832, mean_eps: 0.663265\n",
            " 3774/10000: episode: 108, duration: 0.164s, episode steps:  18, steps per second: 110, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 13.885969, mae: 23.532694, mean_q: 46.895351, mean_eps: 0.661195\n",
            " 3833/10000: episode: 109, duration: 0.500s, episode steps:  59, steps per second: 118, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 10.162705, mae: 23.568595, mean_q: 47.174596, mean_eps: 0.657730\n",
            " 3856/10000: episode: 110, duration: 0.218s, episode steps:  23, steps per second: 105, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 13.382431, mae: 23.854330, mean_q: 47.646188, mean_eps: 0.654040\n",
            " 3884/10000: episode: 111, duration: 0.377s, episode steps:  28, steps per second:  74, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 16.969223, mae: 23.989727, mean_q: 47.635221, mean_eps: 0.651745\n",
            " 4063/10000: episode: 112, duration: 2.449s, episode steps: 179, steps per second:  73, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.497 [0.000, 1.000],  loss: 12.908756, mae: 24.062546, mean_q: 47.987200, mean_eps: 0.642430\n",
            " 4210/10000: episode: 113, duration: 1.236s, episode steps: 147, steps per second: 119, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 11.690160, mae: 24.540589, mean_q: 49.147973, mean_eps: 0.627760\n",
            " 4280/10000: episode: 114, duration: 0.601s, episode steps:  70, steps per second: 116, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 14.236299, mae: 24.824287, mean_q: 49.739232, mean_eps: 0.617995\n",
            " 4404/10000: episode: 115, duration: 1.009s, episode steps: 124, steps per second: 123, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 9.169369, mae: 24.988459, mean_q: 50.278007, mean_eps: 0.609265\n",
            " 4445/10000: episode: 116, duration: 0.345s, episode steps:  41, steps per second: 119, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 17.921662, mae: 25.294428, mean_q: 50.505616, mean_eps: 0.601840\n",
            " 4506/10000: episode: 117, duration: 0.468s, episode steps:  61, steps per second: 130, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 14.361786, mae: 25.470528, mean_q: 50.931229, mean_eps: 0.597250\n",
            " 4583/10000: episode: 118, duration: 0.616s, episode steps:  77, steps per second: 125, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 14.165636, mae: 25.626912, mean_q: 51.255234, mean_eps: 0.591040\n",
            " 4737/10000: episode: 119, duration: 1.219s, episode steps: 154, steps per second: 126, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 12.024002, mae: 25.811720, mean_q: 51.788278, mean_eps: 0.580645\n",
            " 4788/10000: episode: 120, duration: 0.410s, episode steps:  51, steps per second: 124, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 14.150190, mae: 26.037230, mean_q: 52.098375, mean_eps: 0.571420\n",
            " 4849/10000: episode: 121, duration: 0.508s, episode steps:  61, steps per second: 120, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 12.897288, mae: 26.102305, mean_q: 52.297866, mean_eps: 0.566380\n",
            " 5006/10000: episode: 122, duration: 1.138s, episode steps: 157, steps per second: 138, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 12.222835, mae: 26.250958, mean_q: 52.692859, mean_eps: 0.556570\n",
            " 5060/10000: episode: 123, duration: 0.422s, episode steps:  54, steps per second: 128, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 10.131434, mae: 26.190126, mean_q: 52.819664, mean_eps: 0.547075\n",
            " 5235/10000: episode: 124, duration: 1.289s, episode steps: 175, steps per second: 136, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 11.567164, mae: 26.658424, mean_q: 53.552016, mean_eps: 0.536770\n",
            " 5416/10000: episode: 125, duration: 1.599s, episode steps: 181, steps per second: 113, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 9.256556, mae: 27.107144, mean_q: 54.585323, mean_eps: 0.520750\n",
            " 5533/10000: episode: 126, duration: 1.248s, episode steps: 117, steps per second:  94, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 14.017452, mae: 27.643843, mean_q: 55.485123, mean_eps: 0.507340\n",
            " 5697/10000: episode: 127, duration: 1.371s, episode steps: 164, steps per second: 120, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 10.096652, mae: 27.939890, mean_q: 56.290321, mean_eps: 0.494695\n",
            " 5767/10000: episode: 128, duration: 0.509s, episode steps:  70, steps per second: 138, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 12.808631, mae: 28.196605, mean_q: 56.540587, mean_eps: 0.484165\n",
            " 5803/10000: episode: 129, duration: 0.298s, episode steps:  36, steps per second: 121, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 7.173296, mae: 28.231588, mean_q: 56.861821, mean_eps: 0.479395\n",
            " 6001/10000: episode: 130, duration: 1.567s, episode steps: 198, steps per second: 126, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.100751, mae: 28.601739, mean_q: 57.487393, mean_eps: 0.468865\n",
            " 6168/10000: episode: 131, duration: 1.303s, episode steps: 167, steps per second: 128, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 12.626953, mae: 28.785011, mean_q: 57.890343, mean_eps: 0.452440\n",
            " 6343/10000: episode: 132, duration: 1.291s, episode steps: 175, steps per second: 136, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 9.336215, mae: 29.074252, mean_q: 58.614221, mean_eps: 0.437050\n",
            " 6543/10000: episode: 133, duration: 1.438s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 10.201544, mae: 29.784141, mean_q: 59.966685, mean_eps: 0.420175\n",
            " 6743/10000: episode: 134, duration: 1.439s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 11.178972, mae: 30.160274, mean_q: 60.765986, mean_eps: 0.402175\n",
            " 6895/10000: episode: 135, duration: 1.089s, episode steps: 152, steps per second: 140, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 13.533881, mae: 30.647025, mean_q: 61.660257, mean_eps: 0.386335\n",
            " 7095/10000: episode: 136, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 13.055142, mae: 31.144404, mean_q: 62.655360, mean_eps: 0.370495\n",
            " 7277/10000: episode: 137, duration: 1.539s, episode steps: 182, steps per second: 118, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 7.415582, mae: 31.520154, mean_q: 63.698316, mean_eps: 0.353305\n",
            " 7476/10000: episode: 138, duration: 1.390s, episode steps: 199, steps per second: 143, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 10.563454, mae: 32.152670, mean_q: 64.876425, mean_eps: 0.336160\n",
            " 7676/10000: episode: 139, duration: 1.467s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 9.587554, mae: 32.739418, mean_q: 66.023897, mean_eps: 0.318205\n",
            " 7876/10000: episode: 140, duration: 1.514s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 10.925459, mae: 33.159414, mean_q: 66.796429, mean_eps: 0.300205\n",
            " 8076/10000: episode: 141, duration: 1.511s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.038448, mae: 33.492138, mean_q: 67.468521, mean_eps: 0.282205\n",
            " 8276/10000: episode: 142, duration: 1.459s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 11.659850, mae: 33.881419, mean_q: 68.205388, mean_eps: 0.264205\n",
            " 8476/10000: episode: 143, duration: 1.545s, episode steps: 200, steps per second: 129, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.873660, mae: 34.189285, mean_q: 68.850941, mean_eps: 0.246205\n",
            " 8676/10000: episode: 144, duration: 1.837s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 8.799209, mae: 34.519167, mean_q: 69.531134, mean_eps: 0.228205\n",
            " 8876/10000: episode: 145, duration: 1.743s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.963271, mae: 34.885206, mean_q: 70.057701, mean_eps: 0.210205\n",
            " 9076/10000: episode: 146, duration: 1.495s, episode steps: 200, steps per second: 134, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.617327, mae: 34.984083, mean_q: 70.287605, mean_eps: 0.192205\n",
            " 9276/10000: episode: 147, duration: 1.698s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 14.599521, mae: 35.213755, mean_q: 70.721704, mean_eps: 0.174205\n",
            " 9476/10000: episode: 148, duration: 2.391s, episode steps: 200, steps per second:  84, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 12.959084, mae: 35.289250, mean_q: 70.875320, mean_eps: 0.156205\n",
            " 9676/10000: episode: 149, duration: 2.473s, episode steps: 200, steps per second:  81, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.356508, mae: 35.427949, mean_q: 71.264116, mean_eps: 0.138205\n",
            " 9876/10000: episode: 150, duration: 2.874s, episode steps: 200, steps per second:  70, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 8.228252, mae: 35.695411, mean_q: 71.821384, mean_eps: 0.120205\n",
            "done, took 86.681 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history_2.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.title(\"Model_2\")\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bkKOscyvlbDf",
        "outputId": "847362e7-5f75-43ee-bc46-a7d959f49af4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "    dqn_1.test(env, nb_episodes=20, visualize=False)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz6cgSfO6sq8",
        "outputId": "d4f9af33-84b5-417e-fdb4-b6efff4f225a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as the reward is 200 for the consucutive 20 eposode but the mae value is 35 try adding more layers so we can get less mean absolute error value"
      ],
      "metadata": {
        "id": "xsQ3_cnr6AKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model_3"
      ],
      "metadata": {
        "id": "4LhdxDjP5fBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model_3.add(Flatten())\n",
        "model_3.add(Dense(16, activation='relu'))\n",
        "#addint the ayers\n",
        "model_3.add(Dense(32, activation='relu'))\n",
        "model_3.add(Flatten())\n",
        "model_3.add(Dense(64, activation='relu'))\n",
        "\n",
        "# adds a fully connected layer to the model with 16 units and a ReLU activation function.\n",
        "model_3.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model_3.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id8d_GKs43L2",
        "outputId": "8c239927-f158-42a8-c977-5b8488fbf979"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,866\n",
            "Trainable params: 2,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=2500, window_length=1)\n",
        "\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "\n",
        "# define the agent\n",
        "dqn_2 = DQNAgent(model=model_2, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn_2.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history_3 = dqn_2.fit(env, nb_steps=10000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6P831Ge6R4v",
        "outputId": "e53b2a52-ed4b-4fe6-f5ce-0b5609cdb74d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   11/10000: episode: 1, duration: 0.326s, episode steps:  11, steps per second:  34, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   29/10000: episode: 2, duration: 0.015s, episode steps:  18, steps per second: 1224, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   53/10000: episode: 3, duration: 0.019s, episode steps:  24, steps per second: 1280, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   93/10000: episode: 4, duration: 0.031s, episode steps:  40, steps per second: 1291, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  123/10000: episode: 5, duration: 1.456s, episode steps:  30, steps per second:  21, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 37.903174, mae: 42.480672, mean_q: 84.152774, mean_eps: 0.989965\n",
            "  136/10000: episode: 6, duration: 0.107s, episode steps:  13, steps per second: 122, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 50.626645, mae: 42.169905, mean_q: 83.695950, mean_eps: 0.988390\n",
            "  148/10000: episode: 7, duration: 0.101s, episode steps:  12, steps per second: 119, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 76.011935, mae: 42.506243, mean_q: 83.477404, mean_eps: 0.987265\n",
            "  180/10000: episode: 8, duration: 0.247s, episode steps:  32, steps per second: 130, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 56.389599, mae: 42.066828, mean_q: 82.418489, mean_eps: 0.985285\n",
            "  205/10000: episode: 9, duration: 0.185s, episode steps:  25, steps per second: 135, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 70.190182, mae: 42.184781, mean_q: 82.345589, mean_eps: 0.982720\n",
            "  220/10000: episode: 10, duration: 0.122s, episode steps:  15, steps per second: 123, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 69.162210, mae: 42.136753, mean_q: 82.223342, mean_eps: 0.980920\n",
            "  238/10000: episode: 11, duration: 0.145s, episode steps:  18, steps per second: 124, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 70.142322, mae: 41.674403, mean_q: 81.918502, mean_eps: 0.979435\n",
            "  256/10000: episode: 12, duration: 0.158s, episode steps:  18, steps per second: 114, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 82.181840, mae: 41.961076, mean_q: 81.492632, mean_eps: 0.977815\n",
            "  270/10000: episode: 13, duration: 0.127s, episode steps:  14, steps per second: 111, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 70.735201, mae: 41.976030, mean_q: 81.542430, mean_eps: 0.976375\n",
            "  299/10000: episode: 14, duration: 0.253s, episode steps:  29, steps per second: 115, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 81.338745, mae: 41.315516, mean_q: 80.699204, mean_eps: 0.974440\n",
            "  346/10000: episode: 15, duration: 0.375s, episode steps:  47, steps per second: 125, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 67.681333, mae: 41.228509, mean_q: 80.602655, mean_eps: 0.971020\n",
            "  361/10000: episode: 16, duration: 0.134s, episode steps:  15, steps per second: 112, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 60.521879, mae: 41.198300, mean_q: 80.879151, mean_eps: 0.968230\n",
            "  373/10000: episode: 17, duration: 0.108s, episode steps:  12, steps per second: 111, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 74.507764, mae: 40.736274, mean_q: 79.364076, mean_eps: 0.967015\n",
            "  406/10000: episode: 18, duration: 0.256s, episode steps:  33, steps per second: 129, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 78.933895, mae: 41.000186, mean_q: 79.663456, mean_eps: 0.964990\n",
            "  421/10000: episode: 19, duration: 0.116s, episode steps:  15, steps per second: 130, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 72.187367, mae: 40.843725, mean_q: 79.537546, mean_eps: 0.962830\n",
            "  443/10000: episode: 20, duration: 0.170s, episode steps:  22, steps per second: 129, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 69.833844, mae: 40.944659, mean_q: 79.704537, mean_eps: 0.961165\n",
            "  472/10000: episode: 21, duration: 0.229s, episode steps:  29, steps per second: 127, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 82.208201, mae: 40.951280, mean_q: 79.658312, mean_eps: 0.958870\n",
            "  492/10000: episode: 22, duration: 0.156s, episode steps:  20, steps per second: 128, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 77.192290, mae: 40.379249, mean_q: 78.424937, mean_eps: 0.956665\n",
            "  507/10000: episode: 23, duration: 0.123s, episode steps:  15, steps per second: 122, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 62.980728, mae: 40.646816, mean_q: 79.665299, mean_eps: 0.955090\n",
            "  529/10000: episode: 24, duration: 0.177s, episode steps:  22, steps per second: 124, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 60.089871, mae: 40.194776, mean_q: 78.839835, mean_eps: 0.953425\n",
            "  543/10000: episode: 25, duration: 0.129s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 51.301610, mae: 40.120418, mean_q: 79.186453, mean_eps: 0.951805\n",
            "  567/10000: episode: 26, duration: 0.189s, episode steps:  24, steps per second: 127, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 65.636990, mae: 40.041918, mean_q: 78.364361, mean_eps: 0.950095\n",
            "  578/10000: episode: 27, duration: 0.093s, episode steps:  11, steps per second: 118, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 71.119994, mae: 40.015345, mean_q: 78.291939, mean_eps: 0.948520\n",
            "  590/10000: episode: 28, duration: 0.094s, episode steps:  12, steps per second: 127, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 69.412043, mae: 39.849462, mean_q: 77.721550, mean_eps: 0.947485\n",
            "  605/10000: episode: 29, duration: 0.133s, episode steps:  15, steps per second: 113, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 82.181670, mae: 40.149691, mean_q: 77.907876, mean_eps: 0.946270\n",
            "  631/10000: episode: 30, duration: 0.213s, episode steps:  26, steps per second: 122, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 73.212065, mae: 39.329163, mean_q: 76.655008, mean_eps: 0.944425\n",
            "  644/10000: episode: 31, duration: 0.110s, episode steps:  13, steps per second: 118, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 55.747631, mae: 39.507290, mean_q: 77.488890, mean_eps: 0.942670\n",
            "  696/10000: episode: 32, duration: 0.431s, episode steps:  52, steps per second: 121, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 68.419193, mae: 39.255650, mean_q: 76.985907, mean_eps: 0.939745\n",
            "  708/10000: episode: 33, duration: 0.098s, episode steps:  12, steps per second: 122, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 55.578182, mae: 38.592533, mean_q: 75.989314, mean_eps: 0.936865\n",
            "  719/10000: episode: 34, duration: 0.086s, episode steps:  11, steps per second: 128, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 36.275301, mae: 38.882423, mean_q: 77.150452, mean_eps: 0.935830\n",
            "  741/10000: episode: 35, duration: 0.193s, episode steps:  22, steps per second: 114, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 52.383527, mae: 39.163953, mean_q: 77.268402, mean_eps: 0.934345\n",
            "  755/10000: episode: 36, duration: 0.120s, episode steps:  14, steps per second: 117, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 61.431070, mae: 38.920440, mean_q: 76.649919, mean_eps: 0.932725\n",
            "  788/10000: episode: 37, duration: 0.262s, episode steps:  33, steps per second: 126, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 54.952218, mae: 39.121669, mean_q: 77.096174, mean_eps: 0.930610\n",
            "  809/10000: episode: 38, duration: 0.157s, episode steps:  21, steps per second: 134, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 65.282910, mae: 39.203955, mean_q: 76.750357, mean_eps: 0.928180\n",
            "  820/10000: episode: 39, duration: 0.094s, episode steps:  11, steps per second: 118, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 56.463218, mae: 39.014390, mean_q: 76.542087, mean_eps: 0.926740\n",
            "  849/10000: episode: 40, duration: 0.226s, episode steps:  29, steps per second: 128, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.621 [0.000, 1.000],  loss: 44.101825, mae: 38.501630, mean_q: 76.076283, mean_eps: 0.924940\n",
            "  873/10000: episode: 41, duration: 0.224s, episode steps:  24, steps per second: 107, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 60.629155, mae: 38.782891, mean_q: 76.306378, mean_eps: 0.922555\n",
            "  889/10000: episode: 42, duration: 0.198s, episode steps:  16, steps per second:  81, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 74.832323, mae: 38.639654, mean_q: 75.374143, mean_eps: 0.920755\n",
            "  921/10000: episode: 43, duration: 0.372s, episode steps:  32, steps per second:  86, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 74.054992, mae: 38.778201, mean_q: 75.485220, mean_eps: 0.918595\n",
            "  931/10000: episode: 44, duration: 0.119s, episode steps:  10, steps per second:  84, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 45.693512, mae: 38.439117, mean_q: 75.612925, mean_eps: 0.916705\n",
            "  967/10000: episode: 45, duration: 0.405s, episode steps:  36, steps per second:  89, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 59.406794, mae: 38.480067, mean_q: 75.375924, mean_eps: 0.914635\n",
            "  993/10000: episode: 46, duration: 0.306s, episode steps:  26, steps per second:  85, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 35.920941, mae: 38.127264, mean_q: 75.688257, mean_eps: 0.911845\n",
            " 1029/10000: episode: 47, duration: 0.401s, episode steps:  36, steps per second:  90, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 57.002200, mae: 38.628308, mean_q: 76.102554, mean_eps: 0.909055\n",
            " 1045/10000: episode: 48, duration: 0.198s, episode steps:  16, steps per second:  81, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 68.987780, mae: 37.798892, mean_q: 74.088158, mean_eps: 0.906715\n",
            " 1064/10000: episode: 49, duration: 0.272s, episode steps:  19, steps per second:  70, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 39.839065, mae: 37.572453, mean_q: 74.584212, mean_eps: 0.905140\n",
            " 1080/10000: episode: 50, duration: 0.200s, episode steps:  16, steps per second:  80, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 57.732027, mae: 38.008756, mean_q: 74.636992, mean_eps: 0.903565\n",
            " 1160/10000: episode: 51, duration: 0.763s, episode steps:  80, steps per second: 105, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 43.066813, mae: 37.931827, mean_q: 75.193183, mean_eps: 0.899245\n",
            " 1195/10000: episode: 52, duration: 0.314s, episode steps:  35, steps per second: 111, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 62.463629, mae: 37.614093, mean_q: 74.034926, mean_eps: 0.894070\n",
            " 1207/10000: episode: 53, duration: 0.107s, episode steps:  12, steps per second: 112, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 39.559903, mae: 37.299103, mean_q: 74.259034, mean_eps: 0.891955\n",
            " 1217/10000: episode: 54, duration: 0.087s, episode steps:  10, steps per second: 115, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 31.607420, mae: 37.361990, mean_q: 74.267101, mean_eps: 0.890965\n",
            " 1257/10000: episode: 55, duration: 0.330s, episode steps:  40, steps per second: 121, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 42.492433, mae: 37.503575, mean_q: 74.657797, mean_eps: 0.888715\n",
            " 1279/10000: episode: 56, duration: 0.182s, episode steps:  22, steps per second: 121, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 65.824469, mae: 37.331894, mean_q: 73.269535, mean_eps: 0.885925\n",
            " 1317/10000: episode: 57, duration: 0.300s, episode steps:  38, steps per second: 127, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 51.039967, mae: 37.435238, mean_q: 73.688213, mean_eps: 0.883225\n",
            " 1371/10000: episode: 58, duration: 0.444s, episode steps:  54, steps per second: 122, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 51.465838, mae: 37.508245, mean_q: 73.796197, mean_eps: 0.879085\n",
            " 1387/10000: episode: 59, duration: 0.139s, episode steps:  16, steps per second: 115, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 51.508707, mae: 37.362673, mean_q: 73.864683, mean_eps: 0.875935\n",
            " 1417/10000: episode: 60, duration: 0.252s, episode steps:  30, steps per second: 119, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 53.556835, mae: 37.154057, mean_q: 73.002536, mean_eps: 0.873865\n",
            " 1430/10000: episode: 61, duration: 0.110s, episode steps:  13, steps per second: 118, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 55.905991, mae: 37.316759, mean_q: 73.364685, mean_eps: 0.871930\n",
            " 1451/10000: episode: 62, duration: 0.168s, episode steps:  21, steps per second: 125, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 32.625777, mae: 37.003773, mean_q: 73.665875, mean_eps: 0.870400\n",
            " 1476/10000: episode: 63, duration: 0.194s, episode steps:  25, steps per second: 129, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 37.743185, mae: 37.258467, mean_q: 74.188100, mean_eps: 0.868330\n",
            " 1523/10000: episode: 64, duration: 0.400s, episode steps:  47, steps per second: 117, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 44.187315, mae: 36.911445, mean_q: 73.153633, mean_eps: 0.865090\n",
            " 1554/10000: episode: 65, duration: 0.236s, episode steps:  31, steps per second: 132, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.581 [0.000, 1.000],  loss: 34.727347, mae: 37.011496, mean_q: 73.618280, mean_eps: 0.861580\n",
            " 1565/10000: episode: 66, duration: 0.093s, episode steps:  11, steps per second: 118, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 34.555804, mae: 36.900369, mean_q: 73.564667, mean_eps: 0.859690\n",
            " 1618/10000: episode: 67, duration: 0.405s, episode steps:  53, steps per second: 131, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 38.576712, mae: 36.879963, mean_q: 73.401172, mean_eps: 0.856810\n",
            " 1644/10000: episode: 68, duration: 0.211s, episode steps:  26, steps per second: 123, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 58.749319, mae: 36.841624, mean_q: 72.654182, mean_eps: 0.853255\n",
            " 1662/10000: episode: 69, duration: 0.144s, episode steps:  18, steps per second: 125, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 45.245231, mae: 36.697555, mean_q: 72.716875, mean_eps: 0.851275\n",
            " 1679/10000: episode: 70, duration: 0.135s, episode steps:  17, steps per second: 126, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 30.542398, mae: 36.590820, mean_q: 72.990535, mean_eps: 0.849700\n",
            " 1774/10000: episode: 71, duration: 0.723s, episode steps:  95, steps per second: 131, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 49.085319, mae: 36.700875, mean_q: 72.729221, mean_eps: 0.844660\n",
            " 1785/10000: episode: 72, duration: 0.097s, episode steps:  11, steps per second: 113, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 32.186892, mae: 36.927748, mean_q: 73.954251, mean_eps: 0.839890\n",
            " 1815/10000: episode: 73, duration: 0.228s, episode steps:  30, steps per second: 132, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 45.634598, mae: 36.970571, mean_q: 73.414979, mean_eps: 0.838045\n",
            " 1833/10000: episode: 74, duration: 0.130s, episode steps:  18, steps per second: 139, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 42.063888, mae: 36.314022, mean_q: 72.241129, mean_eps: 0.835885\n",
            " 1861/10000: episode: 75, duration: 0.216s, episode steps:  28, steps per second: 129, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 33.404860, mae: 36.676636, mean_q: 73.236334, mean_eps: 0.833815\n",
            " 1940/10000: episode: 76, duration: 0.582s, episode steps:  79, steps per second: 136, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 39.799662, mae: 36.650300, mean_q: 72.783439, mean_eps: 0.829000\n",
            " 1977/10000: episode: 77, duration: 0.275s, episode steps:  37, steps per second: 135, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 34.374662, mae: 36.908407, mean_q: 73.759494, mean_eps: 0.823780\n",
            " 2011/10000: episode: 78, duration: 0.255s, episode steps:  34, steps per second: 133, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 39.007952, mae: 37.117962, mean_q: 74.137197, mean_eps: 0.820585\n",
            " 2025/10000: episode: 79, duration: 0.103s, episode steps:  14, steps per second: 136, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 40.921341, mae: 36.458360, mean_q: 72.809855, mean_eps: 0.818425\n",
            " 2134/10000: episode: 80, duration: 0.796s, episode steps: 109, steps per second: 137, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 33.170127, mae: 36.863094, mean_q: 73.898766, mean_eps: 0.812890\n",
            " 2184/10000: episode: 81, duration: 0.388s, episode steps:  50, steps per second: 129, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 30.302417, mae: 37.139682, mean_q: 74.480157, mean_eps: 0.805735\n",
            " 2197/10000: episode: 82, duration: 0.101s, episode steps:  13, steps per second: 128, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 63.596762, mae: 36.717264, mean_q: 72.771981, mean_eps: 0.802900\n",
            " 2225/10000: episode: 83, duration: 0.224s, episode steps:  28, steps per second: 125, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 30.191071, mae: 36.803366, mean_q: 73.739189, mean_eps: 0.801055\n",
            " 2239/10000: episode: 84, duration: 0.112s, episode steps:  14, steps per second: 125, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 44.121760, mae: 37.270069, mean_q: 74.178022, mean_eps: 0.799165\n",
            " 2296/10000: episode: 85, duration: 0.443s, episode steps:  57, steps per second: 129, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 32.208283, mae: 36.911060, mean_q: 74.078252, mean_eps: 0.795970\n",
            " 2329/10000: episode: 86, duration: 0.269s, episode steps:  33, steps per second: 123, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 39.343525, mae: 37.121877, mean_q: 74.450997, mean_eps: 0.791920\n",
            " 2366/10000: episode: 87, duration: 0.354s, episode steps:  37, steps per second: 105, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 46.048846, mae: 37.543060, mean_q: 75.100370, mean_eps: 0.788770\n",
            " 2402/10000: episode: 88, duration: 0.404s, episode steps:  36, steps per second:  89, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 44.784488, mae: 37.369771, mean_q: 74.328486, mean_eps: 0.785485\n",
            " 2431/10000: episode: 89, duration: 0.331s, episode steps:  29, steps per second:  88, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 35.962696, mae: 36.949918, mean_q: 74.006591, mean_eps: 0.782560\n",
            " 2472/10000: episode: 90, duration: 0.486s, episode steps:  41, steps per second:  84, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 41.358551, mae: 37.037301, mean_q: 74.316725, mean_eps: 0.779410\n",
            " 2484/10000: episode: 91, duration: 0.135s, episode steps:  12, steps per second:  89, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 31.547396, mae: 36.959488, mean_q: 74.257045, mean_eps: 0.777025\n",
            " 2504/10000: episode: 92, duration: 0.252s, episode steps:  20, steps per second:  79, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 34.594344, mae: 37.239504, mean_q: 75.239232, mean_eps: 0.775585\n",
            " 2545/10000: episode: 93, duration: 0.474s, episode steps:  41, steps per second:  87, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 33.913716, mae: 37.115545, mean_q: 74.788298, mean_eps: 0.772840\n",
            " 2560/10000: episode: 94, duration: 0.186s, episode steps:  15, steps per second:  81, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 18.191447, mae: 37.488995, mean_q: 75.941467, mean_eps: 0.770320\n",
            " 2658/10000: episode: 95, duration: 0.816s, episode steps:  98, steps per second: 120, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 36.963164, mae: 37.447495, mean_q: 75.449015, mean_eps: 0.765235\n",
            " 2679/10000: episode: 96, duration: 0.158s, episode steps:  21, steps per second: 133, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 48.609667, mae: 37.194279, mean_q: 74.663140, mean_eps: 0.759880\n",
            " 2718/10000: episode: 97, duration: 0.313s, episode steps:  39, steps per second: 124, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 33.549881, mae: 37.641199, mean_q: 75.759915, mean_eps: 0.757180\n",
            " 2770/10000: episode: 98, duration: 0.402s, episode steps:  52, steps per second: 129, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 39.476068, mae: 37.540879, mean_q: 75.573451, mean_eps: 0.753085\n",
            " 2781/10000: episode: 99, duration: 0.090s, episode steps:  11, steps per second: 122, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 27.765557, mae: 37.282747, mean_q: 75.179350, mean_eps: 0.750250\n",
            " 2850/10000: episode: 100, duration: 0.567s, episode steps:  69, steps per second: 122, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 30.550637, mae: 37.537403, mean_q: 76.179455, mean_eps: 0.746650\n",
            " 2883/10000: episode: 101, duration: 0.289s, episode steps:  33, steps per second: 114, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.394 [0.000, 1.000],  loss: 27.668291, mae: 37.892805, mean_q: 76.848694, mean_eps: 0.742060\n",
            " 2985/10000: episode: 102, duration: 0.794s, episode steps: 102, steps per second: 128, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 39.678357, mae: 37.972741, mean_q: 76.632353, mean_eps: 0.735985\n",
            " 2996/10000: episode: 103, duration: 0.086s, episode steps:  11, steps per second: 129, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 47.643396, mae: 38.521362, mean_q: 77.747354, mean_eps: 0.730900\n",
            " 3023/10000: episode: 104, duration: 0.204s, episode steps:  27, steps per second: 132, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 24.026706, mae: 38.351623, mean_q: 77.743585, mean_eps: 0.729190\n",
            " 3084/10000: episode: 105, duration: 0.457s, episode steps:  61, steps per second: 133, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 36.695659, mae: 38.595245, mean_q: 78.214717, mean_eps: 0.725230\n",
            " 3102/10000: episode: 106, duration: 0.135s, episode steps:  18, steps per second: 134, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 42.704452, mae: 39.181701, mean_q: 78.848734, mean_eps: 0.721675\n",
            " 3128/10000: episode: 107, duration: 0.202s, episode steps:  26, steps per second: 129, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 41.004087, mae: 38.388443, mean_q: 77.669484, mean_eps: 0.719695\n",
            " 3169/10000: episode: 108, duration: 0.316s, episode steps:  41, steps per second: 130, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 31.027976, mae: 38.972224, mean_q: 78.867915, mean_eps: 0.716680\n",
            " 3179/10000: episode: 109, duration: 0.080s, episode steps:  10, steps per second: 125, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 26.031864, mae: 38.673207, mean_q: 78.855733, mean_eps: 0.714385\n",
            " 3240/10000: episode: 110, duration: 0.483s, episode steps:  61, steps per second: 126, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 36.833359, mae: 39.226148, mean_q: 79.239891, mean_eps: 0.711190\n",
            " 3337/10000: episode: 111, duration: 0.772s, episode steps:  97, steps per second: 126, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 34.735082, mae: 39.260322, mean_q: 79.372788, mean_eps: 0.704080\n",
            " 3531/10000: episode: 112, duration: 1.462s, episode steps: 194, steps per second: 133, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 32.968721, mae: 39.450568, mean_q: 80.077988, mean_eps: 0.690985\n",
            " 3664/10000: episode: 113, duration: 1.085s, episode steps: 133, steps per second: 123, episode reward: 133.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 32.685180, mae: 39.868942, mean_q: 80.788269, mean_eps: 0.676270\n",
            " 3679/10000: episode: 114, duration: 0.114s, episode steps:  15, steps per second: 132, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 27.197358, mae: 39.330160, mean_q: 80.084712, mean_eps: 0.669610\n",
            " 3691/10000: episode: 115, duration: 0.104s, episode steps:  12, steps per second: 115, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 15.573774, mae: 39.410029, mean_q: 80.523080, mean_eps: 0.668395\n",
            " 3723/10000: episode: 116, duration: 0.240s, episode steps:  32, steps per second: 133, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 17.208256, mae: 40.037275, mean_q: 81.682517, mean_eps: 0.666415\n",
            " 3753/10000: episode: 117, duration: 0.219s, episode steps:  30, steps per second: 137, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 29.597835, mae: 39.509693, mean_q: 80.673885, mean_eps: 0.663625\n",
            " 3874/10000: episode: 118, duration: 0.924s, episode steps: 121, steps per second: 131, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 30.149576, mae: 40.130530, mean_q: 81.417753, mean_eps: 0.656830\n",
            " 3916/10000: episode: 119, duration: 0.449s, episode steps:  42, steps per second:  94, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 35.895270, mae: 40.392411, mean_q: 81.873442, mean_eps: 0.649495\n",
            " 4010/10000: episode: 120, duration: 1.004s, episode steps:  94, steps per second:  94, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 31.265964, mae: 40.332966, mean_q: 81.728995, mean_eps: 0.643375\n",
            " 4157/10000: episode: 121, duration: 1.433s, episode steps: 147, steps per second: 103, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 25.252135, mae: 40.514446, mean_q: 82.380337, mean_eps: 0.632530\n",
            " 4199/10000: episode: 122, duration: 0.310s, episode steps:  42, steps per second: 135, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 30.367657, mae: 40.353354, mean_q: 81.759564, mean_eps: 0.624025\n",
            " 4359/10000: episode: 123, duration: 1.183s, episode steps: 160, steps per second: 135, episode reward: 160.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 24.984728, mae: 40.451695, mean_q: 82.430728, mean_eps: 0.614935\n",
            " 4379/10000: episode: 124, duration: 0.147s, episode steps:  20, steps per second: 136, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 22.967649, mae: 39.765291, mean_q: 81.003979, mean_eps: 0.606835\n",
            " 4401/10000: episode: 125, duration: 0.164s, episode steps:  22, steps per second: 134, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 29.672465, mae: 40.300733, mean_q: 81.990509, mean_eps: 0.604945\n",
            " 4524/10000: episode: 126, duration: 0.903s, episode steps: 123, steps per second: 136, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 31.846402, mae: 40.080710, mean_q: 81.213220, mean_eps: 0.598420\n",
            " 4683/10000: episode: 127, duration: 1.172s, episode steps: 159, steps per second: 136, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 22.928146, mae: 39.782874, mean_q: 80.946501, mean_eps: 0.585730\n",
            " 4743/10000: episode: 128, duration: 0.429s, episode steps:  60, steps per second: 140, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 21.732818, mae: 39.731245, mean_q: 80.916767, mean_eps: 0.575875\n",
            " 4787/10000: episode: 129, duration: 0.341s, episode steps:  44, steps per second: 129, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 31.648813, mae: 39.534391, mean_q: 80.206940, mean_eps: 0.571195\n",
            " 4863/10000: episode: 130, duration: 0.569s, episode steps:  76, steps per second: 133, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 24.598259, mae: 39.989991, mean_q: 81.347388, mean_eps: 0.565795\n",
            " 4885/10000: episode: 131, duration: 0.164s, episode steps:  22, steps per second: 134, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 26.113428, mae: 39.820656, mean_q: 80.987303, mean_eps: 0.561385\n",
            " 4912/10000: episode: 132, duration: 0.232s, episode steps:  27, steps per second: 116, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 26.536442, mae: 40.434556, mean_q: 81.916204, mean_eps: 0.559180\n",
            " 5098/10000: episode: 133, duration: 1.340s, episode steps: 186, steps per second: 139, episode reward: 186.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 25.654171, mae: 40.365600, mean_q: 81.927365, mean_eps: 0.549595\n",
            " 5129/10000: episode: 134, duration: 0.240s, episode steps:  31, steps per second: 129, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 22.735442, mae: 41.398536, mean_q: 83.914187, mean_eps: 0.539830\n",
            " 5190/10000: episode: 135, duration: 0.465s, episode steps:  61, steps per second: 131, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 18.530564, mae: 40.931055, mean_q: 83.149073, mean_eps: 0.535690\n",
            " 5227/10000: episode: 136, duration: 0.281s, episode steps:  37, steps per second: 132, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 19.016873, mae: 41.118569, mean_q: 83.539678, mean_eps: 0.531280\n",
            " 5320/10000: episode: 137, duration: 0.669s, episode steps:  93, steps per second: 139, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 23.862719, mae: 41.307724, mean_q: 83.530454, mean_eps: 0.525430\n",
            " 5347/10000: episode: 138, duration: 0.194s, episode steps:  27, steps per second: 139, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 22.445328, mae: 40.996718, mean_q: 83.086475, mean_eps: 0.520030\n",
            " 5360/10000: episode: 139, duration: 0.105s, episode steps:  13, steps per second: 123, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 18.173921, mae: 40.997525, mean_q: 83.232394, mean_eps: 0.518230\n",
            " 5555/10000: episode: 140, duration: 1.680s, episode steps: 195, steps per second: 116, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 22.687373, mae: 41.385746, mean_q: 83.762868, mean_eps: 0.508870\n",
            " 5650/10000: episode: 141, duration: 0.985s, episode steps:  95, steps per second:  96, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 26.565414, mae: 41.790568, mean_q: 84.505458, mean_eps: 0.495820\n",
            " 5752/10000: episode: 142, duration: 0.973s, episode steps: 102, steps per second: 105, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 13.000681, mae: 42.080222, mean_q: 85.454603, mean_eps: 0.486955\n",
            " 5885/10000: episode: 143, duration: 0.967s, episode steps: 133, steps per second: 138, episode reward: 133.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 16.643333, mae: 42.276351, mean_q: 85.827885, mean_eps: 0.476380\n",
            " 6015/10000: episode: 144, duration: 0.941s, episode steps: 130, steps per second: 138, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.454 [0.000, 1.000],  loss: 22.128506, mae: 42.351272, mean_q: 85.725421, mean_eps: 0.464545\n",
            " 6209/10000: episode: 145, duration: 1.436s, episode steps: 194, steps per second: 135, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 19.460135, mae: 42.637142, mean_q: 86.317204, mean_eps: 0.449965\n",
            " 6258/10000: episode: 146, duration: 0.368s, episode steps:  49, steps per second: 133, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: 32.696674, mae: 42.305350, mean_q: 85.675570, mean_eps: 0.439030\n",
            " 6321/10000: episode: 147, duration: 0.489s, episode steps:  63, steps per second: 129, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 16.010036, mae: 42.711095, mean_q: 86.572438, mean_eps: 0.433990\n",
            " 6340/10000: episode: 148, duration: 0.153s, episode steps:  19, steps per second: 124, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 20.325182, mae: 42.944300, mean_q: 87.003996, mean_eps: 0.430300\n",
            " 6481/10000: episode: 149, duration: 1.041s, episode steps: 141, steps per second: 135, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 22.708524, mae: 42.690838, mean_q: 86.255317, mean_eps: 0.423100\n",
            " 6681/10000: episode: 150, duration: 1.456s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 24.229858, mae: 42.942789, mean_q: 86.765078, mean_eps: 0.407755\n",
            " 6865/10000: episode: 151, duration: 1.349s, episode steps: 184, steps per second: 136, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 19.929002, mae: 43.603108, mean_q: 88.107210, mean_eps: 0.390475\n",
            " 7056/10000: episode: 152, duration: 1.379s, episode steps: 191, steps per second: 138, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 19.291076, mae: 43.479434, mean_q: 87.846827, mean_eps: 0.373600\n",
            " 7231/10000: episode: 153, duration: 1.849s, episode steps: 175, steps per second:  95, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 19.748879, mae: 43.398067, mean_q: 87.656457, mean_eps: 0.357130\n",
            " 7431/10000: episode: 154, duration: 1.705s, episode steps: 200, steps per second: 117, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 17.670669, mae: 43.572052, mean_q: 88.098120, mean_eps: 0.340255\n",
            " 7631/10000: episode: 155, duration: 1.432s, episode steps: 200, steps per second: 140, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 22.231065, mae: 44.215639, mean_q: 89.337580, mean_eps: 0.322255\n",
            " 7811/10000: episode: 156, duration: 1.395s, episode steps: 180, steps per second: 129, episode reward: 180.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 14.546931, mae: 44.690068, mean_q: 90.331500, mean_eps: 0.305155\n",
            " 8011/10000: episode: 157, duration: 1.513s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 17.932549, mae: 43.844792, mean_q: 88.584802, mean_eps: 0.288055\n",
            " 8211/10000: episode: 158, duration: 1.512s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 9.205608, mae: 42.958116, mean_q: 86.959929, mean_eps: 0.270055\n",
            " 8410/10000: episode: 159, duration: 1.470s, episode steps: 199, steps per second: 135, episode reward: 199.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 15.024550, mae: 43.487349, mean_q: 87.855459, mean_eps: 0.252100\n",
            " 8610/10000: episode: 160, duration: 1.458s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 12.658820, mae: 43.309239, mean_q: 87.430803, mean_eps: 0.234145\n",
            " 8810/10000: episode: 161, duration: 2.020s, episode steps: 200, steps per second:  99, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 9.079247, mae: 43.902727, mean_q: 88.766865, mean_eps: 0.216145\n",
            " 9010/10000: episode: 162, duration: 1.804s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.285957, mae: 44.445471, mean_q: 89.806895, mean_eps: 0.198145\n",
            " 9210/10000: episode: 163, duration: 1.498s, episode steps: 200, steps per second: 133, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 14.010483, mae: 44.565391, mean_q: 90.017887, mean_eps: 0.180145\n",
            " 9383/10000: episode: 164, duration: 1.271s, episode steps: 173, steps per second: 136, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 13.334475, mae: 44.592696, mean_q: 90.055485, mean_eps: 0.163360\n",
            " 9583/10000: episode: 165, duration: 1.465s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 12.158153, mae: 44.658619, mean_q: 90.207135, mean_eps: 0.146575\n",
            " 9783/10000: episode: 166, duration: 1.470s, episode steps: 200, steps per second: 136, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 17.777333, mae: 45.188336, mean_q: 91.136892, mean_eps: 0.128575\n",
            " 9983/10000: episode: 167, duration: 1.440s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 11.896283, mae: 45.166654, mean_q: 91.134739, mean_eps: 0.110575\n",
            "done, took 82.000 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history_3.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.title(\"Model_3\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "DredTgeZ6jm3",
        "outputId": "6ad7c25b-b46b-43cb-d390-4fb2f645a7c0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model 3\n",
        "for i in range(0,3):\n",
        "    dqn_2.test(env, nb_episodes=20, visualize=False)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngRU4trZ6Zg_",
        "outputId": "4f364e7e-b7ed-48fb-cd49-6d3d3e49b8f4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 198.000, steps: 198\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 194.000, steps: 194\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 191.000, steps: 191\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model 4"
      ],
      "metadata": {
        "id": "FCVMsFNX8oyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = Sequential()\n",
        "model_4.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model_4.add(Flatten())\n",
        "model_4.add(Dense(10, activation='relu'))\n",
        "#addint the ayers\n",
        "model_4.add(Dense(3, activation='relu'))\n",
        "\n",
        "\n",
        "# adds a fully connected layer to the model with 16 units and a ReLU activation function.\n",
        "model_4.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model_4.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2LtxIjQ6zO7",
        "outputId": "3c3cb7f9-8723-432c-ce98-5e631b57027c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                50        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 3)                 33        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 2)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91\n",
            "Trainable params: 91\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=2500, window_length=1)\n",
        "\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "\n",
        "# define the agent\n",
        "dqn_3 = DQNAgent(model=model_4, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn_3.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history_4 = dqn_3.fit(env, nb_steps=10000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvR9a5VN8yWR",
        "outputId": "28a8dbe9-7a5d-4273-de83-f81bf3b0e6c2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   13/10000: episode: 1, duration: 0.612s, episode steps:  13, steps per second:  21, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   35/10000: episode: 2, duration: 0.030s, episode steps:  22, steps per second: 724, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   54/10000: episode: 3, duration: 0.026s, episode steps:  19, steps per second: 719, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   70/10000: episode: 4, duration: 0.023s, episode steps:  16, steps per second: 692, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   86/10000: episode: 5, duration: 0.021s, episode steps:  16, steps per second: 757, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   99/10000: episode: 6, duration: 0.017s, episode steps:  13, steps per second: 784, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  111/10000: episode: 7, duration: 2.055s, episode steps:  12, steps per second:   6, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 0.529786, mae: 0.530007, mean_q: 0.014715, mean_eps: 0.990505\n",
            "  144/10000: episode: 8, duration: 0.275s, episode steps:  33, steps per second: 120, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.424 [0.000, 1.000],  loss: 0.483798, mae: 0.513084, mean_q: 0.055061, mean_eps: 0.988570\n",
            "  158/10000: episode: 9, duration: 0.115s, episode steps:  14, steps per second: 122, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.419364, mae: 0.505827, mean_q: 0.145953, mean_eps: 0.986455\n",
            "  177/10000: episode: 10, duration: 0.166s, episode steps:  19, steps per second: 115, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.355698, mae: 0.504609, mean_q: 0.275434, mean_eps: 0.984970\n",
            "  204/10000: episode: 11, duration: 0.243s, episode steps:  27, steps per second: 111, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.312784, mae: 0.533369, mean_q: 0.420988, mean_eps: 0.982900\n",
            "  225/10000: episode: 12, duration: 0.189s, episode steps:  21, steps per second: 111, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.273906, mae: 0.568331, mean_q: 0.624869, mean_eps: 0.980740\n",
            "  244/10000: episode: 13, duration: 0.171s, episode steps:  19, steps per second: 111, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 0.282625, mae: 0.647039, mean_q: 0.785498, mean_eps: 0.978940\n",
            "  260/10000: episode: 14, duration: 0.138s, episode steps:  16, steps per second: 116, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.274257, mae: 0.706127, mean_q: 0.956337, mean_eps: 0.977365\n",
            "  291/10000: episode: 15, duration: 0.262s, episode steps:  31, steps per second: 119, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 0.276215, mae: 0.777145, mean_q: 1.137818, mean_eps: 0.975250\n",
            "  312/10000: episode: 16, duration: 0.174s, episode steps:  21, steps per second: 120, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 0.254077, mae: 0.828502, mean_q: 1.333398, mean_eps: 0.972910\n",
            "  349/10000: episode: 17, duration: 0.332s, episode steps:  37, steps per second: 111, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.405 [0.000, 1.000],  loss: 0.230015, mae: 0.910624, mean_q: 1.574100, mean_eps: 0.970300\n",
            "  450/10000: episode: 18, duration: 0.865s, episode steps: 101, steps per second: 117, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 0.190370, mae: 1.183084, mean_q: 2.126523, mean_eps: 0.964090\n",
            "  468/10000: episode: 19, duration: 0.158s, episode steps:  18, steps per second: 114, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 0.190932, mae: 1.443703, mean_q: 2.577449, mean_eps: 0.958735\n",
            "  488/10000: episode: 20, duration: 0.178s, episode steps:  20, steps per second: 113, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.650 [0.000, 1.000],  loss: 0.201842, mae: 1.504069, mean_q: 2.661319, mean_eps: 0.957025\n",
            "  530/10000: episode: 21, duration: 0.384s, episode steps:  42, steps per second: 109, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.147291, mae: 1.591718, mean_q: 2.861666, mean_eps: 0.954235\n",
            "  549/10000: episode: 22, duration: 0.166s, episode steps:  19, steps per second: 114, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 0.180305, mae: 1.736973, mean_q: 3.202770, mean_eps: 0.951490\n",
            "  580/10000: episode: 23, duration: 0.300s, episode steps:  31, steps per second: 103, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 0.189430, mae: 1.818105, mean_q: 3.402071, mean_eps: 0.949240\n",
            "  617/10000: episode: 24, duration: 0.324s, episode steps:  37, steps per second: 114, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 0.207591, mae: 1.911667, mean_q: 3.619242, mean_eps: 0.946180\n",
            "  658/10000: episode: 25, duration: 0.339s, episode steps:  41, steps per second: 121, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 0.196618, mae: 2.042798, mean_q: 3.901939, mean_eps: 0.942670\n",
            "  690/10000: episode: 26, duration: 0.268s, episode steps:  32, steps per second: 119, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 0.194223, mae: 2.174207, mean_q: 4.153911, mean_eps: 0.939385\n",
            "  706/10000: episode: 27, duration: 0.134s, episode steps:  16, steps per second: 119, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.195635, mae: 2.277700, mean_q: 4.339230, mean_eps: 0.937225\n",
            "  741/10000: episode: 28, duration: 0.282s, episode steps:  35, steps per second: 124, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.287731, mae: 2.392706, mean_q: 4.534418, mean_eps: 0.934930\n",
            "  758/10000: episode: 29, duration: 0.153s, episode steps:  17, steps per second: 111, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.647 [0.000, 1.000],  loss: 0.283105, mae: 2.488818, mean_q: 4.771834, mean_eps: 0.932590\n",
            "  778/10000: episode: 30, duration: 0.194s, episode steps:  20, steps per second: 103, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 0.383269, mae: 2.614106, mean_q: 4.938517, mean_eps: 0.930925\n",
            "  797/10000: episode: 31, duration: 0.173s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 0.326311, mae: 2.667874, mean_q: 5.081071, mean_eps: 0.929170\n",
            "  820/10000: episode: 32, duration: 0.208s, episode steps:  23, steps per second: 111, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 0.523079, mae: 2.796440, mean_q: 5.218242, mean_eps: 0.927280\n",
            "  841/10000: episode: 33, duration: 0.208s, episode steps:  21, steps per second: 101, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 0.438405, mae: 2.878274, mean_q: 5.449755, mean_eps: 0.925300\n",
            "  859/10000: episode: 34, duration: 0.205s, episode steps:  18, steps per second:  88, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.351762, mae: 2.930803, mean_q: 5.586069, mean_eps: 0.923545\n",
            "  890/10000: episode: 35, duration: 0.342s, episode steps:  31, steps per second:  91, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 0.490966, mae: 3.049168, mean_q: 5.783846, mean_eps: 0.921340\n",
            "  901/10000: episode: 36, duration: 0.121s, episode steps:  11, steps per second:  91, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.344065, mae: 3.076453, mean_q: 5.893227, mean_eps: 0.919450\n",
            "  921/10000: episode: 37, duration: 0.215s, episode steps:  20, steps per second:  93, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.343521, mae: 3.164795, mean_q: 6.105822, mean_eps: 0.918055\n",
            "  937/10000: episode: 38, duration: 0.155s, episode steps:  16, steps per second: 103, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.512847, mae: 3.266245, mean_q: 6.227563, mean_eps: 0.916435\n",
            "  962/10000: episode: 39, duration: 0.307s, episode steps:  25, steps per second:  81, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 0.617691, mae: 3.347782, mean_q: 6.277313, mean_eps: 0.914590\n",
            "  981/10000: episode: 40, duration: 0.211s, episode steps:  19, steps per second:  90, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 0.605345, mae: 3.420731, mean_q: 6.487226, mean_eps: 0.912610\n",
            "  993/10000: episode: 41, duration: 0.128s, episode steps:  12, steps per second:  94, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.505731, mae: 3.462318, mean_q: 6.626519, mean_eps: 0.911215\n",
            " 1004/10000: episode: 42, duration: 0.132s, episode steps:  11, steps per second:  83, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.476461, mae: 3.520552, mean_q: 6.768222, mean_eps: 0.910180\n",
            " 1017/10000: episode: 43, duration: 0.122s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 0.678476, mae: 3.580718, mean_q: 6.823583, mean_eps: 0.909100\n",
            " 1027/10000: episode: 44, duration: 0.113s, episode steps:  10, steps per second:  88, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.436070, mae: 3.582793, mean_q: 6.883467, mean_eps: 0.908065\n",
            " 1038/10000: episode: 45, duration: 0.130s, episode steps:  11, steps per second:  85, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 0.765067, mae: 3.672765, mean_q: 6.967226, mean_eps: 0.907120\n",
            " 1053/10000: episode: 46, duration: 0.168s, episode steps:  15, steps per second:  89, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.733 [0.000, 1.000],  loss: 0.474341, mae: 3.673377, mean_q: 7.063393, mean_eps: 0.905950\n",
            " 1113/10000: episode: 47, duration: 0.729s, episode steps:  60, steps per second:  82, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.741360, mae: 3.855588, mean_q: 7.292984, mean_eps: 0.902575\n",
            " 1129/10000: episode: 48, duration: 0.236s, episode steps:  16, steps per second:  68, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.824185, mae: 3.992559, mean_q: 7.487793, mean_eps: 0.899155\n",
            " 1145/10000: episode: 49, duration: 0.217s, episode steps:  16, steps per second:  74, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.654847, mae: 4.015628, mean_q: 7.657905, mean_eps: 0.897715\n",
            " 1158/10000: episode: 50, duration: 0.196s, episode steps:  13, steps per second:  66, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.464625, mae: 4.049665, mean_q: 7.781138, mean_eps: 0.896410\n",
            " 1182/10000: episode: 51, duration: 0.302s, episode steps:  24, steps per second:  79, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.771695, mae: 4.135508, mean_q: 7.799404, mean_eps: 0.894745\n",
            " 1199/10000: episode: 52, duration: 0.240s, episode steps:  17, steps per second:  71, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.353 [0.000, 1.000],  loss: 0.659699, mae: 4.204781, mean_q: 8.066231, mean_eps: 0.892900\n",
            " 1242/10000: episode: 53, duration: 0.597s, episode steps:  43, steps per second:  72, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 0.972725, mae: 4.315962, mean_q: 8.089286, mean_eps: 0.890200\n",
            " 1265/10000: episode: 54, duration: 0.348s, episode steps:  23, steps per second:  66, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 0.842511, mae: 4.419069, mean_q: 8.402812, mean_eps: 0.887230\n",
            " 1281/10000: episode: 55, duration: 0.218s, episode steps:  16, steps per second:  73, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.811896, mae: 4.468077, mean_q: 8.411436, mean_eps: 0.885475\n",
            " 1300/10000: episode: 56, duration: 0.183s, episode steps:  19, steps per second: 104, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 0.812899, mae: 4.515810, mean_q: 8.505992, mean_eps: 0.883900\n",
            " 1314/10000: episode: 57, duration: 0.136s, episode steps:  14, steps per second: 103, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.043903, mae: 4.604820, mean_q: 8.623914, mean_eps: 0.882415\n",
            " 1332/10000: episode: 58, duration: 0.162s, episode steps:  18, steps per second: 111, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.043607, mae: 4.636403, mean_q: 8.663771, mean_eps: 0.880975\n",
            " 1347/10000: episode: 59, duration: 0.160s, episode steps:  15, steps per second:  94, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.675808, mae: 4.691884, mean_q: 8.891953, mean_eps: 0.879490\n",
            " 1362/10000: episode: 60, duration: 0.150s, episode steps:  15, steps per second: 100, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.944535, mae: 4.745569, mean_q: 8.937260, mean_eps: 0.878140\n",
            " 1373/10000: episode: 61, duration: 0.106s, episode steps:  11, steps per second: 103, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 1.213261, mae: 4.740547, mean_q: 8.852029, mean_eps: 0.876970\n",
            " 1389/10000: episode: 62, duration: 0.160s, episode steps:  16, steps per second: 100, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 0.696715, mae: 4.751895, mean_q: 9.045352, mean_eps: 0.875755\n",
            " 1405/10000: episode: 63, duration: 0.179s, episode steps:  16, steps per second:  90, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.776280, mae: 4.857363, mean_q: 9.268914, mean_eps: 0.874315\n",
            " 1431/10000: episode: 64, duration: 0.270s, episode steps:  26, steps per second:  96, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.938944, mae: 4.907996, mean_q: 9.254237, mean_eps: 0.872425\n",
            " 1453/10000: episode: 65, duration: 0.214s, episode steps:  22, steps per second: 103, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 0.944033, mae: 5.008739, mean_q: 9.431993, mean_eps: 0.870265\n",
            " 1493/10000: episode: 66, duration: 0.392s, episode steps:  40, steps per second: 102, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 1.106107, mae: 5.098881, mean_q: 9.486368, mean_eps: 0.867475\n",
            " 1504/10000: episode: 67, duration: 0.103s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 1.517740, mae: 5.230005, mean_q: 9.664968, mean_eps: 0.865180\n",
            " 1526/10000: episode: 68, duration: 0.202s, episode steps:  22, steps per second: 109, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 1.107684, mae: 5.193423, mean_q: 9.675469, mean_eps: 0.863695\n",
            " 1555/10000: episode: 69, duration: 0.260s, episode steps:  29, steps per second: 112, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.379 [0.000, 1.000],  loss: 1.013708, mae: 5.236275, mean_q: 9.758139, mean_eps: 0.861400\n",
            " 1564/10000: episode: 70, duration: 0.091s, episode steps:   9, steps per second:  98, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.559707, mae: 5.345472, mean_q: 9.843570, mean_eps: 0.859690\n",
            " 1576/10000: episode: 71, duration: 0.108s, episode steps:  12, steps per second: 112, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.951754, mae: 5.265414, mean_q: 9.884643, mean_eps: 0.858745\n",
            " 1594/10000: episode: 72, duration: 0.181s, episode steps:  18, steps per second:  99, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 1.440382, mae: 5.289361, mean_q: 9.770817, mean_eps: 0.857395\n",
            " 1604/10000: episode: 73, duration: 0.096s, episode steps:  10, steps per second: 104, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 1.465103, mae: 5.306559, mean_q: 9.806783, mean_eps: 0.856135\n",
            " 1644/10000: episode: 74, duration: 0.378s, episode steps:  40, steps per second: 106, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 1.206433, mae: 5.413428, mean_q: 10.014370, mean_eps: 0.853885\n",
            " 1658/10000: episode: 75, duration: 0.163s, episode steps:  14, steps per second:  86, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 1.357640, mae: 5.496495, mean_q: 10.109826, mean_eps: 0.851455\n",
            " 1680/10000: episode: 76, duration: 0.259s, episode steps:  22, steps per second:  85, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 1.124406, mae: 5.514635, mean_q: 10.233553, mean_eps: 0.849835\n",
            " 1695/10000: episode: 77, duration: 0.217s, episode steps:  15, steps per second:  69, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.097283, mae: 5.585317, mean_q: 10.432129, mean_eps: 0.848170\n",
            " 1710/10000: episode: 78, duration: 0.342s, episode steps:  15, steps per second:  44, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 1.350129, mae: 5.632120, mean_q: 10.480222, mean_eps: 0.846820\n",
            " 1720/10000: episode: 79, duration: 0.195s, episode steps:  10, steps per second:  51, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 1.374309, mae: 5.577018, mean_q: 10.291777, mean_eps: 0.845695\n",
            " 1729/10000: episode: 80, duration: 0.156s, episode steps:   9, steps per second:  58, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 0.746551, mae: 5.662632, mean_q: 10.668346, mean_eps: 0.844840\n",
            " 1755/10000: episode: 81, duration: 0.543s, episode steps:  26, steps per second:  48, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 1.168066, mae: 5.727888, mean_q: 10.606859, mean_eps: 0.843265\n",
            " 1799/10000: episode: 82, duration: 0.780s, episode steps:  44, steps per second:  56, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 1.204151, mae: 5.777440, mean_q: 10.687055, mean_eps: 0.840115\n",
            " 1821/10000: episode: 83, duration: 0.456s, episode steps:  22, steps per second:  48, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 1.755006, mae: 5.731487, mean_q: 10.393346, mean_eps: 0.837145\n",
            " 1840/10000: episode: 84, duration: 0.456s, episode steps:  19, steps per second:  42, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.368 [0.000, 1.000],  loss: 1.354546, mae: 5.819189, mean_q: 10.700513, mean_eps: 0.835300\n",
            " 1883/10000: episode: 85, duration: 0.701s, episode steps:  43, steps per second:  61, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 1.234743, mae: 5.902399, mean_q: 10.872724, mean_eps: 0.832510\n",
            " 1941/10000: episode: 86, duration: 1.044s, episode steps:  58, steps per second:  56, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 1.541485, mae: 6.027258, mean_q: 11.021442, mean_eps: 0.827965\n",
            " 1983/10000: episode: 87, duration: 0.373s, episode steps:  42, steps per second: 113, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.381 [0.000, 1.000],  loss: 1.300147, mae: 6.117521, mean_q: 11.245110, mean_eps: 0.823465\n",
            " 2002/10000: episode: 88, duration: 0.184s, episode steps:  19, steps per second: 103, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.247622, mae: 6.196151, mean_q: 11.395299, mean_eps: 0.820720\n",
            " 2021/10000: episode: 89, duration: 0.206s, episode steps:  19, steps per second:  92, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 1.380171, mae: 6.274579, mean_q: 11.513115, mean_eps: 0.819010\n",
            " 2033/10000: episode: 90, duration: 0.110s, episode steps:  12, steps per second: 109, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 2.248304, mae: 6.352236, mean_q: 11.467873, mean_eps: 0.817615\n",
            " 2056/10000: episode: 91, duration: 0.237s, episode steps:  23, steps per second:  97, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 1.313005, mae: 6.273368, mean_q: 11.434564, mean_eps: 0.816040\n",
            " 2075/10000: episode: 92, duration: 0.261s, episode steps:  19, steps per second:  73, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.530578, mae: 6.337510, mean_q: 11.519897, mean_eps: 0.814150\n",
            " 2111/10000: episode: 93, duration: 0.513s, episode steps:  36, steps per second:  70, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.551603, mae: 6.382331, mean_q: 11.634246, mean_eps: 0.811675\n",
            " 2140/10000: episode: 94, duration: 0.414s, episode steps:  29, steps per second:  70, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.414 [0.000, 1.000],  loss: 1.352148, mae: 6.486245, mean_q: 11.823992, mean_eps: 0.808750\n",
            " 2160/10000: episode: 95, duration: 0.270s, episode steps:  20, steps per second:  74, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.402680, mae: 6.546266, mean_q: 11.955730, mean_eps: 0.806545\n",
            " 2173/10000: episode: 96, duration: 0.170s, episode steps:  13, steps per second:  77, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 1.972231, mae: 6.471425, mean_q: 11.716317, mean_eps: 0.805060\n",
            " 2209/10000: episode: 97, duration: 0.494s, episode steps:  36, steps per second:  73, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 1.622808, mae: 6.572002, mean_q: 12.008971, mean_eps: 0.802855\n",
            " 2252/10000: episode: 98, duration: 0.505s, episode steps:  43, steps per second:  85, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 1.740317, mae: 6.624506, mean_q: 12.044615, mean_eps: 0.799300\n",
            " 2268/10000: episode: 99, duration: 0.139s, episode steps:  16, steps per second: 115, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 2.297469, mae: 6.769302, mean_q: 12.230774, mean_eps: 0.796645\n",
            " 2289/10000: episode: 100, duration: 0.183s, episode steps:  21, steps per second: 115, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 1.529502, mae: 6.629773, mean_q: 12.096206, mean_eps: 0.794980\n",
            " 2300/10000: episode: 101, duration: 0.097s, episode steps:  11, steps per second: 113, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 1.317791, mae: 6.712481, mean_q: 12.322306, mean_eps: 0.793540\n",
            " 2316/10000: episode: 102, duration: 0.173s, episode steps:  16, steps per second:  93, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.736453, mae: 6.708496, mean_q: 12.203184, mean_eps: 0.792325\n",
            " 2353/10000: episode: 103, duration: 0.333s, episode steps:  37, steps per second: 111, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 1.502166, mae: 6.721672, mean_q: 12.319826, mean_eps: 0.789940\n",
            " 2379/10000: episode: 104, duration: 0.258s, episode steps:  26, steps per second: 101, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.692138, mae: 6.890709, mean_q: 12.629226, mean_eps: 0.787105\n",
            " 2398/10000: episode: 105, duration: 0.177s, episode steps:  19, steps per second: 108, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 1.582638, mae: 6.897639, mean_q: 12.660557, mean_eps: 0.785080\n",
            " 2449/10000: episode: 106, duration: 0.432s, episode steps:  51, steps per second: 118, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 1.581511, mae: 6.992454, mean_q: 12.910065, mean_eps: 0.781930\n",
            " 2477/10000: episode: 107, duration: 0.249s, episode steps:  28, steps per second: 112, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 1.630112, mae: 7.017052, mean_q: 13.009908, mean_eps: 0.778375\n",
            " 2495/10000: episode: 108, duration: 0.165s, episode steps:  18, steps per second: 109, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 2.106796, mae: 7.036549, mean_q: 12.915029, mean_eps: 0.776305\n",
            " 2552/10000: episode: 109, duration: 0.499s, episode steps:  57, steps per second: 114, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 1.717940, mae: 7.085929, mean_q: 13.170638, mean_eps: 0.772930\n",
            " 2588/10000: episode: 110, duration: 0.295s, episode steps:  36, steps per second: 122, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 1.890451, mae: 7.248674, mean_q: 13.478009, mean_eps: 0.768745\n",
            " 2600/10000: episode: 111, duration: 0.102s, episode steps:  12, steps per second: 117, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 1.389865, mae: 7.316154, mean_q: 13.720187, mean_eps: 0.766585\n",
            " 2632/10000: episode: 112, duration: 0.284s, episode steps:  32, steps per second: 113, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.692086, mae: 7.390297, mean_q: 13.856014, mean_eps: 0.764605\n",
            " 2686/10000: episode: 113, duration: 0.459s, episode steps:  54, steps per second: 118, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 1.492288, mae: 7.505425, mean_q: 14.232498, mean_eps: 0.760735\n",
            " 2718/10000: episode: 114, duration: 0.262s, episode steps:  32, steps per second: 122, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.283861, mae: 7.684826, mean_q: 14.629986, mean_eps: 0.756865\n",
            " 2732/10000: episode: 115, duration: 0.126s, episode steps:  14, steps per second: 111, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 1.367812, mae: 7.576221, mean_q: 14.426198, mean_eps: 0.754795\n",
            " 2760/10000: episode: 116, duration: 0.236s, episode steps:  28, steps per second: 118, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 1.807688, mae: 7.755928, mean_q: 14.719492, mean_eps: 0.752905\n",
            " 2795/10000: episode: 117, duration: 0.306s, episode steps:  35, steps per second: 114, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 2.250819, mae: 7.769073, mean_q: 14.720445, mean_eps: 0.750070\n",
            " 2821/10000: episode: 118, duration: 0.234s, episode steps:  26, steps per second: 111, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.594489, mae: 7.706099, mean_q: 14.738733, mean_eps: 0.747325\n",
            " 2863/10000: episode: 119, duration: 0.365s, episode steps:  42, steps per second: 115, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 2.033787, mae: 7.977517, mean_q: 15.239218, mean_eps: 0.744265\n",
            " 2914/10000: episode: 120, duration: 0.419s, episode steps:  51, steps per second: 122, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.451 [0.000, 1.000],  loss: 1.827253, mae: 7.997039, mean_q: 15.343927, mean_eps: 0.740080\n",
            " 2968/10000: episode: 121, duration: 0.471s, episode steps:  54, steps per second: 115, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.264306, mae: 8.285510, mean_q: 15.913566, mean_eps: 0.735355\n",
            " 2990/10000: episode: 122, duration: 0.182s, episode steps:  22, steps per second: 121, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.973546, mae: 8.311597, mean_q: 15.938525, mean_eps: 0.731935\n",
            " 3012/10000: episode: 123, duration: 0.201s, episode steps:  22, steps per second: 110, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 2.244022, mae: 8.326736, mean_q: 16.054988, mean_eps: 0.729955\n",
            " 3044/10000: episode: 124, duration: 0.303s, episode steps:  32, steps per second: 106, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.435429, mae: 8.524188, mean_q: 16.452293, mean_eps: 0.727525\n",
            " 3067/10000: episode: 125, duration: 0.199s, episode steps:  23, steps per second: 116, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.391 [0.000, 1.000],  loss: 3.122948, mae: 8.533187, mean_q: 16.364781, mean_eps: 0.725050\n",
            " 3106/10000: episode: 126, duration: 0.341s, episode steps:  39, steps per second: 114, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 2.342906, mae: 8.648972, mean_q: 16.716523, mean_eps: 0.722260\n",
            " 3131/10000: episode: 127, duration: 0.230s, episode steps:  25, steps per second: 108, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 2.352891, mae: 8.780513, mean_q: 16.997928, mean_eps: 0.719380\n",
            " 3161/10000: episode: 128, duration: 0.269s, episode steps:  30, steps per second: 111, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 2.169304, mae: 8.910086, mean_q: 17.265746, mean_eps: 0.716905\n",
            " 3202/10000: episode: 129, duration: 0.383s, episode steps:  41, steps per second: 107, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 2.419246, mae: 8.935797, mean_q: 17.291894, mean_eps: 0.713710\n",
            " 3255/10000: episode: 130, duration: 0.444s, episode steps:  53, steps per second: 119, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 2.860602, mae: 9.143995, mean_q: 17.754091, mean_eps: 0.709480\n",
            " 3287/10000: episode: 131, duration: 0.300s, episode steps:  32, steps per second: 107, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.007052, mae: 9.275503, mean_q: 18.171502, mean_eps: 0.705655\n",
            " 3353/10000: episode: 132, duration: 0.530s, episode steps:  66, steps per second: 124, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 2.979118, mae: 9.394554, mean_q: 18.229799, mean_eps: 0.701245\n",
            " 3426/10000: episode: 133, duration: 0.768s, episode steps:  73, steps per second:  95, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 2.794617, mae: 9.634784, mean_q: 18.834724, mean_eps: 0.694990\n",
            " 3493/10000: episode: 134, duration: 0.751s, episode steps:  67, steps per second:  89, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 2.603652, mae: 9.877352, mean_q: 19.343283, mean_eps: 0.688690\n",
            " 3578/10000: episode: 135, duration: 0.968s, episode steps:  85, steps per second:  88, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 3.463193, mae: 10.153791, mean_q: 19.815700, mean_eps: 0.681850\n",
            " 3618/10000: episode: 136, duration: 0.448s, episode steps:  40, steps per second:  89, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 2.595598, mae: 10.387065, mean_q: 20.388745, mean_eps: 0.676225\n",
            " 3675/10000: episode: 137, duration: 0.446s, episode steps:  57, steps per second: 128, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 3.454431, mae: 10.520806, mean_q: 20.486698, mean_eps: 0.671860\n",
            " 3720/10000: episode: 138, duration: 0.376s, episode steps:  45, steps per second: 120, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 3.961519, mae: 10.710643, mean_q: 20.910997, mean_eps: 0.667270\n",
            " 3791/10000: episode: 139, duration: 0.582s, episode steps:  71, steps per second: 122, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 3.583275, mae: 10.800882, mean_q: 21.203983, mean_eps: 0.662050\n",
            " 3820/10000: episode: 140, duration: 0.227s, episode steps:  29, steps per second: 128, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 2.803550, mae: 11.015852, mean_q: 21.851113, mean_eps: 0.657550\n",
            " 3868/10000: episode: 141, duration: 0.399s, episode steps:  48, steps per second: 120, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 3.964727, mae: 11.208825, mean_q: 22.095371, mean_eps: 0.654085\n",
            " 3894/10000: episode: 142, duration: 0.204s, episode steps:  26, steps per second: 127, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 4.443450, mae: 11.364337, mean_q: 22.301560, mean_eps: 0.650755\n",
            " 3960/10000: episode: 143, duration: 0.508s, episode steps:  66, steps per second: 130, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 3.021575, mae: 11.417763, mean_q: 22.598728, mean_eps: 0.646615\n",
            " 3994/10000: episode: 144, duration: 0.280s, episode steps:  34, steps per second: 122, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 3.922254, mae: 11.676915, mean_q: 23.083635, mean_eps: 0.642115\n",
            " 4044/10000: episode: 145, duration: 0.403s, episode steps:  50, steps per second: 124, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 3.617998, mae: 11.840041, mean_q: 23.573490, mean_eps: 0.638335\n",
            " 4140/10000: episode: 146, duration: 0.760s, episode steps:  96, steps per second: 126, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.582886, mae: 12.068300, mean_q: 23.849173, mean_eps: 0.631765\n",
            " 4155/10000: episode: 147, duration: 0.136s, episode steps:  15, steps per second: 110, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 7.289149, mae: 12.372443, mean_q: 24.137476, mean_eps: 0.626770\n",
            " 4205/10000: episode: 148, duration: 0.411s, episode steps:  50, steps per second: 122, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 4.362224, mae: 12.392172, mean_q: 24.476924, mean_eps: 0.623845\n",
            " 4224/10000: episode: 149, duration: 0.159s, episode steps:  19, steps per second: 120, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 5.222906, mae: 12.692048, mean_q: 25.074594, mean_eps: 0.620740\n",
            " 4275/10000: episode: 150, duration: 0.409s, episode steps:  51, steps per second: 125, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.916882, mae: 12.575374, mean_q: 25.009518, mean_eps: 0.617590\n",
            " 4328/10000: episode: 151, duration: 0.447s, episode steps:  53, steps per second: 118, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 5.979234, mae: 12.809135, mean_q: 25.241641, mean_eps: 0.612910\n",
            " 4359/10000: episode: 152, duration: 0.270s, episode steps:  31, steps per second: 115, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 4.060223, mae: 13.010260, mean_q: 25.830096, mean_eps: 0.609130\n",
            " 4408/10000: episode: 153, duration: 0.430s, episode steps:  49, steps per second: 114, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.460368, mae: 13.031292, mean_q: 25.848601, mean_eps: 0.605530\n",
            " 4488/10000: episode: 154, duration: 0.624s, episode steps:  80, steps per second: 128, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.916780, mae: 13.316501, mean_q: 26.235943, mean_eps: 0.599725\n",
            " 4522/10000: episode: 155, duration: 0.292s, episode steps:  34, steps per second: 116, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 6.737910, mae: 13.528922, mean_q: 26.567839, mean_eps: 0.594595\n",
            " 4683/10000: episode: 156, duration: 1.321s, episode steps: 161, steps per second: 122, episode reward: 161.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.503 [0.000, 1.000],  loss: 4.924188, mae: 13.707710, mean_q: 27.238259, mean_eps: 0.585820\n",
            " 4786/10000: episode: 157, duration: 0.816s, episode steps: 103, steps per second: 126, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 4.941516, mae: 14.196788, mean_q: 28.222332, mean_eps: 0.573940\n",
            " 4823/10000: episode: 158, duration: 0.310s, episode steps:  37, steps per second: 119, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 4.043738, mae: 14.394936, mean_q: 28.841726, mean_eps: 0.567640\n",
            " 4862/10000: episode: 159, duration: 0.440s, episode steps:  39, steps per second:  89, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 5.308115, mae: 14.588147, mean_q: 28.991681, mean_eps: 0.564220\n",
            " 4897/10000: episode: 160, duration: 0.452s, episode steps:  35, steps per second:  77, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 5.191211, mae: 14.693355, mean_q: 29.266860, mean_eps: 0.560890\n",
            " 5037/10000: episode: 161, duration: 1.583s, episode steps: 140, steps per second:  88, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 4.614469, mae: 14.957854, mean_q: 29.872429, mean_eps: 0.553015\n",
            " 5048/10000: episode: 162, duration: 0.148s, episode steps:  11, steps per second:  75, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 3.332239, mae: 15.194013, mean_q: 30.535435, mean_eps: 0.546220\n",
            " 5085/10000: episode: 163, duration: 0.304s, episode steps:  37, steps per second: 122, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 3.823111, mae: 15.207947, mean_q: 30.583514, mean_eps: 0.544060\n",
            " 5138/10000: episode: 164, duration: 0.414s, episode steps:  53, steps per second: 128, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 4.923611, mae: 15.471396, mean_q: 30.966237, mean_eps: 0.540010\n",
            " 5156/10000: episode: 165, duration: 0.154s, episode steps:  18, steps per second: 117, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 6.733751, mae: 15.549589, mean_q: 30.996144, mean_eps: 0.536815\n",
            " 5254/10000: episode: 166, duration: 0.746s, episode steps:  98, steps per second: 131, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 4.750330, mae: 15.680102, mean_q: 31.507730, mean_eps: 0.531595\n",
            " 5327/10000: episode: 167, duration: 0.585s, episode steps:  73, steps per second: 125, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 6.215556, mae: 15.995486, mean_q: 31.923346, mean_eps: 0.523900\n",
            " 5407/10000: episode: 168, duration: 0.623s, episode steps:  80, steps per second: 128, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 4.791499, mae: 16.238604, mean_q: 32.635126, mean_eps: 0.517015\n",
            " 5426/10000: episode: 169, duration: 0.161s, episode steps:  19, steps per second: 118, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 4.119062, mae: 16.378724, mean_q: 32.980791, mean_eps: 0.512560\n",
            " 5606/10000: episode: 170, duration: 1.383s, episode steps: 180, steps per second: 130, episode reward: 180.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 5.186571, mae: 16.708839, mean_q: 33.521630, mean_eps: 0.503605\n",
            " 5730/10000: episode: 171, duration: 0.963s, episode steps: 124, steps per second: 129, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 4.954088, mae: 17.121810, mean_q: 34.484309, mean_eps: 0.489925\n",
            " 5870/10000: episode: 172, duration: 1.126s, episode steps: 140, steps per second: 124, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 4.384181, mae: 17.528425, mean_q: 35.372623, mean_eps: 0.478045\n",
            " 5973/10000: episode: 173, duration: 0.847s, episode steps: 103, steps per second: 122, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 4.079531, mae: 17.925738, mean_q: 36.276525, mean_eps: 0.467110\n",
            " 6102/10000: episode: 174, duration: 1.014s, episode steps: 129, steps per second: 127, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 4.377502, mae: 18.230201, mean_q: 36.934199, mean_eps: 0.456670\n",
            " 6254/10000: episode: 175, duration: 1.185s, episode steps: 152, steps per second: 128, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.461 [0.000, 1.000],  loss: 4.369641, mae: 18.722641, mean_q: 37.845193, mean_eps: 0.444025\n",
            " 6427/10000: episode: 176, duration: 1.728s, episode steps: 173, steps per second: 100, episode reward: 173.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 4.471930, mae: 19.146856, mean_q: 38.761513, mean_eps: 0.429400\n",
            " 6577/10000: episode: 177, duration: 1.590s, episode steps: 150, steps per second:  94, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 4.538610, mae: 19.543215, mean_q: 39.462602, mean_eps: 0.414865\n",
            " 6661/10000: episode: 178, duration: 0.681s, episode steps:  84, steps per second: 123, episode reward: 84.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 4.605198, mae: 19.803843, mean_q: 40.009675, mean_eps: 0.404335\n",
            " 6719/10000: episode: 179, duration: 0.460s, episode steps:  58, steps per second: 126, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 3.503632, mae: 20.006393, mean_q: 40.494115, mean_eps: 0.397945\n",
            " 6915/10000: episode: 180, duration: 1.508s, episode steps: 196, steps per second: 130, episode reward: 196.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 4.120458, mae: 20.387906, mean_q: 41.249273, mean_eps: 0.386515\n",
            " 7105/10000: episode: 181, duration: 1.477s, episode steps: 190, steps per second: 129, episode reward: 190.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 3.576154, mae: 20.815288, mean_q: 42.079752, mean_eps: 0.369145\n",
            " 7299/10000: episode: 182, duration: 1.544s, episode steps: 194, steps per second: 126, episode reward: 194.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 3.874139, mae: 21.108243, mean_q: 42.624100, mean_eps: 0.351865\n",
            " 7450/10000: episode: 183, duration: 1.190s, episode steps: 151, steps per second: 127, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 3.976884, mae: 21.440304, mean_q: 43.249842, mean_eps: 0.336340\n",
            " 7590/10000: episode: 184, duration: 1.093s, episode steps: 140, steps per second: 128, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.080303, mae: 21.631821, mean_q: 43.673256, mean_eps: 0.323245\n",
            " 7743/10000: episode: 185, duration: 1.240s, episode steps: 153, steps per second: 123, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.201823, mae: 21.951424, mean_q: 44.254703, mean_eps: 0.310060\n",
            " 7894/10000: episode: 186, duration: 1.486s, episode steps: 151, steps per second: 102, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 2.415420, mae: 22.092029, mean_q: 44.635371, mean_eps: 0.296380\n",
            " 8045/10000: episode: 187, duration: 1.737s, episode steps: 151, steps per second:  87, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 2.880472, mae: 22.407993, mean_q: 45.219753, mean_eps: 0.282790\n",
            " 8179/10000: episode: 188, duration: 1.049s, episode steps: 134, steps per second: 128, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 2.437884, mae: 22.616876, mean_q: 45.593788, mean_eps: 0.269965\n",
            " 8310/10000: episode: 189, duration: 1.022s, episode steps: 131, steps per second: 128, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.976047, mae: 22.845423, mean_q: 46.016699, mean_eps: 0.258040\n",
            " 8456/10000: episode: 190, duration: 1.198s, episode steps: 146, steps per second: 122, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 2.516477, mae: 22.951378, mean_q: 46.153984, mean_eps: 0.245575\n",
            " 8607/10000: episode: 191, duration: 1.288s, episode steps: 151, steps per second: 117, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 2.755284, mae: 23.241182, mean_q: 46.733829, mean_eps: 0.232210\n",
            " 8750/10000: episode: 192, duration: 1.118s, episode steps: 143, steps per second: 128, episode reward: 143.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.135425, mae: 23.597906, mean_q: 47.438507, mean_eps: 0.218980\n",
            " 8907/10000: episode: 193, duration: 1.240s, episode steps: 157, steps per second: 127, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 1.925741, mae: 23.655196, mean_q: 47.594123, mean_eps: 0.205480\n",
            " 9062/10000: episode: 194, duration: 1.198s, episode steps: 155, steps per second: 129, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.479028, mae: 23.916924, mean_q: 48.036058, mean_eps: 0.191440\n",
            " 9218/10000: episode: 195, duration: 1.248s, episode steps: 156, steps per second: 125, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 2.174909, mae: 23.955341, mean_q: 48.101985, mean_eps: 0.177445\n",
            " 9356/10000: episode: 196, duration: 1.354s, episode steps: 138, steps per second: 102, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 1.530227, mae: 23.785296, mean_q: 47.783837, mean_eps: 0.164215\n",
            " 9500/10000: episode: 197, duration: 1.685s, episode steps: 144, steps per second:  85, episode reward: 144.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 1.101249, mae: 24.077798, mean_q: 48.402376, mean_eps: 0.151525\n",
            " 9640/10000: episode: 198, duration: 1.177s, episode steps: 140, steps per second: 119, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 1.340291, mae: 24.019110, mean_q: 48.222046, mean_eps: 0.138745\n",
            " 9772/10000: episode: 199, duration: 1.044s, episode steps: 132, steps per second: 126, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 1.140135, mae: 24.162120, mean_q: 48.505142, mean_eps: 0.126505\n",
            " 9908/10000: episode: 200, duration: 1.092s, episode steps: 136, steps per second: 125, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.108236, mae: 24.189610, mean_q: 48.547036, mean_eps: 0.114445\n",
            "done, took 94.144 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the log, it seems that the model is making progress in terms of improving its mean reward and mean_q value over time, which suggests that it is learning to make better decisions in the environment, but the previosu models are doing good than this model.\n",
        "\n",
        "BUt mae  value is really good but the rewards are just near to 200"
      ],
      "metadata": {
        "id": "wIf6Ztje_U_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history_4.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "T3d5Gtsd9PE3",
        "outputId": "3c2fc3f9-36ae-4bee-ee92-a293e3981e41"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model 3\n",
        "for i in range(0,3):\n",
        "    dqn_3.test(env, nb_episodes=20, visualize=False)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcnsRdpw-Dsi",
        "outputId": "3b8581c9-5fc2-4d98-9558-b58716b8fbe4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 134.000, steps: 134\n",
            "Episode 2: reward: 136.000, steps: 136\n",
            "Episode 3: reward: 141.000, steps: 141\n",
            "Episode 4: reward: 135.000, steps: 135\n",
            "Episode 5: reward: 126.000, steps: 126\n",
            "Episode 6: reward: 139.000, steps: 139\n",
            "Episode 7: reward: 131.000, steps: 131\n",
            "Episode 8: reward: 139.000, steps: 139\n",
            "Episode 9: reward: 136.000, steps: 136\n",
            "Episode 10: reward: 131.000, steps: 131\n",
            "Episode 11: reward: 128.000, steps: 128\n",
            "Episode 12: reward: 134.000, steps: 134\n",
            "Episode 13: reward: 137.000, steps: 137\n",
            "Episode 14: reward: 130.000, steps: 130\n",
            "Episode 15: reward: 133.000, steps: 133\n",
            "Episode 16: reward: 134.000, steps: 134\n",
            "Episode 17: reward: 142.000, steps: 142\n",
            "Episode 18: reward: 128.000, steps: 128\n",
            "Episode 19: reward: 133.000, steps: 133\n",
            "Episode 20: reward: 128.000, steps: 128\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 129.000, steps: 129\n",
            "Episode 2: reward: 137.000, steps: 137\n",
            "Episode 3: reward: 129.000, steps: 129\n",
            "Episode 4: reward: 141.000, steps: 141\n",
            "Episode 5: reward: 129.000, steps: 129\n",
            "Episode 6: reward: 128.000, steps: 128\n",
            "Episode 7: reward: 130.000, steps: 130\n",
            "Episode 8: reward: 136.000, steps: 136\n",
            "Episode 9: reward: 139.000, steps: 139\n",
            "Episode 10: reward: 130.000, steps: 130\n",
            "Episode 11: reward: 133.000, steps: 133\n",
            "Episode 12: reward: 133.000, steps: 133\n",
            "Episode 13: reward: 140.000, steps: 140\n",
            "Episode 14: reward: 131.000, steps: 131\n",
            "Episode 15: reward: 135.000, steps: 135\n",
            "Episode 16: reward: 125.000, steps: 125\n",
            "Episode 17: reward: 134.000, steps: 134\n",
            "Episode 18: reward: 135.000, steps: 135\n",
            "Episode 19: reward: 139.000, steps: 139\n",
            "Episode 20: reward: 136.000, steps: 136\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 132.000, steps: 132\n",
            "Episode 2: reward: 136.000, steps: 136\n",
            "Episode 3: reward: 131.000, steps: 131\n",
            "Episode 4: reward: 130.000, steps: 130\n",
            "Episode 5: reward: 143.000, steps: 143\n",
            "Episode 6: reward: 125.000, steps: 125\n",
            "Episode 7: reward: 139.000, steps: 139\n",
            "Episode 8: reward: 141.000, steps: 141\n",
            "Episode 9: reward: 135.000, steps: 135\n",
            "Episode 10: reward: 136.000, steps: 136\n",
            "Episode 11: reward: 127.000, steps: 127\n",
            "Episode 12: reward: 138.000, steps: 138\n",
            "Episode 13: reward: 140.000, steps: 140\n",
            "Episode 14: reward: 134.000, steps: 134\n",
            "Episode 15: reward: 138.000, steps: 138\n",
            "Episode 16: reward: 133.000, steps: 133\n",
            "Episode 17: reward: 137.000, steps: 137\n",
            "Episode 18: reward: 139.000, steps: 139\n",
            "Episode 19: reward: 134.000, steps: 134\n",
            "Episode 20: reward: 134.000, steps: 134\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model_5"
      ],
      "metadata": {
        "id": "TfiY7UcCA1OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = Sequential()\n",
        "model_5.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model_5.add(Flatten())\n",
        "model_5.add(Dense(15, activation='relu'))\n",
        "#addint the ayers\n",
        "model_5.add(Dense(10, activation='relu'))\n",
        "model_5.add(Flatten())\n",
        "model_5.add(Dense(3, activation='relu'))\n",
        "\n",
        "# adds a fully connected layer to the model with 16 units and a ReLU activation function.\n",
        "model_5.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model_5.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32TQ-7F-HAt",
        "outputId": "75fa3abd-bf29-4fe3-fe0f-abc7ec44e19d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 15)                75        \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 3)                 33        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 2)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276\n",
            "Trainable params: 276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=2500, window_length=1)\n",
        "\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=10000)\n",
        "\n",
        "\n",
        "# define the agent\n",
        "dqn_5 = DQNAgent(model=model_5, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn_5.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history_5 = dqn_5.fit(env, nb_steps=10000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvNWXbBqBH3w",
        "outputId": "95d54c0f-858c-41c5-b524-64a7ad61c6b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   23/10000: episode: 1, duration: 2.079s, episode steps:  23, steps per second:  11, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   67/10000: episode: 2, duration: 0.107s, episode steps:  44, steps per second: 410, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  102/10000: episode: 3, duration: 3.925s, episode steps:  35, steps per second:   9, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 0.526543, mae: 0.525593, mean_q: 0.018583, mean_eps: 0.990910\n",
            "  157/10000: episode: 4, duration: 0.477s, episode steps:  55, steps per second: 115, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 0.429653, mae: 0.508470, mean_q: 0.171076, mean_eps: 0.988390\n",
            "  183/10000: episode: 5, duration: 0.248s, episode steps:  26, steps per second: 105, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.302938, mae: 0.527379, mean_q: 0.515427, mean_eps: 0.984745\n",
            "  206/10000: episode: 6, duration: 0.221s, episode steps:  23, steps per second: 104, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 0.241657, mae: 0.571897, mean_q: 0.719082, mean_eps: 0.982540\n",
            "  226/10000: episode: 7, duration: 0.199s, episode steps:  20, steps per second: 100, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.157865, mae: 0.629170, mean_q: 0.950851, mean_eps: 0.980605\n",
            "  240/10000: episode: 8, duration: 0.134s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.102837, mae: 0.703843, mean_q: 1.146185, mean_eps: 0.979075\n",
            "  252/10000: episode: 9, duration: 0.117s, episode steps:  12, steps per second: 102, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.078097, mae: 0.772024, mean_q: 1.313212, mean_eps: 0.977905\n",
            "  289/10000: episode: 10, duration: 0.308s, episode steps:  37, steps per second: 120, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.060373, mae: 0.841598, mean_q: 1.465328, mean_eps: 0.975700\n",
            "  305/10000: episode: 11, duration: 0.134s, episode steps:  16, steps per second: 119, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.051936, mae: 0.925990, mean_q: 1.695744, mean_eps: 0.973315\n",
            "  317/10000: episode: 12, duration: 0.115s, episode steps:  12, steps per second: 104, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.046144, mae: 0.968364, mean_q: 1.831117, mean_eps: 0.972055\n",
            "  340/10000: episode: 13, duration: 0.190s, episode steps:  23, steps per second: 121, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 0.040886, mae: 1.013954, mean_q: 1.938027, mean_eps: 0.970480\n",
            "  356/10000: episode: 14, duration: 0.139s, episode steps:  16, steps per second: 115, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.047198, mae: 1.080557, mean_q: 2.078554, mean_eps: 0.968725\n",
            "  395/10000: episode: 15, duration: 0.331s, episode steps:  39, steps per second: 118, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.057142, mae: 1.188570, mean_q: 2.309563, mean_eps: 0.966250\n",
            "  417/10000: episode: 16, duration: 0.182s, episode steps:  22, steps per second: 121, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.067157, mae: 1.327070, mean_q: 2.573650, mean_eps: 0.963505\n",
            "  441/10000: episode: 17, duration: 0.207s, episode steps:  24, steps per second: 116, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 0.091531, mae: 1.430253, mean_q: 2.777325, mean_eps: 0.961435\n",
            "  494/10000: episode: 18, duration: 0.475s, episode steps:  53, steps per second: 112, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 0.101879, mae: 1.583838, mean_q: 3.084802, mean_eps: 0.957970\n",
            "  512/10000: episode: 19, duration: 0.150s, episode steps:  18, steps per second: 120, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.126844, mae: 1.738153, mean_q: 3.385495, mean_eps: 0.954775\n",
            "  528/10000: episode: 20, duration: 0.155s, episode steps:  16, steps per second: 103, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.126095, mae: 1.816007, mean_q: 3.509213, mean_eps: 0.953245\n",
            "  560/10000: episode: 21, duration: 0.270s, episode steps:  32, steps per second: 119, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.159221, mae: 1.931463, mean_q: 3.743312, mean_eps: 0.951085\n",
            "  575/10000: episode: 22, duration: 0.128s, episode steps:  15, steps per second: 117, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.224923, mae: 2.052847, mean_q: 3.900074, mean_eps: 0.948970\n",
            "  585/10000: episode: 23, duration: 0.088s, episode steps:  10, steps per second: 113, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.179366, mae: 2.087062, mean_q: 4.030472, mean_eps: 0.947845\n",
            "  599/10000: episode: 24, duration: 0.115s, episode steps:  14, steps per second: 122, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 0.181024, mae: 2.141562, mean_q: 4.168025, mean_eps: 0.946765\n",
            "  643/10000: episode: 25, duration: 0.373s, episode steps:  44, steps per second: 118, episode reward: 44.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.274141, mae: 2.300023, mean_q: 4.421521, mean_eps: 0.944155\n",
            "  655/10000: episode: 26, duration: 0.110s, episode steps:  12, steps per second: 109, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.214567, mae: 2.393771, mean_q: 4.642051, mean_eps: 0.941635\n",
            "  673/10000: episode: 27, duration: 0.178s, episode steps:  18, steps per second: 101, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 0.216171, mae: 2.497254, mean_q: 4.927263, mean_eps: 0.940285\n",
            "  710/10000: episode: 28, duration: 0.324s, episode steps:  37, steps per second: 114, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.405 [0.000, 1.000],  loss: 0.290881, mae: 2.601356, mean_q: 5.005013, mean_eps: 0.937810\n",
            "  722/10000: episode: 29, duration: 0.110s, episode steps:  12, steps per second: 109, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.276185, mae: 2.715602, mean_q: 5.267222, mean_eps: 0.935605\n",
            "  735/10000: episode: 30, duration: 0.112s, episode steps:  13, steps per second: 116, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.338712, mae: 2.773128, mean_q: 5.388381, mean_eps: 0.934480\n",
            "  751/10000: episode: 31, duration: 0.129s, episode steps:  16, steps per second: 124, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.366382, mae: 2.834957, mean_q: 5.465248, mean_eps: 0.933175\n",
            "  765/10000: episode: 32, duration: 0.180s, episode steps:  14, steps per second:  78, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.550056, mae: 2.933178, mean_q: 5.532497, mean_eps: 0.931825\n",
            "  776/10000: episode: 33, duration: 0.134s, episode steps:  11, steps per second:  82, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.322865, mae: 2.908228, mean_q: 5.581302, mean_eps: 0.930700\n",
            "  787/10000: episode: 34, duration: 0.172s, episode steps:  11, steps per second:  64, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.433044, mae: 3.018666, mean_q: 5.880896, mean_eps: 0.929710\n",
            "  809/10000: episode: 35, duration: 0.286s, episode steps:  22, steps per second:  77, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.431338, mae: 3.081518, mean_q: 5.857693, mean_eps: 0.928225\n",
            "  824/10000: episode: 36, duration: 0.200s, episode steps:  15, steps per second:  75, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.487267, mae: 3.192751, mean_q: 6.139593, mean_eps: 0.926560\n",
            "  850/10000: episode: 37, duration: 0.327s, episode steps:  26, steps per second:  79, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.564281, mae: 3.242006, mean_q: 6.145246, mean_eps: 0.924715\n",
            "  891/10000: episode: 38, duration: 0.545s, episode steps:  41, steps per second:  75, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 0.561789, mae: 3.366890, mean_q: 6.420560, mean_eps: 0.921700\n",
            "  902/10000: episode: 39, duration: 0.158s, episode steps:  11, steps per second:  70, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 0.486647, mae: 3.465746, mean_q: 6.699836, mean_eps: 0.919360\n",
            "  927/10000: episode: 40, duration: 0.383s, episode steps:  25, steps per second:  65, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.499620, mae: 3.540472, mean_q: 6.805454, mean_eps: 0.917740\n",
            "  952/10000: episode: 41, duration: 0.348s, episode steps:  25, steps per second:  72, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 0.432674, mae: 3.608819, mean_q: 6.968959, mean_eps: 0.915490\n",
            "  968/10000: episode: 42, duration: 0.168s, episode steps:  16, steps per second:  95, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: 0.778159, mae: 3.725762, mean_q: 7.027473, mean_eps: 0.913645\n",
            "  998/10000: episode: 43, duration: 0.292s, episode steps:  30, steps per second: 103, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.715719, mae: 3.823424, mean_q: 7.246004, mean_eps: 0.911575\n",
            " 1020/10000: episode: 44, duration: 0.225s, episode steps:  22, steps per second:  98, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.726442, mae: 3.879064, mean_q: 7.319497, mean_eps: 0.909235\n",
            " 1033/10000: episode: 45, duration: 0.114s, episode steps:  13, steps per second: 114, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.819400, mae: 3.979778, mean_q: 7.531009, mean_eps: 0.907660\n",
            " 1043/10000: episode: 46, duration: 0.104s, episode steps:  10, steps per second:  96, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.759064, mae: 3.973675, mean_q: 7.489955, mean_eps: 0.906625\n",
            " 1117/10000: episode: 47, duration: 0.643s, episode steps:  74, steps per second: 115, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 0.764056, mae: 4.114732, mean_q: 7.799720, mean_eps: 0.902845\n",
            " 1142/10000: episode: 48, duration: 0.226s, episode steps:  25, steps per second: 111, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 0.710327, mae: 4.263347, mean_q: 8.110628, mean_eps: 0.898390\n",
            " 1158/10000: episode: 49, duration: 0.158s, episode steps:  16, steps per second: 101, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 0.875107, mae: 4.333697, mean_q: 8.195461, mean_eps: 0.896545\n",
            " 1206/10000: episode: 50, duration: 0.425s, episode steps:  48, steps per second: 113, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.396 [0.000, 1.000],  loss: 0.809132, mae: 4.459180, mean_q: 8.501167, mean_eps: 0.893665\n",
            " 1226/10000: episode: 51, duration: 0.181s, episode steps:  20, steps per second: 110, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.678246, mae: 4.557982, mean_q: 8.757969, mean_eps: 0.890605\n",
            " 1242/10000: episode: 52, duration: 0.159s, episode steps:  16, steps per second: 101, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.972408, mae: 4.583936, mean_q: 8.701271, mean_eps: 0.888985\n",
            " 1256/10000: episode: 53, duration: 0.133s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 0.563766, mae: 4.663754, mean_q: 8.985771, mean_eps: 0.887635\n",
            " 1308/10000: episode: 54, duration: 0.476s, episode steps:  52, steps per second: 109, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.577 [0.000, 1.000],  loss: 0.972205, mae: 4.794439, mean_q: 9.175675, mean_eps: 0.884665\n",
            " 1350/10000: episode: 55, duration: 0.378s, episode steps:  42, steps per second: 111, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.595 [0.000, 1.000],  loss: 0.763047, mae: 4.945557, mean_q: 9.501869, mean_eps: 0.880435\n",
            " 1360/10000: episode: 56, duration: 0.092s, episode steps:  10, steps per second: 109, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.718955, mae: 5.046752, mean_q: 9.751023, mean_eps: 0.878095\n",
            " 1399/10000: episode: 57, duration: 0.334s, episode steps:  39, steps per second: 117, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.799477, mae: 5.145732, mean_q: 9.930824, mean_eps: 0.875890\n",
            " 1411/10000: episode: 58, duration: 0.120s, episode steps:  12, steps per second: 100, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.682730, mae: 5.181535, mean_q: 10.071264, mean_eps: 0.873595\n",
            " 1489/10000: episode: 59, duration: 0.699s, episode steps:  78, steps per second: 112, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.830960, mae: 5.351417, mean_q: 10.469993, mean_eps: 0.869545\n",
            " 1518/10000: episode: 60, duration: 0.264s, episode steps:  29, steps per second: 110, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 0.949602, mae: 5.586575, mean_q: 10.952144, mean_eps: 0.864730\n",
            " 1548/10000: episode: 61, duration: 0.271s, episode steps:  30, steps per second: 111, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.567 [0.000, 1.000],  loss: 0.939774, mae: 5.672555, mean_q: 11.128195, mean_eps: 0.862075\n",
            " 1575/10000: episode: 62, duration: 0.246s, episode steps:  27, steps per second: 110, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.116466, mae: 5.833793, mean_q: 11.405841, mean_eps: 0.859510\n",
            " 1597/10000: episode: 63, duration: 0.325s, episode steps:  22, steps per second:  68, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.591 [0.000, 1.000],  loss: 1.189774, mae: 5.910726, mean_q: 11.537584, mean_eps: 0.857305\n",
            " 1651/10000: episode: 64, duration: 0.895s, episode steps:  54, steps per second:  60, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 0.986698, mae: 6.069551, mean_q: 11.981480, mean_eps: 0.853885\n",
            " 1697/10000: episode: 65, duration: 1.697s, episode steps:  46, steps per second:  27, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 1.167599, mae: 6.284187, mean_q: 12.416770, mean_eps: 0.849385\n",
            " 1728/10000: episode: 66, duration: 1.452s, episode steps:  31, steps per second:  21, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.613 [0.000, 1.000],  loss: 0.916499, mae: 6.497956, mean_q: 12.873345, mean_eps: 0.845920\n",
            " 1751/10000: episode: 67, duration: 0.486s, episode steps:  23, steps per second:  47, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 0.548839, mae: 6.588323, mean_q: 13.246987, mean_eps: 0.843490\n",
            " 1773/10000: episode: 68, duration: 0.607s, episode steps:  22, steps per second:  36, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.017240, mae: 6.668795, mean_q: 13.313791, mean_eps: 0.841465\n",
            " 1865/10000: episode: 69, duration: 2.635s, episode steps:  92, steps per second:  35, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.172135, mae: 6.929767, mean_q: 13.744761, mean_eps: 0.836335\n",
            " 1888/10000: episode: 70, duration: 0.191s, episode steps:  23, steps per second: 120, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 0.825405, mae: 7.200137, mean_q: 14.471551, mean_eps: 0.831160\n",
            " 1902/10000: episode: 71, duration: 0.121s, episode steps:  14, steps per second: 116, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 1.219395, mae: 7.146215, mean_q: 14.164591, mean_eps: 0.829495\n",
            " 1921/10000: episode: 72, duration: 0.158s, episode steps:  19, steps per second: 120, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 1.494790, mae: 7.325254, mean_q: 14.545462, mean_eps: 0.828010\n",
            " 1943/10000: episode: 73, duration: 0.192s, episode steps:  22, steps per second: 115, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.471698, mae: 7.406429, mean_q: 14.679809, mean_eps: 0.826165\n",
            " 1967/10000: episode: 74, duration: 0.222s, episode steps:  24, steps per second: 108, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 1.389991, mae: 7.473392, mean_q: 14.950145, mean_eps: 0.824095\n",
            " 1995/10000: episode: 75, duration: 0.256s, episode steps:  28, steps per second: 110, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 1.182604, mae: 7.586570, mean_q: 15.146734, mean_eps: 0.821755\n",
            " 2019/10000: episode: 76, duration: 0.211s, episode steps:  24, steps per second: 114, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.355554, mae: 7.624627, mean_q: 15.209319, mean_eps: 0.819415\n",
            " 2099/10000: episode: 77, duration: 0.705s, episode steps:  80, steps per second: 113, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.349137, mae: 7.929719, mean_q: 15.903494, mean_eps: 0.814735\n",
            " 2149/10000: episode: 78, duration: 0.435s, episode steps:  50, steps per second: 115, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.953692, mae: 8.161708, mean_q: 16.197061, mean_eps: 0.808885\n",
            " 2186/10000: episode: 79, duration: 0.331s, episode steps:  37, steps per second: 112, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 1.832892, mae: 8.385183, mean_q: 16.643393, mean_eps: 0.804970\n",
            " 2195/10000: episode: 80, duration: 0.081s, episode steps:   9, steps per second: 111, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 3.039633, mae: 8.193948, mean_q: 16.046790, mean_eps: 0.802900\n",
            " 2216/10000: episode: 81, duration: 0.189s, episode steps:  21, steps per second: 111, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 1.598067, mae: 8.636774, mean_q: 17.189984, mean_eps: 0.801550\n",
            " 2334/10000: episode: 82, duration: 1.007s, episode steps: 118, steps per second: 117, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 1.390726, mae: 8.772287, mean_q: 17.598069, mean_eps: 0.795295\n",
            " 2363/10000: episode: 83, duration: 0.249s, episode steps:  29, steps per second: 116, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.345 [0.000, 1.000],  loss: 1.698480, mae: 9.018898, mean_q: 18.168371, mean_eps: 0.788680\n",
            " 2384/10000: episode: 84, duration: 0.174s, episode steps:  21, steps per second: 121, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 1.330061, mae: 9.108186, mean_q: 18.437874, mean_eps: 0.786430\n",
            " 2442/10000: episode: 85, duration: 0.480s, episode steps:  58, steps per second: 121, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 1.360546, mae: 9.291646, mean_q: 18.843761, mean_eps: 0.782875\n",
            " 2474/10000: episode: 86, duration: 0.268s, episode steps:  32, steps per second: 119, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.406 [0.000, 1.000],  loss: 1.734903, mae: 9.488751, mean_q: 19.027322, mean_eps: 0.778825\n",
            " 2599/10000: episode: 87, duration: 1.057s, episode steps: 125, steps per second: 118, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 1.666288, mae: 9.834691, mean_q: 19.880002, mean_eps: 0.771760\n",
            " 2661/10000: episode: 88, duration: 0.544s, episode steps:  62, steps per second: 114, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 1.345414, mae: 10.184620, mean_q: 20.681546, mean_eps: 0.763345\n",
            " 2725/10000: episode: 89, duration: 0.545s, episode steps:  64, steps per second: 117, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.547 [0.000, 1.000],  loss: 1.594757, mae: 10.548239, mean_q: 21.429305, mean_eps: 0.757675\n",
            " 2778/10000: episode: 90, duration: 0.441s, episode steps:  53, steps per second: 120, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.415 [0.000, 1.000],  loss: 1.863922, mae: 10.743430, mean_q: 21.857146, mean_eps: 0.752410\n",
            " 2802/10000: episode: 91, duration: 0.204s, episode steps:  24, steps per second: 118, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 1.364741, mae: 10.930245, mean_q: 22.214160, mean_eps: 0.748945\n",
            " 2813/10000: episode: 92, duration: 0.101s, episode steps:  11, steps per second: 109, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 1.135885, mae: 11.136424, mean_q: 22.797829, mean_eps: 0.747370\n",
            " 2836/10000: episode: 93, duration: 0.194s, episode steps:  23, steps per second: 118, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.304 [0.000, 1.000],  loss: 1.430446, mae: 11.140329, mean_q: 22.613257, mean_eps: 0.745840\n",
            " 2883/10000: episode: 94, duration: 0.391s, episode steps:  47, steps per second: 120, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 1.321165, mae: 11.257427, mean_q: 22.888481, mean_eps: 0.742690\n",
            " 2911/10000: episode: 95, duration: 0.254s, episode steps:  28, steps per second: 110, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.105568, mae: 11.530684, mean_q: 23.418189, mean_eps: 0.739315\n",
            " 2957/10000: episode: 96, duration: 0.598s, episode steps:  46, steps per second:  77, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 0.978156, mae: 11.714821, mean_q: 23.910300, mean_eps: 0.735985\n",
            " 3016/10000: episode: 97, duration: 0.750s, episode steps:  59, steps per second:  79, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.508 [0.000, 1.000],  loss: 1.961404, mae: 11.904896, mean_q: 24.177908, mean_eps: 0.731260\n",
            " 3041/10000: episode: 98, duration: 0.313s, episode steps:  25, steps per second:  80, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.560 [0.000, 1.000],  loss: 1.860876, mae: 11.970252, mean_q: 24.207438, mean_eps: 0.727480\n",
            " 3103/10000: episode: 99, duration: 0.729s, episode steps:  62, steps per second:  85, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 1.395086, mae: 12.222087, mean_q: 24.912945, mean_eps: 0.723565\n",
            " 3192/10000: episode: 100, duration: 0.845s, episode steps:  89, steps per second: 105, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 1.488031, mae: 12.649670, mean_q: 25.841857, mean_eps: 0.716770\n",
            " 3237/10000: episode: 101, duration: 0.385s, episode steps:  45, steps per second: 117, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.682660, mae: 13.141735, mean_q: 26.809050, mean_eps: 0.710740\n",
            " 3276/10000: episode: 102, duration: 0.347s, episode steps:  39, steps per second: 112, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 1.643177, mae: 13.206495, mean_q: 27.078377, mean_eps: 0.706960\n",
            " 3294/10000: episode: 103, duration: 0.155s, episode steps:  18, steps per second: 116, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 1.377225, mae: 13.522816, mean_q: 27.716835, mean_eps: 0.704395\n",
            " 3349/10000: episode: 104, duration: 0.450s, episode steps:  55, steps per second: 122, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 1.631957, mae: 13.623433, mean_q: 27.874229, mean_eps: 0.701110\n",
            " 3460/10000: episode: 105, duration: 0.956s, episode steps: 111, steps per second: 116, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 1.810834, mae: 13.840286, mean_q: 28.316398, mean_eps: 0.693640\n",
            " 3483/10000: episode: 106, duration: 0.210s, episode steps:  23, steps per second: 110, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.609 [0.000, 1.000],  loss: 1.596236, mae: 14.320301, mean_q: 29.380870, mean_eps: 0.687610\n",
            " 3517/10000: episode: 107, duration: 0.295s, episode steps:  34, steps per second: 115, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 2.478276, mae: 14.488814, mean_q: 29.463967, mean_eps: 0.685045\n",
            " 3531/10000: episode: 108, duration: 0.130s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.297747, mae: 14.553908, mean_q: 29.521446, mean_eps: 0.682885\n",
            " 3599/10000: episode: 109, duration: 0.581s, episode steps:  68, steps per second: 117, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 2.357633, mae: 14.716254, mean_q: 29.964759, mean_eps: 0.679195\n",
            " 3634/10000: episode: 110, duration: 0.301s, episode steps:  35, steps per second: 116, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 1.461131, mae: 14.926482, mean_q: 30.503149, mean_eps: 0.674560\n",
            " 3650/10000: episode: 111, duration: 0.158s, episode steps:  16, steps per second: 101, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.562 [0.000, 1.000],  loss: 2.586468, mae: 15.096791, mean_q: 30.619495, mean_eps: 0.672265\n",
            " 3709/10000: episode: 112, duration: 0.537s, episode steps:  59, steps per second: 110, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 1.439544, mae: 15.280054, mean_q: 31.262246, mean_eps: 0.668890\n",
            " 3750/10000: episode: 113, duration: 0.349s, episode steps:  41, steps per second: 117, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 1.473302, mae: 15.640329, mean_q: 32.098780, mean_eps: 0.664390\n",
            " 3779/10000: episode: 114, duration: 0.265s, episode steps:  29, steps per second: 109, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 1.455575, mae: 15.564288, mean_q: 32.064918, mean_eps: 0.661240\n",
            " 3821/10000: episode: 115, duration: 0.363s, episode steps:  42, steps per second: 116, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.210405, mae: 15.879027, mean_q: 32.409743, mean_eps: 0.658045\n",
            " 3935/10000: episode: 116, duration: 0.939s, episode steps: 114, steps per second: 121, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 2.177536, mae: 16.161853, mean_q: 33.088174, mean_eps: 0.651025\n",
            " 3984/10000: episode: 117, duration: 0.446s, episode steps:  49, steps per second: 110, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 2.178066, mae: 16.554126, mean_q: 33.877680, mean_eps: 0.643690\n",
            " 4074/10000: episode: 118, duration: 0.812s, episode steps:  90, steps per second: 111, episode reward: 90.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 1.989888, mae: 16.839320, mean_q: 34.529639, mean_eps: 0.637435\n",
            " 4142/10000: episode: 119, duration: 0.580s, episode steps:  68, steps per second: 117, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 2.010349, mae: 17.287028, mean_q: 35.444259, mean_eps: 0.630325\n",
            " 4196/10000: episode: 120, duration: 0.454s, episode steps:  54, steps per second: 119, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 2.139609, mae: 17.609957, mean_q: 36.056152, mean_eps: 0.624835\n",
            " 4290/10000: episode: 121, duration: 0.836s, episode steps:  94, steps per second: 112, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 2.250522, mae: 17.996973, mean_q: 36.860270, mean_eps: 0.618175\n",
            " 4343/10000: episode: 122, duration: 0.679s, episode steps:  53, steps per second:  78, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 1.801814, mae: 18.573897, mean_q: 38.025518, mean_eps: 0.611560\n",
            " 4422/10000: episode: 123, duration: 0.994s, episode steps:  79, steps per second:  79, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 2.363901, mae: 18.807027, mean_q: 38.398638, mean_eps: 0.605620\n",
            " 4471/10000: episode: 124, duration: 0.589s, episode steps:  49, steps per second:  83, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 2.473109, mae: 19.050588, mean_q: 38.925536, mean_eps: 0.599860\n",
            " 4499/10000: episode: 125, duration: 0.297s, episode steps:  28, steps per second:  94, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 1.730519, mae: 19.228196, mean_q: 39.528791, mean_eps: 0.596395\n",
            " 4523/10000: episode: 126, duration: 0.218s, episode steps:  24, steps per second: 110, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 2.410713, mae: 19.383108, mean_q: 39.619283, mean_eps: 0.594055\n",
            " 4585/10000: episode: 127, duration: 0.529s, episode steps:  62, steps per second: 117, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 2.677021, mae: 19.412550, mean_q: 39.827009, mean_eps: 0.590185\n",
            " 4668/10000: episode: 128, duration: 0.667s, episode steps:  83, steps per second: 125, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 3.511523, mae: 19.956476, mean_q: 40.935516, mean_eps: 0.583660\n",
            " 4787/10000: episode: 129, duration: 1.076s, episode steps: 119, steps per second: 111, episode reward: 119.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 1.897482, mae: 20.471015, mean_q: 41.986123, mean_eps: 0.574570\n",
            " 4855/10000: episode: 130, duration: 0.632s, episode steps:  68, steps per second: 108, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.930116, mae: 20.987620, mean_q: 43.139168, mean_eps: 0.566155\n",
            " 4974/10000: episode: 131, duration: 1.032s, episode steps: 119, steps per second: 115, episode reward: 119.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 3.132926, mae: 21.420041, mean_q: 43.931032, mean_eps: 0.557740\n",
            " 5137/10000: episode: 132, duration: 1.365s, episode steps: 163, steps per second: 119, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 4.114668, mae: 22.153305, mean_q: 45.210645, mean_eps: 0.545050\n",
            " 5300/10000: episode: 133, duration: 1.295s, episode steps: 163, steps per second: 126, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 3.266356, mae: 22.696820, mean_q: 46.424861, mean_eps: 0.530380\n",
            " 5500/10000: episode: 134, duration: 1.718s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 4.130680, mae: 23.456489, mean_q: 47.837384, mean_eps: 0.514045\n",
            " 5628/10000: episode: 135, duration: 1.079s, episode steps: 128, steps per second: 119, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.266797, mae: 24.158812, mean_q: 49.483335, mean_eps: 0.499285\n",
            " 5756/10000: episode: 136, duration: 1.465s, episode steps: 128, steps per second:  87, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 3.618401, mae: 24.541927, mean_q: 50.306463, mean_eps: 0.487765\n",
            " 5895/10000: episode: 137, duration: 1.653s, episode steps: 139, steps per second:  84, episode reward: 139.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.496 [0.000, 1.000],  loss: 4.898627, mae: 25.141565, mean_q: 51.366478, mean_eps: 0.475750\n",
            " 6082/10000: episode: 138, duration: 1.624s, episode steps: 187, steps per second: 115, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.571684, mae: 25.994368, mean_q: 53.069249, mean_eps: 0.461080\n",
            " 6196/10000: episode: 139, duration: 1.011s, episode steps: 114, steps per second: 113, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 3.378407, mae: 26.419064, mean_q: 54.086681, mean_eps: 0.447535\n",
            " 6321/10000: episode: 140, duration: 1.098s, episode steps: 125, steps per second: 114, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 3.657110, mae: 27.031999, mean_q: 55.207640, mean_eps: 0.436780\n",
            " 6480/10000: episode: 141, duration: 1.322s, episode steps: 159, steps per second: 120, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 3.746609, mae: 27.324819, mean_q: 55.873773, mean_eps: 0.424000\n",
            " 6680/10000: episode: 142, duration: 1.691s, episode steps: 200, steps per second: 118, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 3.628847, mae: 27.995450, mean_q: 57.126753, mean_eps: 0.407845\n",
            " 6861/10000: episode: 143, duration: 1.586s, episode steps: 181, steps per second: 114, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 2.698911, mae: 28.455898, mean_q: 58.076501, mean_eps: 0.390700\n",
            " 6913/10000: episode: 144, duration: 0.452s, episode steps:  52, steps per second: 115, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 4.009699, mae: 28.524329, mean_q: 58.117579, mean_eps: 0.380215\n",
            " 7091/10000: episode: 145, duration: 1.763s, episode steps: 178, steps per second: 101, episode reward: 178.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 3.124727, mae: 28.939892, mean_q: 58.971548, mean_eps: 0.369865\n",
            " 7156/10000: episode: 146, duration: 0.780s, episode steps:  65, steps per second:  83, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.216614, mae: 29.186095, mean_q: 59.432242, mean_eps: 0.358930\n",
            " 7341/10000: episode: 147, duration: 1.866s, episode steps: 185, steps per second:  99, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 4.283475, mae: 29.624696, mean_q: 60.208183, mean_eps: 0.347680\n",
            " 7541/10000: episode: 148, duration: 1.676s, episode steps: 200, steps per second: 119, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.973913, mae: 29.879980, mean_q: 60.694930, mean_eps: 0.330355\n",
            " 7709/10000: episode: 149, duration: 1.399s, episode steps: 168, steps per second: 120, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 2.262314, mae: 30.269752, mean_q: 61.504349, mean_eps: 0.313795\n",
            " 7880/10000: episode: 150, duration: 1.494s, episode steps: 171, steps per second: 114, episode reward: 171.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 2.108617, mae: 30.978291, mean_q: 62.783743, mean_eps: 0.298540\n",
            " 8057/10000: episode: 151, duration: 1.384s, episode steps: 177, steps per second: 128, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 2.898415, mae: 30.881442, mean_q: 62.536352, mean_eps: 0.282880\n",
            " 8239/10000: episode: 152, duration: 1.506s, episode steps: 182, steps per second: 121, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.731859, mae: 31.138426, mean_q: 63.034730, mean_eps: 0.266725\n",
            " 8406/10000: episode: 153, duration: 1.481s, episode steps: 167, steps per second: 113, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.890053, mae: 31.268434, mean_q: 63.270429, mean_eps: 0.251020\n",
            " 8603/10000: episode: 154, duration: 2.396s, episode steps: 197, steps per second:  82, episode reward: 197.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 2.368834, mae: 31.156925, mean_q: 62.986775, mean_eps: 0.234640\n",
            " 8778/10000: episode: 155, duration: 1.604s, episode steps: 175, steps per second: 109, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 2.018209, mae: 31.330974, mean_q: 63.234207, mean_eps: 0.217900\n",
            " 8965/10000: episode: 156, duration: 1.598s, episode steps: 187, steps per second: 117, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 2.219349, mae: 31.568631, mean_q: 63.555505, mean_eps: 0.201610\n",
            " 9165/10000: episode: 157, duration: 1.743s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 1.591350, mae: 31.512657, mean_q: 63.451216, mean_eps: 0.184195\n",
            " 9341/10000: episode: 158, duration: 1.519s, episode steps: 176, steps per second: 116, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 2.333440, mae: 31.484297, mean_q: 63.225487, mean_eps: 0.167275\n",
            " 9528/10000: episode: 159, duration: 2.038s, episode steps: 187, steps per second:  92, episode reward: 187.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.720074, mae: 31.590865, mean_q: 63.405581, mean_eps: 0.150940\n",
            " 9728/10000: episode: 160, duration: 1.664s, episode steps: 200, steps per second: 120, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 0.981846, mae: 31.496636, mean_q: 63.245013, mean_eps: 0.133525\n",
            " 9897/10000: episode: 161, duration: 2.120s, episode steps: 169, steps per second:  80, episode reward: 169.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.572981, mae: 31.733131, mean_q: 63.679966, mean_eps: 0.116920\n",
            "done, took 103.650 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history_5.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WzZCl2LgDaRa",
        "outputId": "e94a6913-e6e6-49e0-c048-6271bdb7148f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model 5\n",
        "for i in range(0,3):\n",
        "    dqn_5.test(env, nb_episodes=20, visualize=False)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTeMRtmHDgwC",
        "outputId": "100eeaa8-0183-4d73-9684-6d19232b523f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 199.000, steps: 199\n",
            "Episode 3: reward: 191.000, steps: 191\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 190.000, steps: 190\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 187.000, steps: 187\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 181.000, steps: 181\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 167.000, steps: 167\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 197.000, steps: 197\n",
            "Episode 19: reward: 188.000, steps: 188\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 182.000, steps: 182\n",
            "Episode 3: reward: 177.000, steps: 177\n",
            "Episode 4: reward: 180.000, steps: 180\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 184.000, steps: 184\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 183.000, steps: 183\n",
            "Episode 10: reward: 182.000, steps: 182\n",
            "Episode 11: reward: 183.000, steps: 183\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 194.000, steps: 194\n",
            "Episode 14: reward: 190.000, steps: 190\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 197.000, steps: 197\n",
            "Episode 18: reward: 186.000, steps: 186\n",
            "Episode 19: reward: 183.000, steps: 183\n",
            "Episode 20: reward: 187.000, steps: 187\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 176.000, steps: 176\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 181.000, steps: 181\n",
            "Episode 7: reward: 192.000, steps: 192\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 188.000, steps: 188\n",
            "Episode 10: reward: 197.000, steps: 197\n",
            "Episode 11: reward: 185.000, steps: 185\n",
            "Episode 12: reward: 176.000, steps: 176\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 195.000, steps: 195\n",
            "Episode 15: reward: 195.000, steps: 195\n",
            "Episode 16: reward: 186.000, steps: 186\n",
            "Episode 17: reward: 190.000, steps: 190\n",
            "Episode 18: reward: 173.000, steps: 173\n",
            "Episode 19: reward: 199.000, steps: 199\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model_6\n",
        "model 6 for 5000 steps and learning rate is different"
      ],
      "metadata": {
        "id": "T52RYZQlEcK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6 = Sequential()\n",
        "model_6.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model_6.add(Flatten())\n",
        "model_6.add(Dense(15, activation='relu'))\n",
        "#addint the ayers\n",
        "model_6.add(Dense(10, activation='relu'))\n",
        "model_6.add(Flatten())\n",
        "model_6.add(Dense(3, activation='relu'))\n",
        "\n",
        "# adds a fully connected layer to the model with 16 units and a ReLU activation function.\n",
        "model_6.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model_6.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq2VPK_1D-tv",
        "outputId": "1706bdd0-b777-4ea5-e9dd-6597d0ce6439"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 15)                75        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 3)                 33        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276\n",
            "Trainable params: 276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=2500, window_length=1)\n",
        "\n",
        "# define the policy\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.0,\n",
        "                               value_min=0.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=5000)\n",
        "\n",
        "\n",
        "# define the agent\n",
        "dqn_6 = DQNAgent(model=model_6, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=100,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn_6.compile(Adam(lr=0.00015), metrics=['mae'])\n",
        "\n",
        "history_6 = dqn_5.fit(env, nb_steps=5000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIfr0sEXE1R3",
        "outputId": "2a247730-29ef-4732-eaa7-b187629a234a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 5000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   23/5000: episode: 1, duration: 0.667s, episode steps:  23, steps per second:  34, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   92/5000: episode: 2, duration: 0.074s, episode steps:  69, steps per second: 928, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.449 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  105/5000: episode: 3, duration: 0.056s, episode steps:  13, steps per second: 232, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 1.274072, mae: 6.536688, mean_q: 12.287602, mean_eps: 0.981550\n",
            "  150/5000: episode: 4, duration: 0.440s, episode steps:  45, steps per second: 102, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.422 [0.000, 1.000],  loss: 1.994155, mae: 6.421136, mean_q: 11.889154, mean_eps: 0.977140\n",
            "  170/5000: episode: 5, duration: 0.179s, episode steps:  20, steps per second: 112, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 1.319335, mae: 6.388333, mean_q: 11.933860, mean_eps: 0.971290\n",
            "  183/5000: episode: 6, duration: 0.118s, episode steps:  13, steps per second: 111, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 2.097418, mae: 6.490300, mean_q: 11.954566, mean_eps: 0.968320\n",
            "  195/5000: episode: 7, duration: 0.111s, episode steps:  12, steps per second: 108, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 1.417015, mae: 6.326087, mean_q: 11.823266, mean_eps: 0.966070\n",
            "  252/5000: episode: 8, duration: 0.507s, episode steps:  57, steps per second: 113, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 1.558498, mae: 6.331798, mean_q: 11.760042, mean_eps: 0.959860\n",
            "  266/5000: episode: 9, duration: 0.127s, episode steps:  14, steps per second: 110, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 1.790578, mae: 6.243439, mean_q: 11.525345, mean_eps: 0.953470\n",
            "  303/5000: episode: 10, duration: 0.326s, episode steps:  37, steps per second: 113, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.432 [0.000, 1.000],  loss: 1.821386, mae: 6.366449, mean_q: 11.714622, mean_eps: 0.948880\n",
            "  313/5000: episode: 11, duration: 0.092s, episode steps:  10, steps per second: 108, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 1.798029, mae: 6.493702, mean_q: 11.965284, mean_eps: 0.944650\n",
            "  331/5000: episode: 12, duration: 0.173s, episode steps:  18, steps per second: 104, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 1.742965, mae: 6.293832, mean_q: 11.579520, mean_eps: 0.942130\n",
            "  353/5000: episode: 13, duration: 0.202s, episode steps:  22, steps per second: 109, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 1.583547, mae: 6.298026, mean_q: 11.651650, mean_eps: 0.938530\n",
            "  371/5000: episode: 14, duration: 0.173s, episode steps:  18, steps per second: 104, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 1.698073, mae: 6.338419, mean_q: 11.687371, mean_eps: 0.934930\n",
            "  394/5000: episode: 15, duration: 0.223s, episode steps:  23, steps per second: 103, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 1.600178, mae: 6.460911, mean_q: 11.932313, mean_eps: 0.931240\n",
            "  413/5000: episode: 16, duration: 0.170s, episode steps:  19, steps per second: 112, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 1.460131, mae: 6.512875, mean_q: 12.091094, mean_eps: 0.927460\n",
            "  429/5000: episode: 17, duration: 0.154s, episode steps:  16, steps per second: 104, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 1.726824, mae: 6.437287, mean_q: 11.888793, mean_eps: 0.924310\n",
            "  441/5000: episode: 18, duration: 0.105s, episode steps:  12, steps per second: 115, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 1.451122, mae: 6.194712, mean_q: 11.452582, mean_eps: 0.921790\n",
            "  455/5000: episode: 19, duration: 0.132s, episode steps:  14, steps per second: 106, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.213168, mae: 6.473395, mean_q: 12.077441, mean_eps: 0.919450\n",
            "  469/5000: episode: 20, duration: 0.130s, episode steps:  14, steps per second: 108, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.714 [0.000, 1.000],  loss: 2.028493, mae: 6.523730, mean_q: 12.017422, mean_eps: 0.916930\n",
            "  486/5000: episode: 21, duration: 0.166s, episode steps:  17, steps per second: 102, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.800882, mae: 6.361150, mean_q: 11.778785, mean_eps: 0.914140\n",
            "  500/5000: episode: 22, duration: 0.122s, episode steps:  14, steps per second: 115, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 1.411283, mae: 6.307057, mean_q: 11.729028, mean_eps: 0.911350\n",
            "  509/5000: episode: 23, duration: 0.085s, episode steps:   9, steps per second: 106, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 1.321946, mae: 6.241093, mean_q: 11.622496, mean_eps: 0.909280\n",
            "  530/5000: episode: 24, duration: 0.199s, episode steps:  21, steps per second: 105, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 1.539576, mae: 6.589882, mean_q: 12.325386, mean_eps: 0.906580\n",
            "  544/5000: episode: 25, duration: 0.146s, episode steps:  14, steps per second:  96, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 1.437969, mae: 6.438307, mean_q: 12.003273, mean_eps: 0.903430\n",
            "  577/5000: episode: 26, duration: 0.352s, episode steps:  33, steps per second:  94, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.702499, mae: 6.464677, mean_q: 12.011910, mean_eps: 0.899200\n",
            "  614/5000: episode: 27, duration: 0.495s, episode steps:  37, steps per second:  75, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 1.999916, mae: 6.545258, mean_q: 12.148394, mean_eps: 0.892900\n",
            "  631/5000: episode: 28, duration: 0.238s, episode steps:  17, steps per second:  71, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 1.531179, mae: 6.459636, mean_q: 12.105086, mean_eps: 0.888040\n",
            "  670/5000: episode: 29, duration: 0.509s, episode steps:  39, steps per second:  77, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.513 [0.000, 1.000],  loss: 1.380960, mae: 6.680952, mean_q: 12.546767, mean_eps: 0.883000\n",
            "  687/5000: episode: 30, duration: 0.225s, episode steps:  17, steps per second:  76, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 1.531620, mae: 6.842401, mean_q: 12.836161, mean_eps: 0.877960\n",
            "  700/5000: episode: 31, duration: 0.171s, episode steps:  13, steps per second:  76, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 1.507163, mae: 6.888438, mean_q: 12.957897, mean_eps: 0.875260\n",
            "  710/5000: episode: 32, duration: 0.146s, episode steps:  10, steps per second:  68, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 1.995723, mae: 6.842546, mean_q: 12.742441, mean_eps: 0.873190\n",
            "  726/5000: episode: 33, duration: 0.230s, episode steps:  16, steps per second:  70, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 1.690519, mae: 6.763160, mean_q: 12.677115, mean_eps: 0.870850\n",
            "  740/5000: episode: 34, duration: 0.189s, episode steps:  14, steps per second:  74, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 1.962951, mae: 6.858759, mean_q: 12.830439, mean_eps: 0.868150\n",
            "  756/5000: episode: 35, duration: 0.232s, episode steps:  16, steps per second:  69, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 1.463990, mae: 6.856488, mean_q: 12.909918, mean_eps: 0.865450\n",
            "  768/5000: episode: 36, duration: 0.112s, episode steps:  12, steps per second: 107, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.382550, mae: 6.810867, mean_q: 12.752305, mean_eps: 0.862930\n",
            "  784/5000: episode: 37, duration: 0.144s, episode steps:  16, steps per second: 111, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.654131, mae: 6.932240, mean_q: 13.018790, mean_eps: 0.860410\n",
            "  795/5000: episode: 38, duration: 0.108s, episode steps:  11, steps per second: 101, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 1.440771, mae: 6.886317, mean_q: 12.959729, mean_eps: 0.857980\n",
            "  810/5000: episode: 39, duration: 0.132s, episode steps:  15, steps per second: 114, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 1.721783, mae: 6.890170, mean_q: 12.893465, mean_eps: 0.855640\n",
            "  836/5000: episode: 40, duration: 0.220s, episode steps:  26, steps per second: 118, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 2.256627, mae: 6.968908, mean_q: 13.004569, mean_eps: 0.851950\n",
            "  900/5000: episode: 41, duration: 0.557s, episode steps:  64, steps per second: 115, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.783232, mae: 6.973857, mean_q: 13.046336, mean_eps: 0.843850\n",
            "  920/5000: episode: 42, duration: 0.182s, episode steps:  20, steps per second: 110, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 2.190414, mae: 7.139173, mean_q: 13.286915, mean_eps: 0.836290\n",
            "  938/5000: episode: 43, duration: 0.170s, episode steps:  18, steps per second: 106, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 2.353678, mae: 7.242394, mean_q: 13.457456, mean_eps: 0.832870\n",
            "  959/5000: episode: 44, duration: 0.182s, episode steps:  21, steps per second: 115, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 2.967240, mae: 7.143786, mean_q: 13.149157, mean_eps: 0.829360\n",
            " 1001/5000: episode: 45, duration: 0.397s, episode steps:  42, steps per second: 106, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 1.266981, mae: 7.189204, mean_q: 13.491273, mean_eps: 0.823690\n",
            " 1017/5000: episode: 46, duration: 0.154s, episode steps:  16, steps per second: 104, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 1.739453, mae: 7.479170, mean_q: 13.980060, mean_eps: 0.818470\n",
            " 1040/5000: episode: 47, duration: 0.219s, episode steps:  23, steps per second: 105, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.565 [0.000, 1.000],  loss: 2.009001, mae: 7.324889, mean_q: 13.611067, mean_eps: 0.814960\n",
            " 1060/5000: episode: 48, duration: 0.180s, episode steps:  20, steps per second: 111, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 2.100464, mae: 7.259583, mean_q: 13.471430, mean_eps: 0.811090\n",
            " 1098/5000: episode: 49, duration: 0.358s, episode steps:  38, steps per second: 106, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 2.479819, mae: 7.358030, mean_q: 13.627375, mean_eps: 0.805870\n",
            " 1208/5000: episode: 50, duration: 1.043s, episode steps: 110, steps per second: 105, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 2.334107, mae: 7.507083, mean_q: 13.920057, mean_eps: 0.792550\n",
            " 1247/5000: episode: 51, duration: 0.380s, episode steps:  39, steps per second: 103, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 1.813846, mae: 7.562625, mean_q: 14.124689, mean_eps: 0.779140\n",
            " 1290/5000: episode: 52, duration: 0.385s, episode steps:  43, steps per second: 112, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 2.389800, mae: 7.636916, mean_q: 14.181899, mean_eps: 0.771760\n",
            " 1310/5000: episode: 53, duration: 0.186s, episode steps:  20, steps per second: 108, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 2.906339, mae: 7.862326, mean_q: 14.531967, mean_eps: 0.766090\n",
            " 1348/5000: episode: 54, duration: 0.325s, episode steps:  38, steps per second: 117, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.000184, mae: 7.764722, mean_q: 14.539134, mean_eps: 0.760870\n",
            " 1366/5000: episode: 55, duration: 0.161s, episode steps:  18, steps per second: 112, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 1.765866, mae: 7.899498, mean_q: 14.811826, mean_eps: 0.755830\n",
            " 1404/5000: episode: 56, duration: 0.374s, episode steps:  38, steps per second: 102, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 2.263792, mae: 7.860802, mean_q: 14.688392, mean_eps: 0.750790\n",
            " 1435/5000: episode: 57, duration: 0.314s, episode steps:  31, steps per second:  99, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 2.672083, mae: 7.935876, mean_q: 14.830891, mean_eps: 0.744580\n",
            " 1457/5000: episode: 58, duration: 0.218s, episode steps:  22, steps per second: 101, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 2.208977, mae: 8.021956, mean_q: 15.041645, mean_eps: 0.739810\n",
            " 1478/5000: episode: 59, duration: 0.213s, episode steps:  21, steps per second:  99, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 2.424529, mae: 8.091534, mean_q: 15.160273, mean_eps: 0.735940\n",
            " 1500/5000: episode: 60, duration: 0.222s, episode steps:  22, steps per second:  99, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.318 [0.000, 1.000],  loss: 2.806052, mae: 8.143265, mean_q: 15.243693, mean_eps: 0.732070\n",
            " 1542/5000: episode: 61, duration: 0.406s, episode steps:  42, steps per second: 103, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.548 [0.000, 1.000],  loss: 2.618600, mae: 8.178983, mean_q: 15.364019, mean_eps: 0.726310\n",
            " 1565/5000: episode: 62, duration: 0.205s, episode steps:  23, steps per second: 112, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.435 [0.000, 1.000],  loss: 2.499402, mae: 8.124268, mean_q: 15.282199, mean_eps: 0.720460\n",
            " 1625/5000: episode: 63, duration: 0.553s, episode steps:  60, steps per second: 109, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 2.848330, mae: 8.394841, mean_q: 15.781386, mean_eps: 0.712990\n",
            " 1636/5000: episode: 64, duration: 0.111s, episode steps:  11, steps per second:  99, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 2.102287, mae: 8.310890, mean_q: 15.748987, mean_eps: 0.706600\n",
            " 1679/5000: episode: 65, duration: 0.409s, episode steps:  43, steps per second: 105, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 3.435579, mae: 8.471001, mean_q: 15.856661, mean_eps: 0.701740\n",
            " 1754/5000: episode: 66, duration: 0.667s, episode steps:  75, steps per second: 112, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 2.900065, mae: 8.554153, mean_q: 16.156386, mean_eps: 0.691120\n",
            " 1812/5000: episode: 67, duration: 0.536s, episode steps:  58, steps per second: 108, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 3.225197, mae: 8.870887, mean_q: 16.729023, mean_eps: 0.679150\n",
            " 1847/5000: episode: 68, duration: 0.397s, episode steps:  35, steps per second:  88, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 2.991647, mae: 8.989115, mean_q: 17.039332, mean_eps: 0.670780\n",
            " 1893/5000: episode: 69, duration: 0.620s, episode steps:  46, steps per second:  74, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.433185, mae: 9.023619, mean_q: 16.931250, mean_eps: 0.663490\n",
            " 1927/5000: episode: 70, duration: 0.477s, episode steps:  34, steps per second:  71, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 2.776578, mae: 9.078150, mean_q: 17.252931, mean_eps: 0.656290\n",
            " 1959/5000: episode: 71, duration: 0.455s, episode steps:  32, steps per second:  70, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.388013, mae: 9.282931, mean_q: 17.599123, mean_eps: 0.650350\n",
            " 2005/5000: episode: 72, duration: 0.700s, episode steps:  46, steps per second:  66, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 2.273201, mae: 9.333442, mean_q: 17.858308, mean_eps: 0.643330\n",
            " 2059/5000: episode: 73, duration: 0.550s, episode steps:  54, steps per second:  98, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.585380, mae: 9.573370, mean_q: 18.207960, mean_eps: 0.634330\n",
            " 2148/5000: episode: 74, duration: 0.830s, episode steps:  89, steps per second: 107, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 3.794628, mae: 9.801002, mean_q: 18.652404, mean_eps: 0.621460\n",
            " 2212/5000: episode: 75, duration: 0.590s, episode steps:  64, steps per second: 109, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 3.983881, mae: 10.009623, mean_q: 19.092065, mean_eps: 0.607690\n",
            " 2262/5000: episode: 76, duration: 0.441s, episode steps:  50, steps per second: 113, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 2.822731, mae: 10.142555, mean_q: 19.523096, mean_eps: 0.597430\n",
            " 2313/5000: episode: 77, duration: 0.447s, episode steps:  51, steps per second: 114, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 3.388702, mae: 10.293973, mean_q: 19.788594, mean_eps: 0.588340\n",
            " 2355/5000: episode: 78, duration: 0.376s, episode steps:  42, steps per second: 112, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 3.487259, mae: 10.444910, mean_q: 20.127574, mean_eps: 0.579970\n",
            " 2400/5000: episode: 79, duration: 0.430s, episode steps:  45, steps per second: 105, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 2.895727, mae: 10.627445, mean_q: 20.603702, mean_eps: 0.572140\n",
            " 2465/5000: episode: 80, duration: 0.597s, episode steps:  65, steps per second: 109, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 3.792000, mae: 10.764204, mean_q: 20.810599, mean_eps: 0.562240\n",
            " 2527/5000: episode: 81, duration: 0.580s, episode steps:  62, steps per second: 107, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 3.568112, mae: 10.950235, mean_q: 21.254698, mean_eps: 0.550810\n",
            " 2563/5000: episode: 82, duration: 0.334s, episode steps:  36, steps per second: 108, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 5.826487, mae: 11.141455, mean_q: 21.387741, mean_eps: 0.541990\n",
            " 2580/5000: episode: 83, duration: 0.157s, episode steps:  17, steps per second: 109, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.226693, mae: 10.997757, mean_q: 21.350568, mean_eps: 0.537220\n",
            " 2639/5000: episode: 84, duration: 0.564s, episode steps:  59, steps per second: 105, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 4.419272, mae: 11.210825, mean_q: 21.711374, mean_eps: 0.530380\n",
            " 2682/5000: episode: 85, duration: 0.437s, episode steps:  43, steps per second:  98, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.488 [0.000, 1.000],  loss: 5.377473, mae: 11.424399, mean_q: 22.077140, mean_eps: 0.521200\n",
            " 2700/5000: episode: 86, duration: 0.180s, episode steps:  18, steps per second: 100, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.611 [0.000, 1.000],  loss: 4.139885, mae: 11.301273, mean_q: 21.946618, mean_eps: 0.515710\n",
            " 2900/5000: episode: 87, duration: 1.820s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.824958, mae: 11.744378, mean_q: 22.832170, mean_eps: 0.496090\n",
            " 2995/5000: episode: 88, duration: 0.878s, episode steps:  95, steps per second: 108, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 4.391523, mae: 12.121684, mean_q: 23.639813, mean_eps: 0.469540\n",
            " 3146/5000: episode: 89, duration: 1.495s, episode steps: 151, steps per second: 101, episode reward: 151.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 4.775649, mae: 12.488697, mean_q: 24.399581, mean_eps: 0.447400\n",
            " 3207/5000: episode: 90, duration: 0.719s, episode steps:  61, steps per second:  85, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 5.265929, mae: 12.844635, mean_q: 25.101681, mean_eps: 0.428320\n",
            " 3278/5000: episode: 91, duration: 0.889s, episode steps:  71, steps per second:  80, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 5.148678, mae: 12.973235, mean_q: 25.390078, mean_eps: 0.416440\n",
            " 3411/5000: episode: 92, duration: 1.257s, episode steps: 133, steps per second: 106, episode reward: 133.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 5.385899, mae: 13.302266, mean_q: 26.087315, mean_eps: 0.398080\n",
            " 3494/5000: episode: 93, duration: 0.758s, episode steps:  83, steps per second: 110, episode reward: 83.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 4.676625, mae: 13.522108, mean_q: 26.603892, mean_eps: 0.378640\n",
            " 3580/5000: episode: 94, duration: 0.769s, episode steps:  86, steps per second: 112, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 6.023323, mae: 13.814864, mean_q: 27.088157, mean_eps: 0.363430\n",
            " 3618/5000: episode: 95, duration: 0.320s, episode steps:  38, steps per second: 119, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 4.171945, mae: 13.875263, mean_q: 27.413230, mean_eps: 0.352270\n",
            " 3670/5000: episode: 96, duration: 0.433s, episode steps:  52, steps per second: 120, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.467126, mae: 14.024201, mean_q: 27.649616, mean_eps: 0.344170\n",
            " 3738/5000: episode: 97, duration: 0.651s, episode steps:  68, steps per second: 104, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.914582, mae: 14.209066, mean_q: 27.829977, mean_eps: 0.333370\n",
            " 3805/5000: episode: 98, duration: 0.609s, episode steps:  67, steps per second: 110, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 4.741369, mae: 14.338685, mean_q: 28.307916, mean_eps: 0.321220\n",
            " 3897/5000: episode: 99, duration: 0.803s, episode steps:  92, steps per second: 115, episode reward: 92.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 5.756390, mae: 14.571262, mean_q: 28.693634, mean_eps: 0.306910\n",
            " 3974/5000: episode: 100, duration: 0.640s, episode steps:  77, steps per second: 120, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 5.576559, mae: 14.740045, mean_q: 29.090140, mean_eps: 0.291700\n",
            " 4050/5000: episode: 101, duration: 0.703s, episode steps:  76, steps per second: 108, episode reward: 76.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 6.274818, mae: 14.992296, mean_q: 29.551462, mean_eps: 0.277930\n",
            " 4118/5000: episode: 102, duration: 0.590s, episode steps:  68, steps per second: 115, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 5.386915, mae: 15.119301, mean_q: 29.877202, mean_eps: 0.264970\n",
            " 4318/5000: episode: 103, duration: 1.725s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 5.587877, mae: 15.401247, mean_q: 30.492993, mean_eps: 0.240850\n",
            " 4443/5000: episode: 104, duration: 1.064s, episode steps: 125, steps per second: 117, episode reward: 125.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 4.581224, mae: 15.710610, mean_q: 31.239377, mean_eps: 0.211600\n",
            " 4499/5000: episode: 105, duration: 0.723s, episode steps:  56, steps per second:  77, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 5.385270, mae: 16.018998, mean_q: 31.813095, mean_eps: 0.195310\n",
            " 4562/5000: episode: 106, duration: 0.791s, episode steps:  63, steps per second:  80, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 4.520501, mae: 16.034658, mean_q: 31.934317, mean_eps: 0.184600\n",
            " 4624/5000: episode: 107, duration: 0.807s, episode steps:  62, steps per second:  77, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.548 [0.000, 1.000],  loss: 5.974803, mae: 16.264168, mean_q: 32.315268, mean_eps: 0.173350\n",
            " 4691/5000: episode: 108, duration: 0.688s, episode steps:  67, steps per second:  97, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.552 [0.000, 1.000],  loss: 8.630619, mae: 16.443809, mean_q: 32.396802, mean_eps: 0.161740\n",
            " 4797/5000: episode: 109, duration: 0.910s, episode steps: 106, steps per second: 116, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 5.753090, mae: 16.455627, mean_q: 32.686450, mean_eps: 0.146170\n",
            " 4865/5000: episode: 110, duration: 0.595s, episode steps:  68, steps per second: 114, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.544 [0.000, 1.000],  loss: 5.743227, mae: 16.682458, mean_q: 33.165334, mean_eps: 0.130510\n",
            " 4930/5000: episode: 111, duration: 0.581s, episode steps:  65, steps per second: 112, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 6.253937, mae: 16.750338, mean_q: 33.252375, mean_eps: 0.118540\n",
            "done, took 48.626 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history_6.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "#testing the model 5\n",
        "for i in range(0,3):\n",
        "    dqn_6.test(env, nb_episodes=20, visualize=False)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w4oL3LZHFGT2",
        "outputId": "cd013812-3cfe-4a30-ece1-fb6b44802bdc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 65.000, steps: 65\n",
            "Episode 2: reward: 71.000, steps: 71\n",
            "Episode 3: reward: 64.000, steps: 64\n",
            "Episode 4: reward: 82.000, steps: 82\n",
            "Episode 5: reward: 73.000, steps: 73\n",
            "Episode 6: reward: 69.000, steps: 69\n",
            "Episode 7: reward: 77.000, steps: 77\n",
            "Episode 8: reward: 68.000, steps: 68\n",
            "Episode 9: reward: 59.000, steps: 59\n",
            "Episode 10: reward: 91.000, steps: 91\n",
            "Episode 11: reward: 76.000, steps: 76\n",
            "Episode 12: reward: 87.000, steps: 87\n",
            "Episode 13: reward: 87.000, steps: 87\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 71.000, steps: 71\n",
            "Episode 16: reward: 129.000, steps: 129\n",
            "Episode 17: reward: 84.000, steps: 84\n",
            "Episode 18: reward: 67.000, steps: 67\n",
            "Episode 19: reward: 77.000, steps: 77\n",
            "Episode 20: reward: 91.000, steps: 91\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 101.000, steps: 101\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 69.000, steps: 69\n",
            "Episode 4: reward: 90.000, steps: 90\n",
            "Episode 5: reward: 77.000, steps: 77\n",
            "Episode 6: reward: 71.000, steps: 71\n",
            "Episode 7: reward: 77.000, steps: 77\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 71.000, steps: 71\n",
            "Episode 10: reward: 75.000, steps: 75\n",
            "Episode 11: reward: 82.000, steps: 82\n",
            "Episode 12: reward: 61.000, steps: 61\n",
            "Episode 13: reward: 75.000, steps: 75\n",
            "Episode 14: reward: 88.000, steps: 88\n",
            "Episode 15: reward: 96.000, steps: 96\n",
            "Episode 16: reward: 63.000, steps: 63\n",
            "Episode 17: reward: 81.000, steps: 81\n",
            "Episode 18: reward: 69.000, steps: 69\n",
            "Episode 19: reward: 63.000, steps: 63\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "\n",
            "\n",
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 69.000, steps: 69\n",
            "Episode 2: reward: 69.000, steps: 69\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 57.000, steps: 57\n",
            "Episode 5: reward: 79.000, steps: 79\n",
            "Episode 6: reward: 69.000, steps: 69\n",
            "Episode 7: reward: 75.000, steps: 75\n",
            "Episode 8: reward: 69.000, steps: 69\n",
            "Episode 9: reward: 79.000, steps: 79\n",
            "Episode 10: reward: 69.000, steps: 69\n",
            "Episode 11: reward: 57.000, steps: 57\n",
            "Episode 12: reward: 74.000, steps: 74\n",
            "Episode 13: reward: 72.000, steps: 72\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 75.000, steps: 75\n",
            "Episode 16: reward: 60.000, steps: 60\n",
            "Episode 17: reward: 77.000, steps: 77\n",
            "Episode 18: reward: 75.000, steps: 75\n",
            "Episode 19: reward: 83.000, steps: 83\n",
            "Episode 20: reward: 101.000, steps: 101\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2TVHMlRsFyoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "Model 2 and model 3  gets similar result but, I have choosen the model which is having the less mae that is model_2"
      ],
      "metadata": {
        "id": "LzTAi-WjGs2b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m20O_8cnG1wd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}